{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c90dab",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5161412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db625c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from uberduck_ml_dev.models.common import STFT, MelSTFT\n",
    "from uberduck_ml_dev.text.util import text_to_sequence\n",
    "from uberduck_ml_dev.utils import load_filepaths_and_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "?text_to_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _orig_to_dense_speaker_id(speaker_ids):\n",
    "    speaker_ids = sorted(list(set(speaker_ids)))\n",
    "    return {\n",
    "        orig: idx for orig, idx in zip(speaker_ids, range(len(speaker_ids)))\n",
    "    }\n",
    "\n",
    "\n",
    "class TextMelDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        audiopaths_and_text: str,\n",
    "        text_cleaners: List[str],\n",
    "        n_mel_channels: int,\n",
    "        sample_rate: int,\n",
    "        mel_fmin: float,\n",
    "        mel_fmax: float,\n",
    "        filter_length: int,\n",
    "        hop_length: int,\n",
    "        win_length: int,\n",
    "        max_wav_value: float = 32768.0,\n",
    "        include_f0: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if include_f0:\n",
    "            raise NotImplemented\n",
    "        path = str(Path(dataset_path) / audiopaths_and_text)\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(path)\n",
    "        self.text_cleaners = text_cleaners\n",
    "        self.stft = MelSTFT(\n",
    "            filter_length=filter_length,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            n_mel_channels=n_mel_channels,\n",
    "            sampling_rate=sample_rate,\n",
    "            mel_fmin=mel_fmin,\n",
    "            mel_fmax=mel_fmax,\n",
    "        )\n",
    "        self.max_wav_value = max_wav_value\n",
    "        self.include_f0 = include_f0\n",
    "        # speaker id lookup table\n",
    "        speaker_ids =[i[2] for i in self.audiopaths_and_text]\n",
    "        self._speaker_id_map = _orig_to_dense_speaker_id(speaker_ids)\n",
    "        \n",
    "\n",
    "    def _get_data(audiopath_and_text):\n",
    "        path, transcription, speaker_id = audiopath_and_text\n",
    "        speaker_id = self._speaker_id_map[speaker_id]\n",
    "        sample_rate, wav_data = read(path)\n",
    "        text_sequence = torch.LongTensor(text_to_sequence(transcription, self.cleaners))\n",
    "        audio = torch.FloatTensor(wav_data)\n",
    "        audio_norm = audio / self.max_wav_value\n",
    "        audio_norm = audio_norm.unsqueeze(0)\n",
    "        melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "        melspec = torch.squeeze(melspec, 0)\n",
    "        return (text, melspec, speaker_id)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return\"\"\"\n",
    "        return self._get_data(self.audiopaths_and_text[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audiopaths_and_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class TextMelCollate:\n",
    "    def __init__(self, n_frames_per_step: int = 1, include_f0: bool = False):\n",
    "        self.n_frames_per_step = n_frames_per_step\n",
    "        self.include_f0 = include_f0\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"Collate's training batch from normalized text and mel-spectrogram\n",
    "        PARAMS\n",
    "        ------\n",
    "        batch: [text_normalized, mel_normalized, speaker_id]\n",
    "        \"\"\"\n",
    "        # Right zero-pad all one-hot text sequences to max input length\n",
    "        input_lengths, ids_sorted_decreasing = torch.sort(\n",
    "            torch.LongTensor([len(x[0]) for x in batch]), dim=0, descending=True\n",
    "        )\n",
    "        max_input_len = input_lengths[0]\n",
    "\n",
    "        text_padded = torch.LongTensor(len(batch), max_input_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            text = batch[ids_sorted_decreasing[i]][0]\n",
    "            text_padded[i, : text.size(0)] = text\n",
    "\n",
    "        # Right zero-pad mel-spec\n",
    "        num_mels = batch[0][1].size(0)\n",
    "        max_target_len = max([x[1].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += (\n",
    "                self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            )\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "\n",
    "        # include mel padded, gate padded and speaker ids\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        gate_padded = torch.FloatTensor(len(batch), max_target_len)\n",
    "        gate_padded.zero_()\n",
    "        output_lengths = torch.LongTensor(len(batch))\n",
    "        speaker_ids = torch.LongTensor(len(batch))\n",
    "        if self.include_f0:\n",
    "            f0_padded = torch.FloatTensor(len(batch), 1, max_target_len)\n",
    "            f0_padded.zero_()\n",
    "\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            mel = batch[ids_sorted_decreasing[i]][1]\n",
    "            mel_padded[i, :, : mel.size(1)] = mel\n",
    "            gate_padded[i, mel.size(1) - 1 :] = 1\n",
    "            output_lengths[i] = mel.size(1)\n",
    "            speaker_ids[i] = batch[ids_sorted_decreasing[i]][2]\n",
    "            if self.include_f0:\n",
    "                f0 = batch[ids_sorted_decreasing[i]][3]\n",
    "                f0_padded[i, :, : f0.size(1)] = f0\n",
    "\n",
    "        # NOTE(zach): would model_inputs be better as a namedtuple or dataclass?\n",
    "        if self.include_f0:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "                f0_padded,\n",
    "            )\n",
    "        else:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "            )\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed89f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0, 3: 1, 4: 2, 9: 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_orig_to_dense_speaker_id([4, 2, 9, 3, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198059d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7a8f36198146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-35-1bddb3227af5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, audiopaths_and_text, text_cleaners, n_mel_channels, sample_rate, mel_fmin, mel_fmax, filter_length, hop_length, win_length, max_wav_value, include_f0)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mmel_fmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmel_fmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mmel_fmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmel_fmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wav_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_wav_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/uberduck-ml-dev/uberduck_ml_dev/models/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filter_length, hop_length, win_length, n_mel_channels, sampling_rate, mel_fmin, mel_fmax)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_mel_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_mel_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         mel_basis = librosa_mel_fn(\n\u001b[1;32m    171\u001b[0m             \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mel_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_fmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_fmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/uberduck-ml-dev/uberduck_ml_dev/models/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filter_length, hop_length, win_length, window)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_length\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mfourier_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_length\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "?MelSTFT\n",
    "ds = TextMelDataset(\n",
    "    \"../dataset\",\n",
    "     \"val.txt\",\n",
    "    [\"english_cleaners\"],\n",
    "    80,\n",
    "    22050,\n",
    "    0,\n",
    "    8000,\n",
    "    1024,\n",
    "    256,\n",
    "    1024,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16563fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zwf/code/uberduck-ml-dev/nbs\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10c68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
