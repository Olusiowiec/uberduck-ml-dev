{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697b10dd",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c90dab",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5161412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db625c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from uberduck_ml_dev.models.common import STFT, MelSTFT\n",
    "from uberduck_ml_dev.text.util import text_to_sequence\n",
    "from uberduck_ml_dev.utils import load_filepaths_and_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "?text_to_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _orig_to_dense_speaker_id(speaker_ids):\n",
    "    speaker_ids = sorted(list(set(speaker_ids)))\n",
    "    return {\n",
    "        orig: idx for orig, idx in zip(speaker_ids, range(len(speaker_ids)))\n",
    "    }\n",
    "\n",
    "\n",
    "class TextMelDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        audiopaths_and_text: str,\n",
    "        text_cleaners: List[str],\n",
    "        n_mel_channels: int,\n",
    "        sample_rate: int,\n",
    "        mel_fmin: float,\n",
    "        mel_fmax: float,\n",
    "        filter_length: int,\n",
    "        hop_length: int,\n",
    "        win_length: int,\n",
    "        max_wav_value: float = 32768.0,\n",
    "        include_f0: bool = False,\n",
    "        debug: bool = False,\n",
    "        debug_dataset_size: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if include_f0:\n",
    "            raise NotImplemented\n",
    "        path = str(Path(dataset_path) / audiopaths_and_text)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(path)\n",
    "        self.text_cleaners = text_cleaners\n",
    "        self.stft = MelSTFT(\n",
    "            filter_length=filter_length,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            n_mel_channels=n_mel_channels,\n",
    "            sampling_rate=sample_rate,\n",
    "            mel_fmin=mel_fmin,\n",
    "            mel_fmax=mel_fmax,\n",
    "        )\n",
    "        self.max_wav_value = max_wav_value\n",
    "        self.include_f0 = include_f0\n",
    "        # speaker id lookup table\n",
    "        speaker_ids =[i[2] for i in self.audiopaths_and_text]\n",
    "        self._speaker_id_map = _orig_to_dense_speaker_id(speaker_ids)\n",
    "        self.debug = debug\n",
    "        self.debug_dataset_size = debug_dataset_size\n",
    "        \n",
    "\n",
    "    def _get_data(self, audiopath_and_text):\n",
    "        path, transcription, speaker_id = audiopath_and_text\n",
    "        speaker_id = self._speaker_id_map[speaker_id]\n",
    "        path = Path(self.dataset_path) / path\n",
    "        sample_rate, wav_data = read(path)\n",
    "        text_sequence = torch.LongTensor(text_to_sequence(transcription, self.text_cleaners))\n",
    "        audio = torch.FloatTensor(wav_data)\n",
    "        audio_norm = audio / self.max_wav_value\n",
    "        audio_norm = audio_norm.unsqueeze(0)\n",
    "        melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "        melspec = torch.squeeze(melspec, 0)\n",
    "        return (text_sequence, melspec, speaker_id)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return\"\"\"\n",
    "        return self._get_data(self.audiopaths_and_text[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.debug and self.debug_dataset_size:\n",
    "            return self.debug_dataset_size\n",
    "        return len(self.audiopaths_and_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class TextMelCollate:\n",
    "    def __init__(self, n_frames_per_step: int = 1, include_f0: bool = False):\n",
    "        self.n_frames_per_step = n_frames_per_step\n",
    "        self.include_f0 = include_f0\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"Collate's training batch from normalized text and mel-spectrogram\n",
    "        PARAMS\n",
    "        ------\n",
    "        batch: [text_normalized, mel_normalized, speaker_id]\n",
    "        \"\"\"\n",
    "        # Right zero-pad all one-hot text sequences to max input length\n",
    "        input_lengths, ids_sorted_decreasing = torch.sort(\n",
    "            torch.LongTensor([len(x[0]) for x in batch]), dim=0, descending=True\n",
    "        )\n",
    "        max_input_len = input_lengths[0]\n",
    "\n",
    "        text_padded = torch.LongTensor(len(batch), max_input_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            text = batch[ids_sorted_decreasing[i]][0]\n",
    "            text_padded[i, : text.size(0)] = text\n",
    "\n",
    "        # Right zero-pad mel-spec\n",
    "        num_mels = batch[0][1].size(0)\n",
    "        max_target_len = max([x[1].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += (\n",
    "                self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            )\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "\n",
    "        # include mel padded, gate padded and speaker ids\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        gate_padded = torch.FloatTensor(len(batch), max_target_len)\n",
    "        gate_padded.zero_()\n",
    "        output_lengths = torch.LongTensor(len(batch))\n",
    "        speaker_ids = torch.LongTensor(len(batch))\n",
    "        if self.include_f0:\n",
    "            f0_padded = torch.FloatTensor(len(batch), 1, max_target_len)\n",
    "            f0_padded.zero_()\n",
    "\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            mel = batch[ids_sorted_decreasing[i]][1]\n",
    "            mel_padded[i, :, : mel.size(1)] = mel\n",
    "            gate_padded[i, mel.size(1) - 1 :] = 1\n",
    "            output_lengths[i] = mel.size(1)\n",
    "            speaker_ids[i] = batch[ids_sorted_decreasing[i]][2]\n",
    "            if self.include_f0:\n",
    "                f0 = batch[ids_sorted_decreasing[i]][3]\n",
    "                f0_padded[i, :, : f0.size(1)] = f0\n",
    "\n",
    "        # NOTE(zach): would model_inputs be better as a namedtuple or dataclass?\n",
    "        if self.include_f0:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "                speaker_ids,\n",
    "                f0_padded,\n",
    "            )\n",
    "        else:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "                speaker_ids,\n",
    "            )\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed89f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0, 3: 1, 4: 2, 9: 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_orig_to_dense_speaker_id([4, 2, 9, 3, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TextMelDataset(\n",
    "    \"../dataset\",\n",
    "     \"val.txt\",\n",
    "    [\"english_cleaners\"],\n",
    "    80,\n",
    "    22050,\n",
    "    0,\n",
    "    8000,\n",
    "    1024,\n",
    "    256,\n",
    "    1024,\n",
    "    debug=True,\n",
    "    debug_dataset_size=12,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16563fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(tensor([[97, 79, 86,  ..., 88, 81,  4],\n",
      "        [86, 83, 80,  ...,  0,  0,  0],\n",
      "        [94, 82, 75,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [89, 82,  4,  ...,  0,  0,  0],\n",
      "        [78, 83, 78,  ...,  0,  0,  0],\n",
      "        [99, 79, 75,  ...,  0,  0,  0]]), tensor([86, 76, 66, 51, 50, 35, 22, 20, 16, 14, 14,  9]), tensor([[[ -9.2433,  -8.2504,  -7.7021,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -8.8916,  -8.1060,  -7.6521,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -9.2697,  -8.5779,  -8.2722,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-11.5129, -11.3297, -10.4252,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.2788, -10.6261,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -10.5454,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-11.5129, -11.5129, -10.1166,  ...,  -8.9449, -10.6371, -11.5129],\n",
      "         [-11.5129, -11.5129, -10.0481,  ...,  -8.8486, -10.6160, -11.5129],\n",
      "         [-11.5129, -11.5129, -10.7568,  ...,  -8.7972, -10.6435, -11.5129],\n",
      "         ...,\n",
      "         [-11.5129, -11.5129, -11.5129,  ..., -11.5129, -11.5129, -11.5129],\n",
      "         [-11.5129, -11.5129, -11.3916,  ..., -11.5129, -11.5129, -11.5129],\n",
      "         [-11.5129, -11.5129, -11.5129,  ..., -11.5129, -11.5129, -11.5129]],\n",
      "\n",
      "        [[-11.5129, -11.5129, -10.7644,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -10.5505,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -10.2999,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-11.5129, -11.5129, -10.6466,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129,  -9.7470,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129,  -9.4861,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-10.4281,  -8.8104,  -8.6297,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-10.0612,  -9.7577,  -9.4897,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -9.9452,  -9.6346, -10.0173,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-11.5129, -11.3703, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -11.5129,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-10.3279,  -9.2361,  -8.5865,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -9.8919,  -9.1726,  -8.0391,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -9.9966,  -9.5341,  -7.3779,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-11.5129, -11.5129, -10.2992,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -10.3661,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-11.5129, -11.5129, -10.5072,  ...,   0.0000,   0.0000,   0.0000]]]), tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.]]), tensor([408, 534, 320, 378, 246, 178, 151, 133, 124, 118,  88,  75]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zwf/miniconda3/envs/uberduck/lib/python3.6/site-packages/ipykernel_launcher.py:57: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "collate_fn = TextMelCollate()\n",
    "dl = DataLoader(ds, 12, collate_fn=collate_fn)\n",
    "for i, batch in enumerate(dl):\n",
    "    print(i)\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10c68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
