{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cdb5ef",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c90dab",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5161412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db625c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from uberduck_ml_dev.models.common import STFT, MelSTFT\n",
    "from uberduck_ml_dev.text.util import text_to_sequence\n",
    "from uberduck_ml_dev.utils import load_filepaths_and_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "?text_to_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def _orig_to_dense_speaker_id(speaker_ids):\n",
    "    speaker_ids = sorted(list(set(speaker_ids)))\n",
    "    return {\n",
    "        orig: idx for orig, idx in zip(speaker_ids, range(len(speaker_ids)))\n",
    "    }\n",
    "\n",
    "\n",
    "class TextMelDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        audiopaths_and_text: str,\n",
    "        text_cleaners: List[str],\n",
    "        n_mel_channels: int,\n",
    "        sample_rate: int,\n",
    "        mel_fmin: float,\n",
    "        mel_fmax: float,\n",
    "        filter_length: int,\n",
    "        hop_length: int,\n",
    "        win_length: int,\n",
    "        max_wav_value: float = 32768.0,\n",
    "        include_f0: bool = False,\n",
    "        debug: bool = False,\n",
    "        debug_dataset_size: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if include_f0:\n",
    "            raise NotImplemented\n",
    "        path = str(Path(dataset_path) / audiopaths_and_text)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(path)\n",
    "        self.text_cleaners = text_cleaners\n",
    "        self.stft = MelSTFT(\n",
    "            filter_length=filter_length,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            n_mel_channels=n_mel_channels,\n",
    "            sampling_rate=sample_rate,\n",
    "            mel_fmin=mel_fmin,\n",
    "            mel_fmax=mel_fmax,\n",
    "        )\n",
    "        self.max_wav_value = max_wav_value\n",
    "        self.include_f0 = include_f0\n",
    "        # speaker id lookup table\n",
    "        speaker_ids =[i[2] for i in self.audiopaths_and_text]\n",
    "        self._speaker_id_map = _orig_to_dense_speaker_id(speaker_ids)\n",
    "        self.debug = debug\n",
    "        self.debug_dataset_size = debug_dataset_size\n",
    "        \n",
    "\n",
    "    def _get_data(self, audiopath_and_text):\n",
    "        path, transcription, speaker_id = audiopath_and_text\n",
    "        speaker_id = self._speaker_id_map[speaker_id]\n",
    "        path = Path(self.dataset_path) / path\n",
    "        sample_rate, wav_data = read(path)\n",
    "        text_sequence = torch.LongTensor(text_to_sequence(transcription, self.text_cleaners))\n",
    "        audio = torch.FloatTensor(wav_data)\n",
    "        audio_norm = audio / self.max_wav_value\n",
    "        audio_norm = audio_norm.unsqueeze(0)\n",
    "        melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "        melspec = torch.squeeze(melspec, 0)\n",
    "        return (text_sequence, melspec, speaker_id)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return\"\"\"\n",
    "        return self._get_data(self.audiopaths_and_text[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.debug and self.debug_dataset_size:\n",
    "            return min(self.debug_dataset_size, len(self.audiopaths_and_text))\n",
    "        return len(self.audiopaths_and_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class TextMelCollate:\n",
    "    def __init__(self, n_frames_per_step: int = 1, include_f0: bool = False):\n",
    "        self.n_frames_per_step = n_frames_per_step\n",
    "        self.include_f0 = include_f0\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"Collate's training batch from normalized text and mel-spectrogram\n",
    "        PARAMS\n",
    "        ------\n",
    "        batch: [text_normalized, mel_normalized, speaker_id]\n",
    "        \"\"\"\n",
    "        # Right zero-pad all one-hot text sequences to max input length\n",
    "        input_lengths, ids_sorted_decreasing = torch.sort(\n",
    "            torch.LongTensor([len(x[0]) for x in batch]), dim=0, descending=True\n",
    "        )\n",
    "        max_input_len = input_lengths[0]\n",
    "\n",
    "        text_padded = torch.LongTensor(len(batch), max_input_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            text = batch[ids_sorted_decreasing[i]][0]\n",
    "            text_padded[i, : text.size(0)] = text\n",
    "\n",
    "        # Right zero-pad mel-spec\n",
    "        num_mels = batch[0][1].size(0)\n",
    "        max_target_len = max([x[1].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += (\n",
    "                self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            )\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "\n",
    "        # include mel padded, gate padded and speaker ids\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        gate_padded = torch.FloatTensor(len(batch), max_target_len)\n",
    "        gate_padded.zero_()\n",
    "        output_lengths = torch.LongTensor(len(batch))\n",
    "        speaker_ids = torch.LongTensor(len(batch))\n",
    "        if self.include_f0:\n",
    "            f0_padded = torch.FloatTensor(len(batch), 1, max_target_len)\n",
    "            f0_padded.zero_()\n",
    "\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            mel = batch[ids_sorted_decreasing[i]][1]\n",
    "            mel_padded[i, :, : mel.size(1)] = mel\n",
    "            gate_padded[i, mel.size(1) - 1 :] = 1\n",
    "            output_lengths[i] = mel.size(1)\n",
    "            speaker_ids[i] = batch[ids_sorted_decreasing[i]][2]\n",
    "            if self.include_f0:\n",
    "                f0 = batch[ids_sorted_decreasing[i]][3]\n",
    "                f0_padded[i, :, : f0.size(1)] = f0\n",
    "\n",
    "        # NOTE(zach): would model_inputs be better as a namedtuple or dataclass?\n",
    "        if self.include_f0:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "                speaker_ids,\n",
    "                f0_padded,\n",
    "            )\n",
    "        else:\n",
    "            model_inputs = (\n",
    "                text_padded,\n",
    "                input_lengths,\n",
    "                mel_padded,\n",
    "                gate_padded,\n",
    "                output_lengths,\n",
    "                speaker_ids,\n",
    "            )\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed89f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0, 3: 1, 4: 2, 9: 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_orig_to_dense_speaker_id([4, 2, 9, 3, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TextMelDataset(\n",
    "    \"./test/fixtures\",\n",
    "     \"val.txt\",\n",
    "    [\"english_cleaners\"],\n",
    "    80,\n",
    "    22050,\n",
    "    0,\n",
    "    8000,\n",
    "    1024,\n",
    "    256,\n",
    "    1024,\n",
    "    debug=True,\n",
    "    debug_dataset_size=12,\n",
    ")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16563fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(tensor([[97, 79, 86, 86,  3,  8, 99, 89, 95,  1, 92, 79,  4,  8, 99, 89, 95,  1,\n",
      "         92, 79,  8, 88, 89, 94,  8, 92, 79, 75, 86, 86, 99,  8, 75,  8, 90, 79,\n",
      "         92, 93, 89, 88,  4,  8, 99, 89, 95,  1, 92, 79,  8, 87, 89, 92, 79,  8,\n",
      "         89, 80,  8, 75, 88,  8, 75, 88, 94, 82, 92, 89, 90, 89, 87, 89, 92, 90,\n",
      "         82, 83, 77,  8, 78, 89, 81,  8, 94, 82, 83, 88, 81,  4]]), tensor([86]), tensor([[[ -7.4811,  -7.1174,  -6.2034,  ...,  -6.8980,  -6.4200,  -6.8893],\n",
      "         [ -7.6766,  -7.0730,  -6.0029,  ...,  -6.4762,  -6.0089,  -6.4041],\n",
      "         [ -6.9245,  -6.7840,  -6.4049,  ...,  -6.2306,  -6.1970,  -6.6943],\n",
      "         ...,\n",
      "         [ -9.6343,  -9.4932,  -9.6086,  ...,  -9.2852,  -9.5855,  -9.9288],\n",
      "         [ -9.5884,  -9.4754,  -9.6879,  ...,  -9.2717,  -9.2050,  -9.6523],\n",
      "         [-10.0712,  -9.8129,  -9.7728,  ...,  -9.4478,  -9.2810,  -9.3694]]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1.]]), tensor([566]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "collate_fn = TextMelCollate()\n",
    "dl = DataLoader(ds, 12, collate_fn=collate_fn)\n",
    "for i, batch in enumerate(dl):\n",
    "    print(i)\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10c68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
