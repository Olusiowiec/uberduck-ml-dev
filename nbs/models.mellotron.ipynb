{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0638ab87",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.mellotron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from uberduck_ml_dev.models.base import TTSModel\n",
    "\n",
    "class Tacotron2(TTSModel):\n",
    "    def __init__(self, hparams):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.mask_padding = hparams.mask_padding\n",
    "        self.fp16_run = hparams.fp16_run\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step = hparams.n_frames_per_step\n",
    "        self.embedding = nn.Embedding(\n",
    "            hparams.n_symbols, hparams.symbols_embedding_dim)\n",
    "        std = sqrt(2.0 / (hparams.n_symbols + hparams.symbols_embedding_dim))\n",
    "        val = sqrt(3.0) * std  # uniform bounds for std\n",
    "        self.embedding.weight.data.uniform_(-val, val)\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.postnet = Postnet(hparams)\n",
    "        if hparams.with_gst:\n",
    "            self.gst = GST(hparams)\n",
    "        self.speaker_embedding = nn.Embedding(\n",
    "            hparams.n_speakers, hparams.speaker_embedding_dim)\n",
    "\n",
    "    def parse_batch(self, batch):\n",
    "        text_padded, input_lengths, mel_padded, gate_padded, \\\n",
    "            output_lengths, speaker_ids, f0_padded = batch\n",
    "        text_padded = to_gpu(text_padded).long()\n",
    "        input_lengths = to_gpu(input_lengths).long()\n",
    "        max_len = torch.max(input_lengths.data).item()\n",
    "        mel_padded = to_gpu(mel_padded).float()\n",
    "        gate_padded = to_gpu(gate_padded).float()\n",
    "        output_lengths = to_gpu(output_lengths).long()\n",
    "        speaker_ids = to_gpu(speaker_ids.data).long()\n",
    "        f0_padded = to_gpu(f0_padded).float()\n",
    "        return ((text_padded, input_lengths, mel_padded, max_len,\n",
    "                 output_lengths, speaker_ids, f0_padded),\n",
    "                (mel_padded, gate_padded))\n",
    "\n",
    "    def parse_output(self, outputs, output_lengths=None):\n",
    "        if self.mask_padding and output_lengths is not None:\n",
    "            mask = ~get_mask_from_lengths(output_lengths)\n",
    "            mask = mask.expand(self.n_mel_channels, mask.size(0), mask.size(1))\n",
    "            mask = mask.permute(1, 0, 2)\n",
    "\n",
    "            outputs[0].data.masked_fill_(mask, 0.0)\n",
    "            outputs[1].data.masked_fill_(mask, 0.0)\n",
    "            outputs[2].data.masked_fill_(mask[:, 0, :], 1e3)  # gate energies\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs, input_lengths, targets, max_len, \\\n",
    "            output_lengths, speaker_ids, f0s = inputs\n",
    "        input_lengths, output_lengths = input_lengths.data, output_lengths.data\n",
    "\n",
    "        embedded_inputs = self.embedding(inputs).transpose(1, 2)\n",
    "        embedded_text = self.encoder(embedded_inputs, input_lengths)\n",
    "        embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "        embedded_gst = self.gst(targets, output_lengths)\n",
    "        embedded_gst = embedded_gst.repeat(1, embedded_text.size(1), 1)\n",
    "        embedded_speakers = embedded_speakers.repeat(1, embedded_text.size(1), 1)\n",
    "\n",
    "        encoder_outputs = torch.cat(\n",
    "            (embedded_text, embedded_gst, embedded_speakers), dim=2)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder(\n",
    "            encoder_outputs, targets, memory_lengths=input_lengths, f0s=f0s)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments],\n",
    "            output_lengths)\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        text, style_input, speaker_ids, f0s = inputs\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        embedded_text = self.encoder.inference(embedded_inputs)\n",
    "        embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "        if hasattr(self, 'gst'):\n",
    "            if isinstance(style_input, int):\n",
    "                query = torch.zeros(1, 1, self.gst.encoder.ref_enc_gru_size).cuda()\n",
    "                GST = torch.tanh(self.gst.stl.embed)\n",
    "                key = GST[style_input].unsqueeze(0).expand(1, -1, -1)\n",
    "                embedded_gst = self.gst.stl.attention(query, key)\n",
    "            else:\n",
    "                embedded_gst = self.gst(style_input)\n",
    "\n",
    "        embedded_speakers = embedded_speakers.repeat(1, embedded_text.size(1), 1)\n",
    "        if hasattr(self, 'gst'):\n",
    "            embedded_gst = embedded_gst.repeat(1, embedded_text.size(1), 1)\n",
    "            encoder_outputs = torch.cat(\n",
    "                (embedded_text, embedded_gst, embedded_speakers), dim=2)\n",
    "        else:\n",
    "            encoder_outputs = torch.cat(\n",
    "                (embedded_text, embedded_speakers), dim=2)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder.inference(\n",
    "            encoder_outputs, f0s)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments])\n",
    "\n",
    "    def inference_noattention(self, inputs):\n",
    "        text, style_input, speaker_ids, f0s, attention_map = inputs\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        embedded_text = self.encoder.inference(embedded_inputs)\n",
    "        embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "        if hasattr(self, 'gst'):\n",
    "            if isinstance(style_input, int):\n",
    "                query = torch.zeros(1, 1, self.gst.encoder.ref_enc_gru_size).cuda()\n",
    "                GST = torch.tanh(self.gst.stl.embed)\n",
    "                key = GST[style_input].unsqueeze(0).expand(1, -1, -1)\n",
    "                embedded_gst = self.gst.stl.attention(query, key)\n",
    "            else:\n",
    "                embedded_gst = self.gst(style_input)\n",
    "\n",
    "        embedded_speakers = embedded_speakers.repeat(1, embedded_text.size(1), 1)\n",
    "        if hasattr(self, 'gst'):\n",
    "            embedded_gst = embedded_gst.repeat(1, embedded_text.size(1), 1)\n",
    "            encoder_outputs = torch.cat(\n",
    "                (embedded_text, embedded_gst, embedded_speakers), dim=2)\n",
    "        else:\n",
    "            encoder_outputs = torch.cat(\n",
    "                (embedded_text, embedded_speakers), dim=2)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder.inference_noattention(\n",
    "            encoder_outputs, f0s, attention_map)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee9119",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-825958957ca2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-825958957ca2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from uberduck_ml_dev.models.base import\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
