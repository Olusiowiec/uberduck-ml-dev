{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pydub import AudioSegment, silence\n",
    "from pydub.utils import mediainfo_json\n",
    "import nltk\n",
    "from typing import List\n",
    "import speechmetrics\n",
    "from tqdm import tqdm\n",
    "from mdutils.mdutils import MdUtils\n",
    "import math\n",
    "from wordfreq import word_frequency\n",
    "from PIL import Image, ImageOps\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from g2p_en import G2p\n",
    "\n",
    "from uberduck_ml_dev.text.util import clean_text, text_to_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f27e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequencies(word_list: List[str]) -> List[float]:\n",
    "    freqs = []\n",
    "    for word in word_list:\n",
    "        freqs.append(word_frequency(word, \"en\"))\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text: str, output_file: str):\n",
    "    mask = np.array(ImageOps.invert(Image.open(\"duck.png\").convert(\"RGB\")))\n",
    "    wc = WordCloud(\n",
    "        background_color=\"white\",\n",
    "        max_words=3000,\n",
    "        mask=mask,\n",
    "        stopwords=set(STOPWORDS),\n",
    "        contour_width=7,\n",
    "        contour_color=\"steelblue\",\n",
    "    )\n",
    "    wc.generate(text)\n",
    "    wc.to_file(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(\n",
    "    dataset_path, input_file, img_folder, delimiter, metrics=True, wordcloud=True\n",
    "):\n",
    "    n_clips = 0\n",
    "    sample_rates = {}\n",
    "    channels = {\"mono\": 0, \"stereo\": 0}\n",
    "    extensions = {}\n",
    "    sample_formats = {}\n",
    "    total_lengths = []\n",
    "    leading_silence_lengths = []\n",
    "    trailing_silence_lengths = []\n",
    "    paces_characters = []  # number of characters / seconds in audio clip\n",
    "    paces_phonemes = []  # number of phonemes / seconds in audio clip\n",
    "    lookup_results = {}  # keep track of how arpabet sequences were generated\n",
    "    mosnet_scores = []\n",
    "    srmr_scores = []\n",
    "    word_frequencies = []\n",
    "    all_words = []\n",
    "    g2p = G2p()\n",
    "\n",
    "    if metrics:\n",
    "        window_length = None  # seconds\n",
    "        metrics = speechmetrics.load(\"absolute\", None)\n",
    "\n",
    "    with open(os.path.join(dataset_path, input_file)) as transcripts:\n",
    "        for line in tqdm(transcripts):\n",
    "            line = line.strip()  # remove trailing newline character\n",
    "            file, transcription = line.lower().split(delimiter)\n",
    "            transcription_cleaned = clean_text(transcription, [\"english_cleaners\"])\n",
    "\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "\n",
    "            file_pydub = AudioSegment.from_wav(os.path.join(dataset_path, file))\n",
    "\n",
    "            # Format Metadata\n",
    "            sr = file_pydub.frame_rate\n",
    "            if sr in sample_rates.keys():\n",
    "                sample_rates[sr] += 1\n",
    "            else:\n",
    "                sample_rates[sr] = 1\n",
    "\n",
    "            if file_pydub.channels == 1:\n",
    "                channels[\"mono\"] += 1\n",
    "            else:\n",
    "                channels[\"stereo\"] += 1\n",
    "\n",
    "            if file_extension in extensions.keys():\n",
    "                extensions[file_extension] += 1\n",
    "            else:\n",
    "                extensions[file_extension] = 1\n",
    "\n",
    "            #  https://stackoverflow.com/questions/62677912/how-to-detect-a-floating-point-audio-file\n",
    "            #  https://forum.videohelp.com/threads/373264-FFMpeg-List-of-working-sample-formats-per-format-and-encoder\n",
    "            info = mediainfo_json(os.path.join(dataset_path, file))\n",
    "            audio_streams = [x for x in info[\"streams\"] if x[\"codec_type\"] == \"audio\"]\n",
    "            fmt = audio_streams[0].get(\"sample_fmt\")\n",
    "            if fmt in sample_formats.keys():\n",
    "                sample_formats[fmt] += 1\n",
    "            else:\n",
    "                sample_formats[fmt] = 1\n",
    "\n",
    "            # lengths\n",
    "            total_lengths.append(file_pydub.duration_seconds)\n",
    "            leading_silence_lengths.append(silence.detect_leading_silence(file_pydub))\n",
    "            trailing_silence_lengths.append(\n",
    "                silence.detect_leading_silence(file_pydub.reverse())\n",
    "            )\n",
    "\n",
    "            # Paces\n",
    "            arpabet_seq = text_to_sequence(\n",
    "                transcription_cleaned, [\"english_cleaners\"], p_arpabet=1.0\n",
    "            )\n",
    "            #             print(\"should be 1D array of arpabet tokens\")\n",
    "            #             print(arpabet_seq)\n",
    "            paces_phonemes.append(len(arpabet_seq) / file_pydub.duration_seconds)\n",
    "            paces_characters.append(\n",
    "                len(transcription_cleaned) / file_pydub.duration_seconds\n",
    "            )\n",
    "\n",
    "            # Quality\n",
    "            if metrics:\n",
    "                scores = metrics(os.path.join(dataset_path, file))\n",
    "                mosnet_scores.append(scores[\"mosnet\"][0][0])\n",
    "                srmr_scores.append(scores[\"srmr\"])\n",
    "\n",
    "            # Transcription\n",
    "            word_frequencies.extend(get_word_frequencies(transcription_cleaned.split()))\n",
    "            transcription_lookups = g2p.check_lookup(transcription_cleaned)\n",
    "            for k in transcription_lookups:\n",
    "                if k in lookup_results.keys():\n",
    "                    lookup_results[k].extend(transcription_lookups[k])\n",
    "                else:\n",
    "                    lookup_results[k] = transcription_lookups[k]\n",
    "\n",
    "            all_words.append(transcription_cleaned)\n",
    "\n",
    "            n_clips += 1\n",
    "\n",
    "            if n_clips > 20:\n",
    "                break\n",
    "    if wordcloud:\n",
    "        create_wordcloud(\n",
    "            \" \".join(all_words), os.path.join(dataset_path, img_folder, \"wordcloud.png\")\n",
    "        )\n",
    "\n",
    "    # Length graph\n",
    "    sns.histplot(total_lengths)\n",
    "    plt.title(\"Audio length distribution\")\n",
    "    plt.xlabel(\"Audio length (s)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(dataset_path, img_folder, \"lengths.png\"))\n",
    "\n",
    "    # Word Frequencies graph\n",
    "    sns.histplot(word_frequencies, bins=10)\n",
    "    plt.title(\"Word frequency distribution [0-1]\")\n",
    "    plt.xlabel(\"Word frequency\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(dataset_path, img_folder, \"word_frequencies.png\"))\n",
    "\n",
    "    # Silences graph\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(leading_silence_lengths)\n",
    "    plt.title(\"Leading silence distribution\")\n",
    "    plt.xlabel(\"Leading silence (ms)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(trailing_silence_lengths)\n",
    "    plt.title(\"Traling silence distribution\")\n",
    "    plt.xlabel(\"Trailing silence (ms)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(dataset_path, img_folder, \"silences.png\"))\n",
    "\n",
    "    # Metrics graph\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(mosnet_scores)\n",
    "    plt.title(\"Mosnet score distribution\")\n",
    "    plt.xlabel(\"Mosnet score\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(srmr_scores)\n",
    "    plt.title(\"SRMR score distribution\")\n",
    "    plt.xlabel(\"SRMR score\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(dataset_path, img_folder, \"metrics.png\"))\n",
    "\n",
    "    # Paces graph\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(paces_characters)\n",
    "    plt.title(\"Pace (chars/s)\")\n",
    "    plt.xlabel(\"Characters / second\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(paces_phonemes)\n",
    "    plt.title(\"Pace (phonemes/s)\")\n",
    "    plt.xlabel(\"Phonemes / second\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(dataset_path, img_folder, \"paces.png\"))\n",
    "\n",
    "    return {\n",
    "        \"n_clips\": n_clips,\n",
    "        \"total_lengths\": total_lengths,\n",
    "        \"paces_phonemes\": paces_phonemes,\n",
    "        \"paces_characters\": paces_characters,\n",
    "        \"mosnet_scores\": mosnet_scores,\n",
    "        \"srmr_scores\": srmr_scores,\n",
    "        \"sample_rates\": sample_rates,\n",
    "        \"channels\": channels,\n",
    "        \"extensions\": extensions,\n",
    "        \"sample_formats\": sample_formats,\n",
    "        \"lookup_results\": lookup_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown(output_file, dataset_path, img_folder, data):\n",
    "    mdFile = MdUtils(\n",
    "        file_name=os.path.join(dataset_path, output_file), title=f\"Dataset statistics\"\n",
    "    )\n",
    "\n",
    "    total_length_mins = sum(data[\"total_lengths\"]) / 60.0\n",
    "    mdFile.new_header(level=1, title=\"Overview\")\n",
    "    mdFile.new_line(f\"**Number of clips:** {data['n_clips']}\")\n",
    "    mdFile.new_line(\n",
    "        f\"**Total data:** {math.floor(total_length_mins)} minutes {math.ceil(total_length_mins % 1 * 60.0)} seconds\"\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        f\"**Mean clip length:** {sum(data['total_lengths'])/data['n_clips']:.2f} seconds\"\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        f\"**Mean pace:** {sum(data['paces_phonemes'])/len(data['paces_phonemes']):.2f} \\\n",
    "            phonemes/sec {sum(data['paces_characters'])/len(data['paces_characters']):.2f} chars/sec\"\n",
    "    )\n",
    "    if len(data[\"mosnet_scores\"]) > 0:\n",
    "        mdFile.new_line(\n",
    "            f\"**Mean MOSNet:** {sum(data['mosnet_scores'])/len(data['mosnet_scores']):.2f}\"\n",
    "        )\n",
    "        mdFile.new_line(\n",
    "            f\"**Mean SRMR:** {sum(data['srmr_scores'])/len(data['srmr_scores']):.2f}\"\n",
    "        )\n",
    "\n",
    "    list_of_strings = [\"Sample Rate (Hz)\", \"Count\"]\n",
    "    for k in data[\"sample_rates\"].keys():\n",
    "        list_of_strings.extend([str(k), str(data[\"sample_rates\"][k])])\n",
    "    mdFile.new_table(\n",
    "        columns=2,\n",
    "        rows=len(data[\"sample_rates\"].keys()) + 1,\n",
    "        text=list_of_strings,\n",
    "        text_align=\"center\",\n",
    "    )\n",
    "\n",
    "    list_of_strings = [\"Audio Type\", \"Count\"]\n",
    "    n_rows = 1\n",
    "    for k in data[\"channels\"].keys():\n",
    "        if data[\"channels\"][k] > 0:\n",
    "            n_rows += 1\n",
    "            list_of_strings.extend([str(k), str(data[\"channels\"][k])])\n",
    "    mdFile.new_table(columns=2, rows=n_rows, text=list_of_strings, text_align=\"center\")\n",
    "\n",
    "    list_of_strings = [\"Audio Format\", \"Count\"]\n",
    "    for k in data[\"extensions\"].keys():\n",
    "        list_of_strings.extend([str(k), str(data[\"extensions\"][k])])\n",
    "    mdFile.new_table(\n",
    "        columns=2,\n",
    "        rows=len(data[\"extensions\"].keys()) + 1,\n",
    "        text=list_of_strings,\n",
    "        text_align=\"center\",\n",
    "    )\n",
    "\n",
    "    list_of_strings = [\"Sample Format\", \"Count\"]\n",
    "    for k in data[\"sample_formats\"].keys():\n",
    "        list_of_strings.extend([str(k), str(data[\"sample_formats\"][k])])\n",
    "    mdFile.new_table(\n",
    "        columns=2,\n",
    "        rows=len(data[\"sample_formats\"].keys()) + 1,\n",
    "        text=list_of_strings,\n",
    "        text_align=\"center\",\n",
    "    )\n",
    "\n",
    "    list_of_strings = [\"Arpabet Lookup Type\", \"Count\"]\n",
    "    for k in data[\"lookup_results\"].keys():\n",
    "        list_of_strings.extend([str(k), str(len(data[\"lookup_results\"][k]))])\n",
    "    mdFile.new_table(\n",
    "        columns=2,\n",
    "        rows=len(data[\"lookup_results\"].keys()) + 1,\n",
    "        text=list_of_strings,\n",
    "        text_align=\"center\",\n",
    "    )\n",
    "\n",
    "    mdFile.new_line(\n",
    "        f'**Arpabet sequences obtained via g2P RNN:** {\" \".join(data[\"lookup_results\"][\"RNN\"])}'\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        mdFile.new_inline_image(\n",
    "            text=\"Wordcloud\", path=os.path.join(img_folder, \"wordcloud.png\")\n",
    "        )\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        mdFile.new_inline_image(\n",
    "            text=\"Audio Lengths\", path=os.path.join(img_folder, \"lengths.png\")\n",
    "        )\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        mdFile.new_inline_image(\n",
    "            text=\"Paces\", path=os.path.join(img_folder, \"paces.png\")\n",
    "        )\n",
    "    )\n",
    "    mdFile.new_line(\n",
    "        mdFile.new_inline_image(\n",
    "            text=\"Silences\", path=os.path.join(img_folder, \"silences.png\")\n",
    "        )\n",
    "    )\n",
    "    if len(data[\"mosnet_scores\"]) > 0:\n",
    "        mdFile.new_line(\n",
    "            mdFile.new_inline_image(\n",
    "                text=\"Metrics\", path=os.path.join(img_folder, \"metrics.png\")\n",
    "            )\n",
    "        )\n",
    "    mdFile.new_line(\n",
    "        mdFile.new_inline_image(\n",
    "            text=\"Word Frequencies\",\n",
    "            path=os.path.join(img_folder, \"word_frequencies.png\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mdFile.create_md_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ed80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-d\", \"--dataset_path\", help=\"Path to the dataset.\", type=\"str\")\n",
    "    parser.add_argument(\n",
    "        \"-i\", \"--input_file\", help=\"Path to the transcription file.\", type=\"str\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output_file\",\n",
    "        help=\"Markdown file to write statistics to.\",\n",
    "        type=\"str\",\n",
    "        default=\"STATISTICS\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--metrics\",\n",
    "        help=\"Boolean value to calculate SRMR and MOSNet.\",\n",
    "        default=True,\n",
    "        type=bool,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--img_folder\",\n",
    "        help=\"Folder to save plots and images.\",\n",
    "        type=\"str\",\n",
    "        default=\"stats\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--delimiter\", help=\"Transcription file delimiter.\", type=\"str\", default=\"|\"\n",
    "    )\n",
    "\n",
    "    return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5eb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(\n",
    "    dataset_path, input_file, output_file, img_folder, delimiter, metrics, wordcloud\n",
    "):\n",
    "    os.makedirs(os.path.join(dataset_path, img_folder), exist_ok=True)\n",
    "    data = calculate_statistics(\n",
    "        dataset_path, input_file, img_folder, delimiter, metrics, wordcloud\n",
    "    )\n",
    "    generate_markdown(output_file, dataset_path, img_folder, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "    dataset_path=\"/home/ubuntu/dataset_description/data/eminem\",\n",
    "    input_file=\"all.txt\",\n",
    "    output_file=\"STATISTICS.md\",\n",
    "    img_folder=\"imgs\",\n",
    "    delimiter=\"|\",\n",
    "    metrics=False,\n",
    "    wordcloud=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e79961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "\n",
    "# try:\n",
    "#     from nbdev.imports import IN_NOTEBOOK\n",
    "# except:\n",
    "#     IN_NOTEBOOK = False\n",
    "\n",
    "# if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "#     args = parse_args(sys.argv[1:])\n",
    "#     run(\n",
    "#         args.dataset_path,\n",
    "#         args.input_file,\n",
    "#         args.output_file,\n",
    "#         args.metrics,\n",
    "#         args.img_folder,\n",
    "#         args.delimiter,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62d8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
