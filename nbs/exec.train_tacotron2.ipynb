{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d096a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exec.train_tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96fa8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.trainer.tacotron2 import Tacotron2Trainer\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.trainer.tacotron2 import DEFAULTS as TACOTRON2_TRAINER_DEFAULTS\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7bf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", help=\"Path to JSON config\")\n",
    "    args = parser.parse_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def run(rank, device_count, hparams):\n",
    "    trainer = Tacotron2Trainer(hparams, rank=rank, world_size=device_count)\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except Exception as e:\n",
    "        print(f\"Exception raised while training: {e}\")\n",
    "        # TODO: save state.\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8862336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uberduck_ml_dev.models.tacotron2.tacotron2 import (\n",
    "    NON_ATTENTIVE_DEFAULTS as NON_ATTENTIVE_DEFAULTS,\n",
    ")\n",
    "\n",
    "NON_ATTENTIVE_DEFAULTS.decoder_rnn_dim_nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19435337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('attention_dim', 128), ('attention_location_kernel_size', 31), ('attention_location_n_filters', 32), ('attention_rnn_dim', 1024), ('batch_size', 16), ('checkpoint_name', None), ('checkpoint_path', 'test/fixtures/results/checkpoints'), ('coarse_n_frames_per_step', None), ('compute_durations', True), ('cudnn_enabled', True), ('dataset_path', './dataset'), ('debug', False), ('decoder_rnn_dim', 1024), ('decoder_rnn_dim_nlayers', 2), ('distributed_run', False), ('duration_lstm_dim', 1024), ('encoder_embedding_dim', 512), ('encoder_kernel_size', 5), ('encoder_n_convolutions', 3), ('epochs', 5), ('epochs_per_checkpoint', 4), ('filter_length', 1024), ('fp16_run', False), ('gate_threshold', 0.5), ('grad_clip_thresh', 1.0), ('gst_type', None), ('has_speaker_embedding', False), ('hop_length', 256), ('ignore_layers', ['speaker_embedding.weight', 'decoder.attention_rnn.weight_ih', 'decoder.attention_rnn.weight_hh', 'decoder.attention_rnn.bias_ih', 'decoder.attention_rnn.bias_hh', 'decoder.attention_layer.query_layer.linear_layer.weight', 'decoder.attention_layer.memory_layer.linear_layer.weight', 'decoder.attention_layer.v.linear_layer.weight', 'decoder.attention_layer.location_layer.location_conv.conv.weight', 'decoder.attention_layer.location_layer.location_dense.linear_layer.weight', 'decoder.decoder_rnn.weight_ih', 'decoder.decoder_rnn.weight_hh', 'decoder.decoder_rnn.bias_ih', 'decoder.decoder_rnn.bias_hh', 'decoder.linear_projection.linear_layer.weight']), ('include_durations', True), ('include_f0', False), ('learning_rate', 0.001), ('location_specific_attention', False), ('log_dir', 'test/fixtures/results/logs'), ('mask_padding', True), ('max_decoder_steps', 1000), ('max_wav_value', 32768.0), ('mel_fmax', 8000), ('mel_fmin', 0), ('n_frames_per_step_initial', 1), ('n_mel_channels', 80), ('n_speakers', 1), ('n_symbols', 148), ('non_attentive', True), ('num_heads', 8), ('p_arpabet', 1.0), ('p_attention_dropout', 0.1), ('p_decoder_dropout', 0.1), ('p_teacher_forcing', 1.0), ('pos_weight', None), ('positional_embedding_dim', 32), ('postnet_embedding_dim', 512), ('postnet_kernel_size', 5), ('postnet_n_convolutions', 5), ('prenet_dim', 256), ('prenet_f0_dim', 1), ('prenet_f0_kernel_size', 1), ('prenet_f0_n_layers', 1), ('prenet_fms_kernel_size', 1), ('prenet_rms_dim', 0), ('range_lstm_dim', 1024), ('reduction_window_schedule', [{'until_step': 10000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 50000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 60000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 70000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': None, 'batch_size': 16, 'n_frames_per_step': 1}]), ('ref_enc_filters', [32, 32, 64, 64, 128, 128]), ('ref_enc_gru_size', 128), ('ref_enc_pad', [1, 1]), ('ref_enc_size', [3, 3]), ('ref_enc_strides', [2, 2]), ('sample_inference_speaker_ids', [0]), ('sample_inference_text', 'That quick beige fox jumped in the air loudly over the thin dog fence.'), ('sampling_rate', 22050), ('seed', 1234), ('speaker_embedding_dim', 1), ('steps_per_sample', 100), ('symbol_set', 'nvidia_taco2'), ('symbols_embedding_dim', 512), ('text_cleaners', ['english_cleaners']), ('torchmoji_model_file', None), ('torchmoji_vocabulary_file', None), ('training_audiopaths_and_text', 'test/fixtures/ljtest/list.txt'), ('val_audiopaths_and_text', 'test/fixtures/ljtest/list.txt'), ('warm_start_name', 'test/fixtures/models/taco2ljdefault'), ('weight_decay', 1e-06), ('win_length', 1024), ('with_gst', False)]\n",
      "TTSTrainer start 27685.58735274\n",
      "Initializing trainer with hparams:\n",
      "{'attention_dim': 128,\n",
      " 'attention_location_kernel_size': 31,\n",
      " 'attention_location_n_filters': 32,\n",
      " 'attention_rnn_dim': 1024,\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_name': None,\n",
      " 'checkpoint_path': 'test/fixtures/results/checkpoints',\n",
      " 'coarse_n_frames_per_step': None,\n",
      " 'compute_durations': True,\n",
      " 'cudnn_enabled': True,\n",
      " 'dataset_path': './dataset',\n",
      " 'debug': False,\n",
      " 'decoder_rnn_dim': 1024,\n",
      " 'decoder_rnn_dim_nlayers': 2,\n",
      " 'distributed_run': False,\n",
      " 'duration_lstm_dim': 1024,\n",
      " 'encoder_embedding_dim': 512,\n",
      " 'encoder_kernel_size': 5,\n",
      " 'encoder_n_convolutions': 3,\n",
      " 'epochs': 5,\n",
      " 'epochs_per_checkpoint': 4,\n",
      " 'filter_length': 1024,\n",
      " 'fp16_run': False,\n",
      " 'gate_threshold': 0.5,\n",
      " 'grad_clip_thresh': 1.0,\n",
      " 'gst_type': None,\n",
      " 'has_speaker_embedding': False,\n",
      " 'hop_length': 256,\n",
      " 'ignore_layers': ['speaker_embedding.weight',\n",
      "                   'decoder.attention_rnn.weight_ih',\n",
      "                   'decoder.attention_rnn.weight_hh',\n",
      "                   'decoder.attention_rnn.bias_ih',\n",
      "                   'decoder.attention_rnn.bias_hh',\n",
      "                   'decoder.attention_layer.query_layer.linear_layer.weight',\n",
      "                   'decoder.attention_layer.memory_layer.linear_layer.weight',\n",
      "                   'decoder.attention_layer.v.linear_layer.weight',\n",
      "                   'decoder.attention_layer.location_layer.location_conv.conv.weight',\n",
      "                   'decoder.attention_layer.location_layer.location_dense.linear_layer.weight',\n",
      "                   'decoder.decoder_rnn.weight_ih',\n",
      "                   'decoder.decoder_rnn.weight_hh',\n",
      "                   'decoder.decoder_rnn.bias_ih',\n",
      "                   'decoder.decoder_rnn.bias_hh',\n",
      "                   'decoder.linear_projection.linear_layer.weight'],\n",
      " 'include_durations': True,\n",
      " 'include_f0': False,\n",
      " 'learning_rate': 0.001,\n",
      " 'location_specific_attention': False,\n",
      " 'log_dir': 'test/fixtures/results/logs',\n",
      " 'mask_padding': True,\n",
      " 'max_decoder_steps': 1000,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0,\n",
      " 'n_frames_per_step_initial': 1,\n",
      " 'n_mel_channels': 80,\n",
      " 'n_speakers': 1,\n",
      " 'n_symbols': 148,\n",
      " 'non_attentive': True,\n",
      " 'num_heads': 8,\n",
      " 'p_arpabet': 1.0,\n",
      " 'p_attention_dropout': 0.1,\n",
      " 'p_decoder_dropout': 0.1,\n",
      " 'p_teacher_forcing': 1.0,\n",
      " 'pos_weight': None,\n",
      " 'positional_embedding_dim': 32,\n",
      " 'postnet_embedding_dim': 512,\n",
      " 'postnet_kernel_size': 5,\n",
      " 'postnet_n_convolutions': 5,\n",
      " 'prenet_dim': 256,\n",
      " 'prenet_f0_dim': 1,\n",
      " 'prenet_f0_kernel_size': 1,\n",
      " 'prenet_f0_n_layers': 1,\n",
      " 'prenet_fms_kernel_size': 1,\n",
      " 'prenet_rms_dim': 0,\n",
      " 'range_lstm_dim': 1024,\n",
      " 'reduction_window_schedule': [{'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 10000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 50000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 60000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 70000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': None}],\n",
      " 'ref_enc_filters': [32, 32, 64, 64, 128, 128],\n",
      " 'ref_enc_gru_size': 128,\n",
      " 'ref_enc_pad': [1, 1],\n",
      " 'ref_enc_size': [3, 3],\n",
      " 'ref_enc_strides': [2, 2],\n",
      " 'sample_inference_speaker_ids': [0],\n",
      " 'sample_inference_text': 'That quick beige fox jumped in the air loudly over '\n",
      "                          'the thin dog fence.',\n",
      " 'sampling_rate': 22050,\n",
      " 'seed': 1234,\n",
      " 'speaker_embedding_dim': 1,\n",
      " 'steps_per_sample': 100,\n",
      " 'symbol_set': 'nvidia_taco2',\n",
      " 'symbols_embedding_dim': 512,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'torchmoji_model_file': None,\n",
      " 'torchmoji_vocabulary_file': None,\n",
      " 'training_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'val_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'warm_start_name': 'test/fixtures/models/taco2ljdefault',\n",
      " 'weight_decay': 1e-06,\n",
      " 'win_length': 1024,\n",
      " 'with_gst': False}\n",
      "start train 27685.64048247\n",
      "[NeMo I 2022-02-22 06:53:55 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 06:53:55 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 06:53:55 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 06:53:55 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:53:55 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 06:53:55 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 06:53:59 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 06:53:59 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fbc478de730>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:54:00 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 06:54:00 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 06:54:00 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 06:54:00 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:54:00 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 06:54:00 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 06:54:01 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 06:54:01 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fbc3d1742b0>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "config = NON_ATTENTIVE_DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "config[\"speaker_embedding_dim\"] = 1\n",
    "config[\"decoder_rnn_dim_nlayers\"] = 2\n",
    "config[\"ignore_layers\"] = [\n",
    "    \"speaker_embedding.weight\",\n",
    "    \"decoder.attention_rnn.weight_ih\",\n",
    "    \"decoder.attention_rnn.weight_hh\",\n",
    "    \"decoder.attention_rnn.bias_ih\",\n",
    "    \"decoder.attention_rnn.bias_hh\",\n",
    "    \"decoder.attention_layer.query_layer.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.memory_layer.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.v.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.location_layer.location_conv.conv.weight\",\n",
    "    \"decoder.attention_layer.location_layer.location_dense.linear_layer.weight\",\n",
    "    \"decoder.decoder_rnn.weight_ih\",\n",
    "    \"decoder.decoder_rnn.weight_hh\",\n",
    "    \"decoder.decoder_rnn.bias_ih\",\n",
    "    \"decoder.decoder_rnn.bias_hh\",\n",
    "    \"decoder.linear_projection.linear_layer.weight\",\n",
    "]\n",
    "hparams = HParams(**config)\n",
    "\n",
    "print(hparams)\n",
    "if hparams.distributed_run:\n",
    "    device_count = torch.cuda.device_count()\n",
    "    mp.spawn(run, (device_count, hparams), device_count)\n",
    "else:\n",
    "    run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33313def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('attention_dim', 128), ('attention_location_kernel_size', 31), ('attention_location_n_filters', 32), ('attention_rnn_dim', 1024), ('batch_size', 16), ('checkpoint_name', None), ('checkpoint_path', 'test/fixtures/results/checkpoints'), ('coarse_n_frames_per_step', None), ('compute_durations', False), ('cudnn_enabled', True), ('dataset_path', './dataset'), ('debug', False), ('decay_rate', 8000), ('decay_start', 15000), ('decoder_rnn_dim', 1024), ('distributed_run', False), ('encoder_embedding_dim', 512), ('encoder_kernel_size', 5), ('encoder_n_convolutions', 3), ('epochs', 5), ('epochs_per_checkpoint', 4), ('filter_length', 1024), ('fp16_run', False), ('gate_threshold', 0.5), ('grad_clip_thresh', 1.0), ('gst_type', None), ('has_speaker_embedding', False), ('hop_length', 256), ('ignore_layers', ['speaker_embedding.weight']), ('include_durations', False), ('include_f0', False), ('learning_rate', 0.001), ('location_specific_attention', True), ('log_dir', 'test/fixtures/results/logs'), ('mask_padding', True), ('max_decoder_steps', 1000), ('max_wav_value', 32768.0), ('mel_fmax', 8000), ('mel_fmin', 0), ('n_frames_per_step_initial', 1), ('n_mel_channels', 80), ('n_speakers', 1), ('n_symbols', 148), ('non_attentive', False), ('num_heads', 8), ('p_arpabet', 1.0), ('p_attention_dropout', 0.1), ('p_decoder_dropout', 0.1), ('p_teacher_forcing', 1.0), ('pos_weight', None), ('postnet_embedding_dim', 512), ('postnet_kernel_size', 5), ('postnet_n_convolutions', 5), ('prenet_dim', 256), ('prenet_f0_dim', 1), ('prenet_f0_kernel_size', 1), ('prenet_f0_n_layers', 1), ('prenet_fms_kernel_size', 1), ('prenet_rms_dim', 0), ('reduction_window_schedule', [{'until_step': 10000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 50000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 60000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 70000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': None, 'batch_size': 16, 'n_frames_per_step': 1}]), ('ref_enc_filters', [32, 32, 64, 64, 128, 128]), ('ref_enc_gru_size', 128), ('ref_enc_pad', [1, 1]), ('ref_enc_size', [3, 3]), ('ref_enc_strides', [2, 2]), ('sample_inference_speaker_ids', [0]), ('sample_inference_text', 'That quick beige fox jumped in the air loudly over the thin dog fence.'), ('sampling_rate', 22050), ('seed', 1234), ('speaker_embedding_dim', 128), ('steps_per_sample', 100), ('symbol_set', 'nvidia_taco2'), ('symbols_embedding_dim', 512), ('text_cleaners', ['english_cleaners']), ('torchmoji_model_file', None), ('torchmoji_vocabulary_file', None), ('training_audiopaths_and_text', 'test/fixtures/ljtest/list.txt'), ('val_audiopaths_and_text', 'test/fixtures/ljtest/list.txt'), ('warm_start_name', 'test/fixtures/models/taco2ljdefault'), ('weight_decay', 1e-06), ('win_length', 1024), ('with_gst', False)]\n",
      "TTSTrainer start 27717.689341057\n",
      "Initializing trainer with hparams:\n",
      "{'attention_dim': 128,\n",
      " 'attention_location_kernel_size': 31,\n",
      " 'attention_location_n_filters': 32,\n",
      " 'attention_rnn_dim': 1024,\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_name': None,\n",
      " 'checkpoint_path': 'test/fixtures/results/checkpoints',\n",
      " 'coarse_n_frames_per_step': None,\n",
      " 'compute_durations': False,\n",
      " 'cudnn_enabled': True,\n",
      " 'dataset_path': './dataset',\n",
      " 'debug': False,\n",
      " 'decay_rate': 8000,\n",
      " 'decay_start': 15000,\n",
      " 'decoder_rnn_dim': 1024,\n",
      " 'distributed_run': False,\n",
      " 'encoder_embedding_dim': 512,\n",
      " 'encoder_kernel_size': 5,\n",
      " 'encoder_n_convolutions': 3,\n",
      " 'epochs': 5,\n",
      " 'epochs_per_checkpoint': 4,\n",
      " 'filter_length': 1024,\n",
      " 'fp16_run': False,\n",
      " 'gate_threshold': 0.5,\n",
      " 'grad_clip_thresh': 1.0,\n",
      " 'gst_type': None,\n",
      " 'has_speaker_embedding': False,\n",
      " 'hop_length': 256,\n",
      " 'ignore_layers': ['speaker_embedding.weight'],\n",
      " 'include_durations': False,\n",
      " 'include_f0': False,\n",
      " 'learning_rate': 0.001,\n",
      " 'location_specific_attention': True,\n",
      " 'log_dir': 'test/fixtures/results/logs',\n",
      " 'mask_padding': True,\n",
      " 'max_decoder_steps': 1000,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0,\n",
      " 'n_frames_per_step_initial': 1,\n",
      " 'n_mel_channels': 80,\n",
      " 'n_speakers': 1,\n",
      " 'n_symbols': 148,\n",
      " 'non_attentive': False,\n",
      " 'num_heads': 8,\n",
      " 'p_arpabet': 1.0,\n",
      " 'p_attention_dropout': 0.1,\n",
      " 'p_decoder_dropout': 0.1,\n",
      " 'p_teacher_forcing': 1.0,\n",
      " 'pos_weight': None,\n",
      " 'postnet_embedding_dim': 512,\n",
      " 'postnet_kernel_size': 5,\n",
      " 'postnet_n_convolutions': 5,\n",
      " 'prenet_dim': 256,\n",
      " 'prenet_f0_dim': 1,\n",
      " 'prenet_f0_kernel_size': 1,\n",
      " 'prenet_f0_n_layers': 1,\n",
      " 'prenet_fms_kernel_size': 1,\n",
      " 'prenet_rms_dim': 0,\n",
      " 'reduction_window_schedule': [{'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 10000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 50000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 60000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 70000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': None}],\n",
      " 'ref_enc_filters': [32, 32, 64, 64, 128, 128],\n",
      " 'ref_enc_gru_size': 128,\n",
      " 'ref_enc_pad': [1, 1],\n",
      " 'ref_enc_size': [3, 3],\n",
      " 'ref_enc_strides': [2, 2],\n",
      " 'sample_inference_speaker_ids': [0],\n",
      " 'sample_inference_text': 'That quick beige fox jumped in the air loudly over '\n",
      "                          'the thin dog fence.',\n",
      " 'sampling_rate': 22050,\n",
      " 'seed': 1234,\n",
      " 'speaker_embedding_dim': 128,\n",
      " 'steps_per_sample': 100,\n",
      " 'symbol_set': 'nvidia_taco2',\n",
      " 'symbols_embedding_dim': 512,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'torchmoji_model_file': None,\n",
      " 'torchmoji_vocabulary_file': None,\n",
      " 'training_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'val_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'warm_start_name': 'test/fixtures/models/taco2ljdefault',\n",
      " 'weight_decay': 1e-06,\n",
      " 'win_length': 1024,\n",
      " 'with_gst': False}\n",
      "start train 27717.707580156\n",
      "[NeMo I 2022-02-22 06:54:27 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 06:54:27 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 06:54:27 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 06:54:27 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:54:27 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 06:54:27 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 06:54:28 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 06:54:28 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fbc3c1e0b20>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:54:28 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 06:54:28 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 06:54:28 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 06:54:29 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 06:54:29 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 06:54:29 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 06:54:29 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 06:54:29 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fbc3c021ee0>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using any style tokens\n",
      "Starting warm_start 27720.967232332\n",
      "Ending warm_start 27721.03247772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 06:54:31 nemo_logging:349] /opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "      warnings.warn(warning.format(ret))\n",
      "    \n",
      "[NeMo W 2022-02-22 06:54:33 nemo_logging:349] /mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/trainer/tacotron2.py:545: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "      grad_norm = torch.nn.utils.clip_grad_norm(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/5 | batch: 0/1 | loss: 0.84 | mel: 1.74 | gate: 0.899 | t: 0.40s | w: 0.00h\n",
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     mp\u001b[38;5;241m.\u001b[39mspawn(run, (device_count, hparams), device_count)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(rank, device_count, hparams)\u001b[0m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Tacotron2Trainer(hparams, rank\u001b[38;5;241m=\u001b[39mrank, world_size\u001b[38;5;241m=\u001b[39mdevice_count)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised while training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/trainer/tacotron2.py:544\u001b[0m, in \u001b[0;36mTacotron2Trainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 544\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm(\n\u001b[1;32m    546\u001b[0m         model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip_thresh\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# skip\n",
    "config = TACOTRON2_TRAINER_DEFAULTS.values()\n",
    "config['batch_size'] = 4\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "print(hparams)\n",
    "if hparams.distributed_run:\n",
    "    device_count = torch.cuda.device_count()\n",
    "    mp.spawn(run, (device_count, hparams), device_count)\n",
    "else:\n",
    "    run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cadc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/envs/uberduck/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 2 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams\u001b[38;5;241m.\u001b[39mdistributed_run:\n\u001b[1;32m      9\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     run(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, hparams)\n",
      "File \u001b[0;32m/opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:230\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    229\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:188\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:139\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    132\u001b[0m             (error_index, name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    141\u001b[0m             (error_index, exitcode),\n\u001b[1;32m    142\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    143\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    144\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode\n\u001b[1;32m    145\u001b[0m         )\n\u001b[1;32m    147\u001b[0m original_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_queues[error_index]\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    148\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 2 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "config = TACOTRON2_TRAINER_DEFAULTS.values()\n",
    "config['batch_size'] = 4\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "config['distributed_run'] = True\n",
    "hparams = HParams(**config)\n",
    "if hparams.distributed_run:\n",
    "    device_count = torch.cuda.device_count()\n",
    "    mp.spawn(run, (device_count, hparams), device_count)\n",
    "else:\n",
    "    run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "try:\n",
    "    from nbdev.imports import IN_NOTEBOOK\n",
    "except:\n",
    "    IN_NOTEBOOK = False\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    args = parse_args(sys.argv[1:])\n",
    "    config = TACOTRON2_TRAINER_DEFAULTS.values()\n",
    "    config['distributed_run'] = True\n",
    "    if args.config:\n",
    "        with open(args.config) as f:\n",
    "            config.update(json.load(f))\n",
    "    config.update(vars(args))\n",
    "    hparams = HParams(**config)\n",
    "    if hparams.distributed_run:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        mp.spawn(run, (device_count, hparams), device_count)\n",
    "    else:\n",
    "        run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b80d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTSTrainer start 23580.806363276\n",
      "Initializing trainer with hparams:\n",
      "{'attention_dim': 128,\n",
      " 'attention_location_kernel_size': 31,\n",
      " 'attention_location_n_filters': 32,\n",
      " 'attention_rnn_dim': 1024,\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_name': None,\n",
      " 'checkpoint_path': 'test/fixtures/results/checkpoints',\n",
      " 'coarse_n_frames_per_step': None,\n",
      " 'compute_durations': False,\n",
      " 'cudnn_enabled': True,\n",
      " 'dataset_path': './dataset',\n",
      " 'debug': False,\n",
      " 'decay_rate': 8000,\n",
      " 'decay_start': 15000,\n",
      " 'decoder_rnn_dim': 1024,\n",
      " 'distributed_run': False,\n",
      " 'encoder_embedding_dim': 512,\n",
      " 'encoder_kernel_size': 5,\n",
      " 'encoder_n_convolutions': 3,\n",
      " 'epochs': 5,\n",
      " 'epochs_per_checkpoint': 4,\n",
      " 'filter_length': 1024,\n",
      " 'fp16_run': False,\n",
      " 'gate_threshold': 0.5,\n",
      " 'grad_clip_thresh': 1.0,\n",
      " 'gst_type': None,\n",
      " 'has_speaker_embedding': False,\n",
      " 'hop_length': 256,\n",
      " 'ignore_layers': ['speaker_embedding.weight'],\n",
      " 'include_durations': False,\n",
      " 'include_f0': False,\n",
      " 'learning_rate': 0.001,\n",
      " 'location_specific_attention': True,\n",
      " 'log_dir': 'test/fixtures/results/logs',\n",
      " 'mask_padding': True,\n",
      " 'max_decoder_steps': 1000,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0,\n",
      " 'n_frames_per_step_initial': 1,\n",
      " 'n_mel_channels': 80,\n",
      " 'n_speakers': 1,\n",
      " 'n_symbols': 148,\n",
      " 'non_attentive': False,\n",
      " 'num_heads': 8,\n",
      " 'p_arpabet': 1.0,\n",
      " 'p_attention_dropout': 0.1,\n",
      " 'p_decoder_dropout': 0.1,\n",
      " 'p_teacher_forcing': 1.0,\n",
      " 'pos_weight': None,\n",
      " 'postnet_embedding_dim': 512,\n",
      " 'postnet_kernel_size': 5,\n",
      " 'postnet_n_convolutions': 5,\n",
      " 'prenet_dim': 256,\n",
      " 'prenet_f0_dim': 1,\n",
      " 'prenet_f0_kernel_size': 1,\n",
      " 'prenet_f0_n_layers': 1,\n",
      " 'prenet_fms_kernel_size': 1,\n",
      " 'prenet_rms_dim': 0,\n",
      " 'reduction_window_schedule': [{'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 10000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 50000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 60000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 70000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': None}],\n",
      " 'ref_enc_filters': [32, 32, 64, 64, 128, 128],\n",
      " 'ref_enc_gru_size': 128,\n",
      " 'ref_enc_pad': [1, 1],\n",
      " 'ref_enc_size': [3, 3],\n",
      " 'ref_enc_strides': [2, 2],\n",
      " 'sample_inference_speaker_ids': [0],\n",
      " 'sample_inference_text': 'That quick beige fox jumped in the air loudly over '\n",
      "                          'the thin dog fence.',\n",
      " 'sampling_rate': 22050,\n",
      " 'seed': 1234,\n",
      " 'speaker_embedding_dim': 128,\n",
      " 'steps_per_sample': 100,\n",
      " 'symbol_set': 'nvidia_taco2',\n",
      " 'symbols_embedding_dim': 512,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'torchmoji_model_file': None,\n",
      " 'torchmoji_vocabulary_file': None,\n",
      " 'training_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'val_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'warm_start_name': 'test/fixtures/models/taco2ljdefault',\n",
      " 'weight_decay': 1e-06,\n",
      " 'win_length': 1024,\n",
      " 'with_gst': False}\n",
      "start train 23580.861048527\n",
      "[NeMo I 2022-02-22 05:45:30 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 05:45:30 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 05:45:30 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 05:45:30 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:45:30 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 05:45:30 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 05:45:34 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 05:45:34 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7f5c2b6b9d00>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:45:34 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 05:45:34 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 05:45:34 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 05:45:35 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:45:35 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 05:45:35 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 05:45:35 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 05:45:35 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7f5c20f66670>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using any style tokens\n",
      "Starting warm_start 23587.086845543\n",
      "Ending warm_start 23587.150656177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 05:45:37 nemo_logging:349] /opt/conda/envs/uberduck/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "      warnings.warn(warning.format(ret))\n",
      "    \n",
      "[NeMo W 2022-02-22 05:45:39 nemo_logging:349] /mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/trainer/tacotron2.py:545: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "      grad_norm = torch.nn.utils.clip_grad_norm(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/5 | batch: 0/1 | loss: 0.84 | mel: 1.74 | gate: 0.899 | t: 0.38s | w: 0.00h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 1/5 | batch: 0/1 | loss: 4.20 | mel: 5.09 | gate: 0.899 | t: 9.23s | w: 0.01h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 2/5 | batch: 0/1 | loss: 1.22 | mel: 2.12 | gate: 0.899 | t: 6.43s | w: 0.01h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 3/5 | batch: 0/1 | loss: 1.48 | mel: 2.38 | gate: 0.899 | t: 6.20s | w: 0.01h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 4/5 | batch: 0/1 | loss: 1.15 | mel: 2.05 | gate: 0.899 | t: 6.18s | w: 0.01h\n",
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    }
   ],
   "source": [
    "config = TACOTRON2_TRAINER_DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "\n",
    "rank = None\n",
    "device_count = None\n",
    "trainer = Tacotron2Trainer(hparams, rank=rank, world_size=device_count)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8223947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTSTrainer start 23132.803585774\n",
      "Initializing trainer with hparams:\n",
      "{'attention_dim': 128,\n",
      " 'attention_location_kernel_size': 31,\n",
      " 'attention_location_n_filters': 32,\n",
      " 'attention_rnn_dim': 1024,\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_name': None,\n",
      " 'checkpoint_path': 'test/fixtures/results/checkpoints',\n",
      " 'coarse_n_frames_per_step': None,\n",
      " 'compute_durations': True,\n",
      " 'cudnn_enabled': True,\n",
      " 'dataset_path': './dataset',\n",
      " 'debug': False,\n",
      " 'decoder_rnn_dim': 1024,\n",
      " 'decoder_rnn_dim_nlayers': 2,\n",
      " 'distributed_run': False,\n",
      " 'duration_lstm_dim': 1024,\n",
      " 'encoder_embedding_dim': 512,\n",
      " 'encoder_kernel_size': 5,\n",
      " 'encoder_n_convolutions': 3,\n",
      " 'epochs': 5,\n",
      " 'epochs_per_checkpoint': 4,\n",
      " 'filter_length': 1024,\n",
      " 'fp16_run': False,\n",
      " 'gate_threshold': 0.5,\n",
      " 'grad_clip_thresh': 1.0,\n",
      " 'gst_type': None,\n",
      " 'has_speaker_embedding': False,\n",
      " 'hop_length': 256,\n",
      " 'ignore_layers': ['speaker_embedding.weight',\n",
      "                   'decoder.attention_rnn.weight_ih',\n",
      "                   'decoder.attention_rnn.weight_hh',\n",
      "                   'decoder.attention_rnn.bias_ih',\n",
      "                   'decoder.attention_rnn.bias_hh',\n",
      "                   'decoder.attention_layer.query_layer.linear_layer.weight',\n",
      "                   'decoder.attention_layer.memory_layer.linear_layer.weight',\n",
      "                   'decoder.attention_layer.v.linear_layer.weight',\n",
      "                   'decoder.attention_layer.location_layer.location_conv.conv.weight',\n",
      "                   'decoder.attention_layer.location_layer.location_dense.linear_layer.weight',\n",
      "                   'decoder.decoder_rnn.weight_ih',\n",
      "                   'decoder.decoder_rnn.weight_hh',\n",
      "                   'decoder.decoder_rnn.bias_ih',\n",
      "                   'decoder.decoder_rnn.bias_hh',\n",
      "                   'decoder.linear_projection.linear_layer.weight'],\n",
      " 'include_durations': True,\n",
      " 'include_f0': False,\n",
      " 'learning_rate': 0.001,\n",
      " 'location_specific_attention': False,\n",
      " 'log_dir': 'test/fixtures/results/logs',\n",
      " 'mask_padding': True,\n",
      " 'max_decoder_steps': 1000,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0,\n",
      " 'n_frames_per_step_initial': 1,\n",
      " 'n_mel_channels': 80,\n",
      " 'n_speakers': 1,\n",
      " 'n_symbols': 148,\n",
      " 'non_attentive': True,\n",
      " 'num_heads': 8,\n",
      " 'p_arpabet': 1.0,\n",
      " 'p_attention_dropout': 0.1,\n",
      " 'p_decoder_dropout': 0.1,\n",
      " 'p_teacher_forcing': 1.0,\n",
      " 'pos_weight': None,\n",
      " 'positional_embedding_dim': 32,\n",
      " 'postnet_embedding_dim': 512,\n",
      " 'postnet_kernel_size': 5,\n",
      " 'postnet_n_convolutions': 5,\n",
      " 'prenet_dim': 256,\n",
      " 'prenet_f0_dim': 1,\n",
      " 'prenet_f0_kernel_size': 1,\n",
      " 'prenet_f0_n_layers': 1,\n",
      " 'prenet_fms_kernel_size': 1,\n",
      " 'prenet_rms_dim': 0,\n",
      " 'range_lstm_dim': 1024,\n",
      " 'reduction_window_schedule': [{'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 10000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 50000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 60000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 70000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': None}],\n",
      " 'ref_enc_filters': [32, 32, 64, 64, 128, 128],\n",
      " 'ref_enc_gru_size': 128,\n",
      " 'ref_enc_pad': [1, 1],\n",
      " 'ref_enc_size': [3, 3],\n",
      " 'ref_enc_strides': [2, 2],\n",
      " 'sample_inference_speaker_ids': [0],\n",
      " 'sample_inference_text': 'That quick beige fox jumped in the air loudly over '\n",
      "                          'the thin dog fence.',\n",
      " 'sampling_rate': 22050,\n",
      " 'seed': 1234,\n",
      " 'speaker_embedding_dim': 1,\n",
      " 'steps_per_sample': 100,\n",
      " 'symbol_set': 'nvidia_taco2',\n",
      " 'symbols_embedding_dim': 512,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'torchmoji_model_file': None,\n",
      " 'torchmoji_vocabulary_file': None,\n",
      " 'training_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'val_audiopaths_and_text': 'test/fixtures/ljtest/list.txt',\n",
      " 'warm_start_name': 'test/fixtures/models/taco2ljdefault',\n",
      " 'weight_decay': 1e-06,\n",
      " 'win_length': 1024,\n",
      " 'with_gst': False}\n",
      "start train 23132.825296525\n",
      "[NeMo I 2022-02-22 05:38:02 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 05:38:02 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 05:38:02 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 05:38:02 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:38:02 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 05:38:02 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 05:38:03 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 05:38:03 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fd9885581c0>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:38:03 cloud:56] Found existing object /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n",
      "[NeMo I 2022-02-22 05:38:03 cloud:62] Re-using file from: /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo\n",
      "[NeMo I 2022-02-22 05:38:03 common:704] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-02-22 05:38:04 features:232] Using torch_stft is deprecated and will be removed in 1.1.0. Please set stft_conv and stft_exact_pad to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-02-22 05:38:04 features:255] PADDING: 1\n",
      "[NeMo I 2022-02-22 05:38:04 features:265] STFT using conv\n",
      "[NeMo I 2022-02-22 05:38:04 save_restore_connector:157] Model EncDecCTCModel was successfully restored from /home/s_uberduck_ai/.cache/torch/NeMo/NeMo_1.7.0rc0/qn5x5_libri_tts_phonemes/656c7439dd3a0d614978529371be498b/qn5x5_libri_tts_phonemes.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2022-02-22 05:38:04 vocabs:324] Torch distributed needs to be initialized before you initialized <nemo.collections.common.data.vocabs.Phonemes object at 0x7fd988316670>. This class is prone to data access race conditions. Now downloading corpora from global rank 0. If other ranks pass this before rank 0, errors might result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using any style tokens\n",
      "Starting warm_start 23136.399235868\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.linear_projection.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.positional_embedding.pe layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "Ending warm_start 23136.469738425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/5 | batch: 0/1 | loss: 41.55 | mel: 62.12 | t: 16.05s | w: 0.01h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 1/5 | batch: 0/1 | loss: 32.81 | mel: 53.09 | t: 40.19s | w: 0.02h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 2/5 | batch: 0/1 | loss: 14.77 | mel: 35.00 | t: 34.39s | w: 0.03h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 3/5 | batch: 0/1 | loss: 7.41 | mel: 27.54 | t: 34.51s | w: 0.04h\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "epoch: 4/5 | batch: 0/1 | loss: 5.20 | mel: 25.32 | t: 34.40s | w: 0.05h\n",
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    }
   ],
   "source": [
    "rank = None\n",
    "device_count = None\n",
    "trainer = Tacotron2Trainer(hparams, rank=rank, world_size=device_count)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea8d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uberduck",
   "language": "python",
   "name": "uberduck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
