{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd67b94",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Example:-partial-teacher-forcing\" data-toc-modified-id=\"Example:-partial-teacher-forcing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Example: partial teacher forcing</a></span></li><li><span><a href=\"#Example:-attention-guided-rhythm-transfer\" data-toc-modified-id=\"Example:-attention-guided-rhythm-transfer-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Example: attention-guided rhythm transfer</a></span></li><li><span><a href=\"#Example:-has_speaker_embedding\" data-toc-modified-id=\"Example:-has_speaker_embedding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Example: has_speaker_embedding</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e7a06",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.tacotron2.tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df468e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pdb\n",
    "from torch import nn\n",
    "from uberduck_ml_dev.models.base import TTSModel\n",
    "from uberduck_ml_dev.models.common import Attention, Conv1d, LinearNorm, GST\n",
    "from uberduck_ml_dev.text.symbols import symbols\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.utils.utils import to_gpu, get_mask_from_lengths\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.nn import functional as F\n",
    "from uberduck_ml_dev.utils.duration import (\n",
    "    GaussianUpsampling,\n",
    "    RangePredictor,\n",
    "    PositionalEncoding,\n",
    "    DurationPredictor,\n",
    ")\n",
    "from uberduck_ml_dev.models.tacotron2.decoder import Decoder\n",
    "from uberduck_ml_dev.models.tacotron2.encoder import Encoder\n",
    "from uberduck_ml_dev.models.tacotron2.prenet import Prenet\n",
    "from uberduck_ml_dev.models.tacotron2.postnet import Postnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.data.batch import Batch\n",
    "\n",
    "\n",
    "class Tacotron2(TTSModel):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "\n",
    "        self.mask_padding = hparams.mask_padding\n",
    "        self.fp16_run = hparams.fp16_run\n",
    "        self.pos_weight = hparams.pos_weight\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step_initial = hparams.n_frames_per_step_initial\n",
    "        self.n_frames_per_step_current = hparams.n_frames_per_step_initial\n",
    "        self.embedding = nn.Embedding(self.n_symbols, hparams.symbols_embedding_dim)\n",
    "        std = np.sqrt(2.0 / (self.n_symbols + hparams.symbols_embedding_dim))\n",
    "        val = np.sqrt(3.0) * std  # uniform bounds for std\n",
    "        self.embedding.weight.data.uniform_(-val, val)\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.postnet = Postnet(hparams)\n",
    "        self.speaker_embedding_dim = hparams.speaker_embedding_dim\n",
    "        self.encoder_embedding_dim = hparams.encoder_embedding_dim\n",
    "        self.has_speaker_embedding = hparams.has_speaker_embedding\n",
    "        self.cudnn_enabled = hparams.cudnn_enabled\n",
    "        self.non_attentive = hparams.non_attentive\n",
    "        self.location_specific_attention = hparams.location_specific_attention\n",
    "        if self.non_attentive:\n",
    "            self.duration_predictor = DurationPredictor(hparams)\n",
    "\n",
    "        if self.n_speakers > 1 and not self.has_speaker_embedding:\n",
    "            raise Exception(\"Speaker embedding is required if n_speakers > 1\")\n",
    "        if hparams.has_speaker_embedding:\n",
    "            self.speaker_embedding = nn.Embedding(\n",
    "                self.n_speakers, hparams.speaker_embedding_dim\n",
    "            )\n",
    "        else:\n",
    "            self.speaker_embedding = None\n",
    "        if self.n_speakers > 1:\n",
    "            self.spkr_lin = nn.Linear(\n",
    "                self.speaker_embedding_dim, self.encoder_embedding_dim\n",
    "            )\n",
    "        else:\n",
    "            self.spkr_lin = lambda a: torch.zeros(\n",
    "                self.encoder_embedding_dim, device=a.device\n",
    "            )\n",
    "\n",
    "        self.gst_init(hparams)\n",
    "\n",
    "    def gst_init(self, hparams):\n",
    "        self.gst_lin = None\n",
    "        self.gst_type = None\n",
    "\n",
    "        if hparams.get(\"gst_type\") == \"torchmoji\":\n",
    "            assert hparams.gst_dim, \"gst_dim must be set\"\n",
    "            self.gst_type = hparams.get(\"gst_type\")\n",
    "            self.gst_lin = nn.Linear(hparams.gst_dim, self.encoder_embedding_dim)\n",
    "            print(\"Initialized Torchmoji GST\")\n",
    "        else:\n",
    "            print(\"Not using any style tokens\")\n",
    "\n",
    "    def parse_batch(self, batch: Batch):\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        durations_padded = batch.durations_padded\n",
    "        text_int_padded = batch.text_int_padded\n",
    "        input_lengths = batch.input_lengths\n",
    "        mel_padded = batch.mel_padded\n",
    "        gate_target = batch.gate_target\n",
    "        output_lengths = batch.output_lengths\n",
    "        speaker_ids = batch.speaker_ids\n",
    "        embedded_gst = batch.gst\n",
    "        f0_padded = batch.f0_padded\n",
    "        gate_pred = batch.gate_pred\n",
    "\n",
    "        if self.cudnn_enabled:\n",
    "            text_int_padded = to_gpu(text_int_padded).long()\n",
    "            input_lengths = to_gpu(input_lengths).long()\n",
    "            mel_padded = to_gpu(mel_padded).float()\n",
    "            gate_target = to_gpu(gate_target).float()\n",
    "            speaker_ids = to_gpu(speaker_ids).long()\n",
    "            output_lengths = to_gpu(output_lengths).long()\n",
    "            gate_pred = to_gpu(output_lengths).long()\n",
    "            if durations_padded is not None:\n",
    "                durations_padded = to_gpu(durations_padded).long()\n",
    "            if embedded_gst is not None:\n",
    "                embedded_gst = to_gpu(embedded_gst).float()\n",
    "\n",
    "        # max_len = torch.max(input_lengths.data).item()\n",
    "        ret_x = Batch(\n",
    "            text_int_padded=text_int_padded,\n",
    "            input_lengths=input_lengths,\n",
    "            mel_padded=mel_padded,\n",
    "            gate_pred=gate_pred,\n",
    "            output_lengths=output_lengths,\n",
    "            speaker_ids=speaker_ids,\n",
    "            gst=embedded_gst,\n",
    "            durations_padded=durations_padded,\n",
    "            f0_padded=f0_padded,\n",
    "            # max_len=max_len,\n",
    "        )\n",
    "        if self.location_specific_attention:\n",
    "            # pdb.set_trace()\n",
    "            ret_y = Batch(mel_padded=mel_padded, gate_target=gate_target)\n",
    "        if self.non_attentive:\n",
    "            ret_y = Batch(mel_padded=mel_padded, durations_padded=durations_padded)\n",
    "\n",
    "        return (ret_x, ret_y)\n",
    "\n",
    "    def parse_output(self, outputs, output_lengths=None):\n",
    "\n",
    "        if self.mask_padding and output_lengths is not None:\n",
    "            mask = ~get_mask_from_lengths(output_lengths)\n",
    "            mask = mask.expand(self.n_mel_channels, mask.size(0), mask.size(1))\n",
    "            mask = F.pad(mask, (0, outputs.mel_outputs.size(2) - mask.size(2)))\n",
    "            mask = mask.permute(1, 0, 2)\n",
    "\n",
    "            outputs.mel_outputs.data.masked_fill_(mask, 0.0)\n",
    "            outputs.mel_outputs_postnet.data.masked_fill_(mask, 0.0)\n",
    "            if self.location_specific_attention:\n",
    "                outputs.gate_pred.data.masked_fill_(mask[:, 0, :], 1e3)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_alignment(self, inputs):\n",
    "        (\n",
    "            input_text,\n",
    "            input_lengths,\n",
    "            targets,\n",
    "            max_len,\n",
    "            output_lengths,\n",
    "            speaker_ids,\n",
    "            *_,\n",
    "        ) = inputs\n",
    "\n",
    "        input_lengths, output_lengths = input_lengths.data, output_lengths.data\n",
    "\n",
    "        embedded_inputs = self.embedding(input_text).transpose(1, 2)\n",
    "        embedded_text = self.encoder(embedded_inputs, input_lengths)\n",
    "        encoder_outputs = embedded_text\n",
    "        if self.speaker_embedding:\n",
    "            embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "            encoder_outputs += self.spkr_lin(embedded_speakers)\n",
    "\n",
    "        encoder_outputs = torch.cat((encoder_outputs,), dim=2)\n",
    "\n",
    "        mel_outputs, gate_pred, alignments = self.decoder(\n",
    "            encoder_outputs,\n",
    "            targets,\n",
    "            input_lengths=input_lengths,\n",
    "            encoder_output_lengths=input_lengths,\n",
    "        )\n",
    "        return alignments\n",
    "\n",
    "    def forward(self, inputs: Batch):\n",
    "        input_text = inputs.text_int_padded\n",
    "        input_lengths = inputs.input_lengths\n",
    "        targets = inputs.mel_padded\n",
    "        output_lengths = inputs.output_lengths\n",
    "        speaker_ids = inputs.speaker_ids\n",
    "        gst = inputs.gst\n",
    "        durations_padded = inputs.durations_padded\n",
    "        # max_len = inputs.max_len\n",
    "\n",
    "        input_lengths, output_lengths = input_lengths.data, output_lengths.data\n",
    "\n",
    "        embedded_inputs = self.embedding(input_text).transpose(1, 2)\n",
    "        embedded_text = self.encoder(embedded_inputs, input_lengths)\n",
    "        encoder_outputs = embedded_text\n",
    "        if self.speaker_embedding:\n",
    "            embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "            encoder_outputs += self.spkr_lin(embedded_speakers)\n",
    "\n",
    "        if self.gst_lin is not None:\n",
    "            assert (\n",
    "                gst is not None\n",
    "            ), f\"embedded_gst is None but gst_type was set to {self.gst_type}\"\n",
    "            encoder_outputs += self.gst_lin(gst)\n",
    "        #         encoder_outputs = torch.cat((encoder_outputs,), dim=2)\n",
    "\n",
    "        if self.location_specific_attention:\n",
    "            # pdb.set_trace()\n",
    "            mel_outputs, gate_pred, alignments = self.decoder(\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                decoder_inputs=targets,\n",
    "                encoder_output_lengths=input_lengths,\n",
    "                # output_lengths=input_lengths,\n",
    "                output_lengths=output_lengths,\n",
    "            )\n",
    "\n",
    "        if self.non_attentive:\n",
    "            predicted_durations = self.decoder.duration_predictor(\n",
    "                encoder_outputs, input_lengths.cpu()\n",
    "            )\n",
    "            # pdb.set_trace()\n",
    "            mel_outputs, predicted_durations = self.decoder(\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                decoder_inputs=targets,\n",
    "                # output_lengths=input_lengths,\n",
    "                output_lengths=output_lengths,\n",
    "                input_lengths=input_lengths,\n",
    "                durations=durations_padded,\n",
    "            )\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        if self.location_specific_attention:\n",
    "            output_raw = Batch(\n",
    "                mel_outputs=mel_outputs,\n",
    "                mel_outputs_postnet=mel_outputs_postnet,\n",
    "                gate_pred=gate_pred,\n",
    "                output_lengths=output_lengths,\n",
    "                alignments=alignments,\n",
    "            )\n",
    "\n",
    "        if self.non_attentive:\n",
    "            output_raw = Batch(\n",
    "                predicted_durations=predicted_durations,\n",
    "                mel_outputs=mel_outputs,\n",
    "                mel_outputs_postnet=mel_outputs_postnet,\n",
    "            )\n",
    "\n",
    "        output = self.parse_output(output_raw, output_lengths)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, inputs: Batch):\n",
    "        # text, input_lengths, speaker_ids, embedded_gst, *_ = inputs\n",
    "        text_int_padded = inputs.text_int_padded\n",
    "        input_lengths = inputs.input_lengths\n",
    "        speaker_ids = inputs.speaker_ids\n",
    "        gst = inputs.gst\n",
    "\n",
    "        embedded_inputs = self.embedding(text_int_padded).transpose(1, 2)\n",
    "        embedded_text = self.encoder.inference(embedded_inputs, input_lengths)\n",
    "        encoder_outputs = embedded_text\n",
    "        if self.speaker_embedding:\n",
    "            embedded_speakers = self.speaker_embedding(speaker_ids)[:, None]\n",
    "            encoder_outputs += self.spkr_lin(embedded_speakers)\n",
    "\n",
    "        if self.gst_lin is not None:\n",
    "            assert (\n",
    "                gst is not None\n",
    "            ), f\"embedded_gst is None but gst_type was set to {self.gst_type}\"\n",
    "            encoder_outputs += self.gst_lin(gst)\n",
    "        #         encoder_outputs = torch.cat((encoder_outputs,), dim=2)\n",
    "\n",
    "        mel_outputs, gate_pred, alignments, mel_lengths = self.decoder.inference(\n",
    "            encoder_outputs, input_lengths\n",
    "        )\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_pred, alignments, mel_lengths]\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference_noattention(self, inputs):\n",
    "        \"\"\"Run inference conditioned on an attention map.\"\"\"\n",
    "        text, input_lengths, speaker_ids, attention_maps = inputs\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        embedded_text = self.encoder.inference(embedded_inputs, input_lengths)\n",
    "\n",
    "        encoder_outputs = torch.cat((embedded_text,), dim=2)\n",
    "\n",
    "        mel_outputs, gate_pred, alignments = self.decoder.inference_noattention(\n",
    "            encoder_outputs, attention_maps\n",
    "        )\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_pred, alignments]\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference_partial_tf(\n",
    "        self, inputs, tf_mel, tf_until_idx,\n",
    "    ):\n",
    "        \"\"\"Run inference with partial teacher forcing.\n",
    "\n",
    "        Teacher forcing is done until tf_until_idx in the mel spectrogram.\n",
    "        Make sure you pass the mel index and not the text index!\n",
    "\n",
    "        tf_mel: (B, T, n_mel_channels)\n",
    "        \"\"\"\n",
    "        text, input_lengths, *_ = inputs\n",
    "        embedded_inputs = self.embedding(text).transpose(1, 2)\n",
    "        embedded_text = self.encoder.inference(embedded_inputs, input_lengths)\n",
    "        encoder_outputs = torch.cat((embedded_text,), dim=2)\n",
    "\n",
    "        mel_outputs, gate_pred, alignments = self.decoder.inference_partial_tf(\n",
    "            encoder_outputs, tf_mel, tf_until_idx,\n",
    "        )\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_pred, alignments]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177770ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.models.base import DEFAULTS as MODEL_DEFAULTS\n",
    "\n",
    "DEFAULTS = HParams(\n",
    "    symbols_embedding_dim=512,\n",
    "    fp16_run=False,\n",
    "    mask_padding=True,\n",
    "    n_mel_channels=80,\n",
    "    # encoder parameters\n",
    "    encoder_kernel_size=5,\n",
    "    encoder_n_convolutions=3,\n",
    "    encoder_embedding_dim=512,\n",
    "    # decoder parameters\n",
    "    coarse_n_frames_per_step=None,\n",
    "    decoder_rnn_dim=1024,\n",
    "    prenet_dim=256,\n",
    "    prenet_f0_n_layers=1,\n",
    "    prenet_f0_dim=1,\n",
    "    prenet_f0_kernel_size=1,\n",
    "    prenet_rms_dim=0,\n",
    "    prenet_fms_kernel_size=1,\n",
    "    max_decoder_steps=1000,\n",
    "    gate_threshold=0.5,\n",
    "    p_attention_dropout=0.1,\n",
    "    p_decoder_dropout=0.1,\n",
    "    p_teacher_forcing=1.0,\n",
    "    pos_weight=None,\n",
    "    # attention parameters\n",
    "    attention_rnn_dim=1024,\n",
    "    attention_dim=128,\n",
    "    # location layer parameters\n",
    "    attention_location_n_filters=32,\n",
    "    attention_location_kernel_size=31,\n",
    "    # mel post-processing network parameters\n",
    "    postnet_embedding_dim=512,\n",
    "    postnet_kernel_size=5,\n",
    "    postnet_n_convolutions=5,\n",
    "    n_speakers=1,\n",
    "    speaker_embedding_dim=128,\n",
    "    # reference encoder\n",
    "    with_gst=False,\n",
    "    ref_enc_filters=[32, 32, 64, 64, 128, 128],\n",
    "    ref_enc_size=[3, 3],\n",
    "    ref_enc_strides=[2, 2],\n",
    "    ref_enc_pad=[1, 1],\n",
    "    filter_length=1024,\n",
    "    hop_length=256,\n",
    "    include_f0=False,\n",
    "    ref_enc_gru_size=128,\n",
    "    symbol_set=\"nvidia_taco2\",\n",
    "    num_heads=8,\n",
    "    text_cleaners=[\"english_cleaners\"],\n",
    "    sampling_rate=22050,\n",
    "    checkpoint_name=None,\n",
    "    max_wav_value=32768.0,\n",
    "    mel_fmax=8000,\n",
    "    mel_fmin=0,\n",
    "    n_frames_per_step_initial=1,\n",
    "    win_length=1024,\n",
    "    has_speaker_embedding=False,\n",
    "    gst_type=None,\n",
    "    torchmoji_model_file=None,\n",
    "    torchmoji_vocabulary_file=None,\n",
    "    sample_inference_speaker_ids=None,\n",
    "    sample_inference_text=\"That quick beige fox jumped in the air loudly over the thin dog fence.\",\n",
    "    distributed_run=False,\n",
    "    cudnn_enabled=False,\n",
    "    # compute_durations=False,\n",
    "    non_attentive=False,\n",
    "    location_specific_attention=True,\n",
    "    include_durations=False,\n",
    "    compute_durations=False,\n",
    ")\n",
    "\n",
    "config = DEFAULTS.values()\n",
    "config.update(MODEL_DEFAULTS.values())\n",
    "DEFAULTS = HParams(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9eca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.models.base import DEFAULTS as MODEL_DEFAULTS\n",
    "\n",
    "config = DEFAULTS.values()\n",
    "config.update(\n",
    "    dict(\n",
    "        # compute_durations=True,\n",
    "        non_attentive=True,\n",
    "        positional_embedding_dim=32,\n",
    "        range_lstm_dim=1024,\n",
    "        duration_lstm_dim=1024,\n",
    "        location_specific_attention=False,\n",
    "        cudnn_enabled=True,\n",
    "        include_durations=True,\n",
    "        compute_durations=True,\n",
    "        decoder_rnn_dim_nlayers=2,\n",
    "    )\n",
    ")\n",
    "config.update(MODEL_DEFAULTS.values())\n",
    "NON_ATTENTIVE_DEFAULTS = HParams(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ba935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from uberduck_ml_dev.trainer.tacotron2 import Tacotron2Trainer\n",
    "import json\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "\n",
    "config = NON_ATTENTIVE_DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "hparams.speaker_embedding_dim = 1\n",
    "hparams.decoder_rnn_dim_nlayers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26a1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speaker_embedding.weight']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.ignore_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.ignore_layers = [\n",
    "    \"speaker_embedding.weight\",\n",
    "    \"decoder.attention_rnn.weight_ih\",\n",
    "    \"decoder.attention_rnn.weight_hh\",\n",
    "    \"decoder.attention_rnn.bias_ih\",\n",
    "    \"decoder.attention_rnn.bias_hh\",\n",
    "    \"decoder.attention_layer.query_layer.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.memory_layer.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.v.linear_layer.weight\",\n",
    "    \"decoder.attention_layer.location_layer.location_conv.conv.weight\",\n",
    "    \"decoder.attention_layer.location_layer.location_dense.linear_layer.weight\",\n",
    "    \"decoder.decoder_rnn.weight_ih\",\n",
    "    \"decoder.decoder_rnn.weight_hh\",\n",
    "    \"decoder.decoder_rnn.bias_ih\",\n",
    "    \"decoder.decoder_rnn.bias_hh\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using any style tokens\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.range_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.duration_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.positional_embedding.pe layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the decoder.decoder_rnn.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l0 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l0_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l1 layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.weight_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_ih_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.lstm.bias_hh_l1_reverse layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.proj.linear_layer.weight layer. This could lead to unexpected results during evaluation.\n",
      "WARNING! Attempting to load a model with out the duration_predictor.proj.linear_layer.bias layer. This could lead to unexpected results during evaluation.\n",
      "> \u001b[0;32m/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/models/base.py\u001b[0m(58)\u001b[0;36mfrom_pretrained\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> model_dict\n",
      "OrderedDict([('embedding.weight', tensor([[-1.2031e-02, -4.0643e-02, -9.4461e-03,  ...,  3.8300e-02,\n",
      "         -4.1219e-02,  8.8430e-03],\n",
      "        [-4.3434e-02, -7.2746e-02,  9.0064e-02,  ...,  7.9890e-02,\n",
      "         -1.3387e-01,  1.4955e-02],\n",
      "        [ 2.5855e-02, -8.6037e-03,  3.2053e-02,  ..., -1.5724e-02,\n",
      "          5.5203e-03,  2.9659e-02],\n",
      "        ...,\n",
      "        [-2.7777e-39, -1.9029e-39,  2.4402e-39,  ..., -2.7994e-39,\n",
      "         -4.2996e-39,  1.7475e-40],\n",
      "        [-2.1060e-39, -3.5895e-39,  3.1522e-39,  ...,  2.2800e-39,\n",
      "          2.6950e-39,  2.6532e-39],\n",
      "        [-2.1562e-39, -6.1537e-39, -4.5764e-39,  ...,  1.4656e-39,\n",
      "          1.8097e-39, -1.6913e-39]])), ('encoder.convolutions.0.0.conv.weight', tensor([[[ 0.0219, -0.0490, -0.0543, -0.0264,  0.0320],\n",
      "         [-0.0274, -0.0412,  0.0262,  0.0126, -0.0235],\n",
      "         [ 0.0430,  0.0396,  0.0022, -0.0360,  0.0083],\n",
      "         ...,\n",
      "         [-0.0045, -0.0111, -0.0332, -0.0159, -0.0059],\n",
      "         [-0.0055,  0.0051, -0.0435, -0.0040,  0.0086],\n",
      "         [ 0.0012,  0.0111, -0.0124, -0.0210, -0.0095]],\n",
      "\n",
      "        [[-0.0136,  0.0028,  0.0177,  0.0112,  0.0042],\n",
      "         [-0.0375, -0.0503, -0.0033,  0.0015,  0.0116],\n",
      "         [ 0.0149,  0.0269, -0.0471, -0.0332, -0.0378],\n",
      "         ...,\n",
      "         [-0.0082,  0.0206,  0.0257,  0.0194,  0.0318],\n",
      "         [-0.0040,  0.0055,  0.0105,  0.0418,  0.0217],\n",
      "         [-0.0080,  0.0324,  0.0107, -0.0221, -0.0031]],\n",
      "\n",
      "        [[-0.0310, -0.0078, -0.0053,  0.0042,  0.0099],\n",
      "         [-0.0199, -0.0087, -0.0221, -0.0426, -0.0074],\n",
      "         [-0.0039,  0.0381,  0.0078,  0.0073, -0.0057],\n",
      "         ...,\n",
      "         [ 0.0110, -0.0242,  0.0028,  0.0273,  0.0116],\n",
      "         [ 0.0094,  0.0043,  0.0052,  0.0198, -0.0043],\n",
      "         [ 0.0065, -0.0151,  0.0274,  0.0059, -0.0184]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0086, -0.0004, -0.0219, -0.0066, -0.0144],\n",
      "         [ 0.0005, -0.0001,  0.0348,  0.0014, -0.0061],\n",
      "         [ 0.0066,  0.0192, -0.0477, -0.0576, -0.0128],\n",
      "         ...,\n",
      "         [-0.0216,  0.0201, -0.0312, -0.0021,  0.0136],\n",
      "         [ 0.0096,  0.0006,  0.0232, -0.0025,  0.0311],\n",
      "         [ 0.0047,  0.0044, -0.0174, -0.0061, -0.0143]],\n",
      "\n",
      "        [[-0.0368, -0.0565, -0.0419, -0.0359, -0.0194],\n",
      "         [-0.0275,  0.0024, -0.0020,  0.0060, -0.0137],\n",
      "         [-0.0006,  0.0118, -0.0057, -0.0415, -0.0219],\n",
      "         ...,\n",
      "         [ 0.0135,  0.0081, -0.0062, -0.0076, -0.0065],\n",
      "         [-0.0150, -0.0058,  0.0004, -0.0238,  0.0162],\n",
      "         [-0.0276, -0.0264, -0.0157, -0.0175,  0.0039]],\n",
      "\n",
      "        [[ 0.0002, -0.0277,  0.0167,  0.0205, -0.0046],\n",
      "         [-0.0073,  0.0146,  0.0060, -0.0488, -0.0142],\n",
      "         [ 0.0042,  0.0143, -0.0144,  0.0006,  0.0144],\n",
      "         ...,\n",
      "         [ 0.0047,  0.0046, -0.0148,  0.0234, -0.0082],\n",
      "         [ 0.0154, -0.0304, -0.0129,  0.0088,  0.0271],\n",
      "         [ 0.0034,  0.0014, -0.0164,  0.0312,  0.0046]]])), ('encoder.convolutions.0.0.conv.bias', tensor([-6.8957e-04, -1.5600e-03,  4.4622e-04,  5.6800e-04, -1.4404e-04,\n",
      "         1.9388e-04, -3.8043e-04,  2.6239e-04,  1.2066e-04, -2.8848e-04,\n",
      "         3.8760e-04, -7.8538e-04,  1.9984e-04, -1.4600e-04, -8.9862e-04,\n",
      "         3.0368e-04, -1.8451e-03,  4.9820e-04,  7.2269e-04, -1.1474e-03,\n",
      "        -6.0465e-04, -7.1459e-04, -1.2966e-03,  4.0986e-04,  8.0180e-04,\n",
      "        -1.5586e-03,  7.2982e-04,  1.4146e-03,  1.0767e-03,  3.8314e-05,\n",
      "         3.1973e-39,  2.5478e-04,  1.6071e-04,  1.0787e-04,  2.3387e-03,\n",
      "         4.7430e-04, -2.8531e-04,  4.3635e-05,  5.6725e-04,  1.3522e-03,\n",
      "        -1.1925e-03, -1.0037e-03,  6.4598e-04,  8.0067e-04, -8.9825e-04,\n",
      "        -1.0339e-03,  1.0481e-03,  4.4815e-04, -7.7455e-04, -7.0623e-04,\n",
      "         1.1963e-04,  5.7915e-05, -3.8045e-04, -6.7618e-04,  7.8845e-04,\n",
      "         1.1212e-03,  6.5088e-04,  4.5874e-04,  1.1709e-03, -4.7254e-04,\n",
      "         2.8135e-04, -3.0356e-04,  9.9800e-04, -1.4025e-04,  1.1315e-03,\n",
      "         6.2483e-05, -1.3579e-04,  2.0292e-04,  8.4759e-05, -5.7418e-04,\n",
      "        -2.7622e-03,  7.1528e-04,  3.2878e-05,  4.5097e-04, -1.8972e-04,\n",
      "        -5.4262e-04,  1.3239e-03, -9.2127e-05, -5.8498e-05,  1.3401e-03,\n",
      "        -2.1205e-05, -1.0990e-03, -4.1610e-04,  1.2398e-04,  3.7651e-04,\n",
      "        -3.3204e-04, -7.8831e-04, -2.1817e-04,  2.6254e-04, -7.8279e-04,\n",
      "         3.2923e-04,  7.5020e-04, -2.4278e-04,  5.4479e-04, -2.2173e-04,\n",
      "         4.6990e-04,  5.6864e-04, -7.4790e-04,  2.4194e-04,  4.7837e-04,\n",
      "         1.5633e-03,  5.6934e-04, -5.5257e-04,  3.4011e-04,  3.0273e-04,\n",
      "         4.1817e-04,  9.7639e-04, -1.4573e-03,  1.6169e-03,  5.8933e-04,\n",
      "        -1.3572e-03,  1.2852e-03, -1.4195e-03,  4.3480e-04,  1.2938e-03,\n",
      "        -4.4055e-04, -2.8802e-04,  1.2390e-03,  7.5758e-04, -4.6603e-04,\n",
      "        -1.7862e-05, -5.5347e-04, -1.1106e-03, -1.2214e-04,  6.2002e-04,\n",
      "        -1.1980e-03, -1.1013e-03,  1.1643e-04,  2.9067e-04, -1.4826e-04,\n",
      "         1.3628e-03,  8.5115e-06,  3.8196e-04, -1.7137e-05,  5.5976e-04,\n",
      "        -8.6358e-04, -6.7731e-04,  8.3723e-04,  7.4725e-04, -9.3147e-04,\n",
      "        -4.8843e-04,  2.6676e-03, -1.0774e-03, -5.4539e-04,  5.5081e-04,\n",
      "         3.6832e-04,  3.2722e-04, -1.5717e-04, -4.0658e-04, -1.6253e-04,\n",
      "         3.9470e-04,  9.4224e-04, -1.0562e-03,  5.5882e-05,  2.7359e-05,\n",
      "        -5.8829e-04,  2.1761e-04,  4.7040e-04,  5.4527e-04,  5.7737e-04,\n",
      "        -2.6988e-04,  1.5017e-04, -6.4362e-05,  2.8135e-04,  2.8329e-04,\n",
      "        -4.7774e-04,  1.0090e-05,  7.5263e-04, -1.0914e-03,  1.0855e-03,\n",
      "         6.4659e-04,  5.5167e-04,  8.5846e-04,  1.3184e-03,  1.1006e-03,\n",
      "         1.2660e-04, -5.3650e-04, -7.2789e-04, -2.5908e-04,  3.2994e-04,\n",
      "         3.8588e-04,  3.6236e-04, -1.0657e-03, -1.3470e-03,  6.3468e-04,\n",
      "         1.3811e-03,  4.7578e-04,  6.5526e-05, -6.6721e-04, -7.9714e-04,\n",
      "         1.8943e-04, -4.7568e-05,  1.4132e-03, -1.6889e-03,  1.1878e-04,\n",
      "         5.3308e-04,  6.1254e-04,  1.3326e-03, -1.0697e-03, -1.2050e-03,\n",
      "        -1.6198e-04, -7.4220e-04, -5.2104e-04,  4.8894e-04, -2.7663e-04,\n",
      "        -2.8607e-04, -1.4321e-05,  4.0501e-04,  5.6723e-04, -5.1016e-05,\n",
      "         7.0329e-04, -4.2207e-05, -4.6805e-05,  3.8991e-04, -9.1343e-04,\n",
      "         4.4818e-04,  8.1695e-04, -8.5311e-04,  1.2762e-04,  1.5904e-03,\n",
      "         2.4476e-05, -4.2299e-04,  8.3636e-05, -9.7446e-04, -2.9317e-04,\n",
      "         1.9711e-03, -1.5216e-04, -7.4073e-04,  4.1336e-04, -8.0102e-06,\n",
      "        -7.9410e-04,  6.9916e-04, -5.5955e-04,  4.6299e-04, -2.4190e-04,\n",
      "        -7.3710e-04, -5.7765e-04, -8.9865e-04,  7.1473e-04,  1.1749e-04,\n",
      "        -4.9149e-04,  2.1408e-05,  6.8832e-04,  4.0028e-04,  8.5347e-04,\n",
      "        -1.2237e-03,  5.2831e-04, -5.2063e-04, -1.1413e-03, -6.6668e-04,\n",
      "         1.8841e-04, -8.6485e-04, -3.9043e-04,  1.3092e-03, -1.7986e-04,\n",
      "         8.7796e-04, -1.6100e-04,  2.7142e-04,  1.0405e-03,  9.0307e-04,\n",
      "        -4.1907e-04,  8.5190e-04, -1.3436e-03,  9.7001e-04,  4.1488e-04,\n",
      "        -5.8626e-04, -1.5633e-04, -2.5271e-04, -3.9565e-05, -1.2201e-03,\n",
      "        -3.7645e-04, -9.4596e-04, -7.7229e-04, -3.2035e-04, -2.0796e-04,\n",
      "         4.2472e-04,  8.6415e-04,  4.8105e-04,  4.0475e-04,  1.0998e-03,\n",
      "         1.5448e-04,  1.1816e-03, -4.4880e-05, -1.3222e-04,  3.0425e-39,\n",
      "         1.1830e-04, -2.7571e-04, -1.3092e-03,  5.1281e-05, -3.0758e-04,\n",
      "        -4.1568e-04,  9.6426e-04,  2.7140e-04, -3.2672e-04,  2.2874e-04,\n",
      "         3.7385e-04,  1.8709e-03,  3.1458e-04, -3.6903e-04,  1.0363e-03,\n",
      "        -4.9173e-04,  1.4933e-03, -8.0674e-04,  1.0913e-03, -7.0975e-04,\n",
      "        -9.1032e-05, -3.0045e-04,  5.3904e-04,  4.5406e-04,  3.3593e-04,\n",
      "        -8.4609e-04, -6.5642e-04,  3.6433e-04,  2.1451e-04,  8.7942e-04,\n",
      "        -8.6586e-04, -1.0844e-04, -4.2521e-04,  2.2535e-04,  1.9108e-04,\n",
      "        -1.0033e-03,  8.2148e-04, -5.5615e-04, -1.5430e-04, -6.6333e-04,\n",
      "        -2.2452e-05, -3.1207e-04, -2.3848e-04, -1.2599e-03, -3.5782e-04,\n",
      "         1.5249e-03, -4.4972e-04, -4.5352e-04,  1.9334e-04,  1.0178e-03,\n",
      "        -1.7773e-04, -8.0717e-04, -3.4115e-04,  5.3178e-04,  5.9509e-04,\n",
      "        -2.4862e-03,  1.4056e-03, -1.8364e-03,  6.4493e-04, -1.1253e-03,\n",
      "         8.8181e-04,  8.3522e-06, -1.3321e-04, -4.0707e-04,  1.0348e-03,\n",
      "         3.3913e-04, -8.0873e-04, -1.2756e-03, -9.5891e-05, -7.8943e-04,\n",
      "         2.2343e-04,  1.4907e-04,  7.0169e-04, -3.7606e-04, -1.8816e-04,\n",
      "        -2.0142e-04,  3.5467e-04,  1.5416e-03,  4.4785e-05,  1.3150e-05,\n",
      "         1.1819e-03,  5.6970e-04, -4.0743e-04, -2.4359e-03,  1.1520e-04,\n",
      "        -1.0392e-03, -1.7860e-03, -4.4114e-04, -2.5590e-39,  4.8559e-04,\n",
      "         1.5016e-03,  4.2413e-40, -2.4107e-04, -3.4612e-04,  1.5950e-03,\n",
      "         9.8593e-04, -6.6786e-04,  1.1963e-04,  1.6523e-03, -9.8686e-04,\n",
      "         2.1465e-04,  1.0521e-03, -3.9097e-04,  5.2863e-04,  3.1982e-04,\n",
      "         5.7193e-04,  7.3161e-04, -2.3928e-04,  7.6118e-04,  1.1373e-03,\n",
      "        -7.7807e-04, -1.0198e-04,  2.8788e-04,  9.0810e-04,  1.1515e-03,\n",
      "        -2.3182e-04,  1.1254e-04,  5.0380e-04, -2.6862e-04, -2.1851e-04,\n",
      "        -3.7055e-04,  7.0107e-04,  8.7596e-04, -1.2685e-03, -6.5019e-04,\n",
      "         1.1535e-05,  9.6218e-04, -1.2295e-03,  1.7748e-04, -1.1236e-05,\n",
      "         3.7762e-04, -1.0964e-04,  1.2553e-03,  3.2667e-04,  6.5804e-05,\n",
      "        -2.7097e-05,  3.3459e-04,  1.5305e-04,  3.3595e-04,  1.7262e-03,\n",
      "         4.4201e-04,  6.0536e-05,  1.0148e-03, -6.7755e-04, -1.3623e-04,\n",
      "        -9.2971e-05,  5.0907e-04,  3.3620e-04, -1.2178e-03,  2.2514e-04,\n",
      "        -7.4052e-04,  1.2722e-03, -2.9998e-04,  5.3911e-04,  9.9346e-05,\n",
      "         2.2217e-03,  1.4053e-03, -6.6449e-05,  6.6104e-04,  2.5090e-04,\n",
      "        -1.8902e-05,  1.1393e-04,  1.3239e-04, -7.4373e-04,  1.4621e-03,\n",
      "         4.5073e-04,  1.2948e-03,  4.4217e-04, -3.8088e-04, -1.3604e-03,\n",
      "         3.3128e-04, -2.5729e-04, -6.0013e-04, -5.9748e-04, -9.6199e-04,\n",
      "         6.4540e-04, -1.2148e-04,  1.4093e-05,  1.2410e-03, -2.8151e-04,\n",
      "         4.3700e-04, -2.3630e-05, -8.6866e-04, -7.5769e-04, -7.6083e-04,\n",
      "        -7.0368e-04,  6.6032e-04,  1.4886e-03,  3.0416e-04, -1.3820e-04,\n",
      "         9.3543e-40,  2.8128e-04, -1.1429e-03,  3.2166e-04, -1.2331e-03,\n",
      "         1.3076e-03, -3.5760e-05,  1.1779e-03,  5.2122e-05,  2.2373e-04,\n",
      "        -1.1763e-03,  3.3286e-04, -4.3759e-04, -6.4655e-04,  4.5006e-04,\n",
      "        -2.8624e-04,  2.2788e-04,  1.1155e-03, -1.6633e-03,  7.1559e-04,\n",
      "        -6.8020e-04,  3.1911e-04,  6.3446e-04, -5.2344e-04, -9.9077e-04,\n",
      "         1.1429e-03,  7.6220e-04, -2.3152e-04, -1.8263e-04, -6.7709e-04,\n",
      "        -4.1764e-04,  2.8317e-04, -1.6783e-04, -1.2375e-03, -1.5790e-04,\n",
      "         1.5235e-03,  4.4174e-04])), ('encoder.convolutions.0.1.weight', tensor([ 4.4020e-01,  4.1207e-01,  3.5064e-01,  3.6412e-01,  2.6753e-01,\n",
      "         2.0668e-01,  3.5717e-01,  2.5876e-01,  3.9362e-01,  2.7729e-01,\n",
      "         3.7684e-01,  3.2483e-01,  3.6841e-01,  2.8994e-01,  4.4096e-01,\n",
      "         3.6169e-01,  4.8260e-01,  2.9541e-01,  2.5891e-01,  4.4186e-01,\n",
      "         3.6208e-01,  3.1795e-01,  2.9892e-01,  2.1718e-01,  2.4051e-01,\n",
      "         2.7669e-01,  2.4693e-01,  3.7320e-01,  3.1897e-01,  2.4663e-01,\n",
      "         2.5705e-10,  4.6799e-01,  3.3605e-01,  3.5140e-01,  2.8798e-01,\n",
      "         3.2707e-01,  4.0026e-01,  2.9377e-01,  2.5977e-01,  3.5519e-01,\n",
      "         3.9198e-01,  3.4873e-01,  3.1161e-01,  2.6087e-01,  3.1497e-01,\n",
      "         3.3690e-01,  2.2708e-01,  2.6662e-01,  3.9981e-01,  3.0668e-01,\n",
      "         4.1259e-01,  3.7286e-01,  3.6727e-01,  4.9183e-01,  2.7437e-01,\n",
      "         2.9317e-01,  4.6448e-01,  2.3790e-01,  4.8169e-01,  3.5494e-01,\n",
      "         3.4340e-01,  3.0124e-01,  4.3267e-01,  2.8888e-01,  4.6537e-01,\n",
      "         3.1018e-01,  3.7175e-01,  2.9521e-01,  3.6381e-01,  3.4963e-01,\n",
      "         4.1781e-01,  2.7803e-01,  3.6758e-01,  4.3659e-01,  4.1886e-01,\n",
      "         3.5889e-01,  5.3750e-01,  2.5935e-01,  3.8557e-01,  4.3607e-01,\n",
      "         3.2981e-01,  3.9486e-01,  2.9534e-01,  3.2937e-01,  4.7887e-01,\n",
      "         3.1272e-01,  3.0440e-01,  2.6883e-01,  4.4388e-01,  2.6826e-01,\n",
      "         4.7322e-01,  4.8992e-01,  3.9557e-01,  2.7304e-01,  4.2529e-01,\n",
      "         3.3064e-01,  3.0460e-01,  4.1163e-01,  3.3444e-01,  2.5529e-01,\n",
      "         2.6488e-01,  4.1408e-01,  2.2625e-01,  3.3985e-01,  2.6589e-01,\n",
      "         4.5805e-01,  3.1827e-01,  3.2416e-01,  5.0071e-01,  4.3466e-01,\n",
      "         5.8526e-01,  3.9564e-01,  6.4348e-01,  3.2613e-01,  3.1642e-01,\n",
      "         3.8375e-01,  2.3583e-01,  4.7104e-01,  2.9018e-01,  4.0567e-01,\n",
      "         3.5090e-01,  4.8976e-01,  3.8988e-01,  4.5069e-01,  3.4173e-01,\n",
      "         3.2946e-01,  3.9085e-01,  4.3053e-01,  4.6005e-01,  2.8412e-01,\n",
      "         4.0121e-01,  4.1369e-01,  3.3616e-01,  4.6393e-01,  4.2931e-01,\n",
      "         4.5247e-01,  4.5346e-01,  3.7732e-01,  2.4463e-01,  2.7017e-01,\n",
      "         4.8040e-01,  3.2773e-01,  4.3266e-01,  2.6061e-01,  2.9562e-01,\n",
      "         2.9245e-01,  4.0075e-01,  5.0376e-01,  2.5618e-01,  2.2795e-01,\n",
      "         4.5534e-01,  3.7487e-01,  2.4416e-01,  3.2578e-01,  3.1161e-01,\n",
      "         3.0289e-01,  4.1609e-01,  2.7083e-01,  2.6380e-01,  3.1602e-01,\n",
      "         3.6451e-01,  2.5621e-01,  2.7708e-01,  4.0299e-01,  3.5497e-01,\n",
      "         4.1009e-01,  4.4497e-01,  3.3294e-01,  3.5417e-01,  3.9095e-01,\n",
      "         2.6818e-01,  2.3824e-01,  3.8964e-01,  3.2127e-01,  2.6332e-01,\n",
      "         3.3496e-01,  3.2687e-01,  3.1998e-01,  4.7114e-01,  3.1380e-01,\n",
      "         3.8453e-01,  2.2944e-01,  3.9574e-01,  4.2106e-01,  3.3721e-01,\n",
      "         3.9748e-01,  3.5088e-01,  4.4528e-01,  4.0023e-01,  2.8955e-01,\n",
      "         3.7425e-01,  2.4266e-01,  2.8255e-01,  3.5698e-01,  3.6350e-01,\n",
      "         3.6880e-01,  4.3112e-01,  2.8256e-01,  2.6311e-01,  3.8706e-01,\n",
      "         4.9934e-01,  3.1609e-01,  4.8047e-01,  4.3581e-01,  3.6090e-01,\n",
      "         2.0890e-01,  3.3314e-01,  5.2286e-01,  3.0485e-01,  2.9833e-01,\n",
      "         3.3193e-01,  3.7720e-01,  2.8256e-01,  3.2407e-01,  2.6019e-01,\n",
      "         3.3452e-01,  3.9894e-01,  4.1499e-01,  5.3290e-01,  3.5861e-01,\n",
      "         2.6733e-01,  2.2520e-01,  3.5199e-01,  3.9829e-01,  3.4599e-01,\n",
      "         4.2574e-01,  3.5265e-01,  2.9554e-01,  4.7885e-01,  4.0189e-01,\n",
      "         4.5153e-01,  4.6796e-01,  4.1081e-01,  3.6578e-01,  2.4464e-01,\n",
      "         2.8116e-01,  3.2755e-01,  3.4683e-01,  3.7390e-01,  3.3429e-01,\n",
      "         3.2717e-01,  3.3799e-01,  3.6342e-01,  3.8002e-01,  3.5218e-01,\n",
      "         3.7918e-01,  4.7196e-01,  3.5357e-01,  3.1099e-01,  2.4992e-01,\n",
      "         4.8293e-01,  3.1283e-01,  3.4463e-01,  4.5839e-01,  3.1940e-01,\n",
      "         5.1791e-01,  3.9581e-01,  2.5825e-01,  4.5974e-01,  4.4430e-01,\n",
      "         4.7240e-01,  3.6057e-01,  4.2721e-01,  4.9840e-01,  3.3521e-01,\n",
      "         3.6292e-01,  5.6103e-01,  4.2322e-01,  3.4572e-01,  3.3283e-01,\n",
      "         5.2480e-01,  3.6141e-01,  5.9030e-01,  3.6875e-01,  3.3867e-01,\n",
      "         2.7823e-01,  6.0165e-01,  3.7164e-01,  4.1024e-01,  3.3569e-01,\n",
      "         3.2972e-01,  2.6031e-01,  4.6422e-01,  4.7818e-01,  2.1507e-38,\n",
      "         4.8472e-01,  4.6305e-01,  3.7784e-01,  3.6194e-01,  3.6233e-01,\n",
      "         2.6752e-01,  4.8517e-01,  4.1049e-01,  3.9166e-01,  2.6351e-01,\n",
      "         3.5229e-01,  3.7575e-01,  4.6526e-01,  5.0560e-01,  3.0552e-01,\n",
      "         4.1051e-01,  2.7878e-01,  3.5120e-01,  3.1589e-01,  3.0965e-01,\n",
      "         4.2775e-01,  5.2773e-01,  3.8625e-01,  3.0596e-01,  3.3123e-01,\n",
      "         3.8887e-01,  4.6926e-01,  3.2269e-01,  2.6708e-01,  3.4890e-01,\n",
      "         3.3609e-01,  2.6745e-01,  3.2132e-01,  5.0878e-01,  2.8109e-01,\n",
      "         3.2344e-01,  2.9035e-01,  2.9166e-01,  2.2193e-01,  4.1967e-01,\n",
      "         4.7910e-01,  3.1930e-01,  3.6895e-01,  3.1333e-01,  3.2700e-01,\n",
      "         3.1933e-01,  2.8053e-01,  2.3534e-01,  3.7425e-01,  3.6114e-01,\n",
      "         2.5843e-01,  3.8331e-01,  2.9188e-01,  2.7536e-01,  4.5804e-01,\n",
      "         3.6263e-01,  4.4488e-01,  3.8598e-01,  2.7973e-01,  3.9950e-01,\n",
      "         3.8594e-01,  4.6321e-01,  3.6189e-01,  3.1307e-01,  4.0248e-01,\n",
      "         5.2863e-01,  3.2208e-01,  5.3400e-01,  3.4813e-01,  4.1075e-01,\n",
      "         4.0227e-01,  5.0068e-01,  2.6456e-01,  3.8601e-01,  3.4682e-01,\n",
      "         3.1349e-01,  3.3685e-01,  3.7461e-01,  3.7053e-01,  4.1443e-01,\n",
      "         3.3133e-01,  4.4851e-01,  4.9967e-01,  2.9764e-01,  3.4068e-01,\n",
      "         2.3743e-01,  3.5431e-01,  3.0908e-01,  2.3272e-15,  4.6041e-01,\n",
      "         5.3330e-01, -4.3434e-25,  2.6291e-01,  3.4953e-01,  2.6947e-01,\n",
      "         2.8083e-01,  3.9464e-01,  3.2749e-01,  5.3696e-01,  3.1820e-01,\n",
      "         2.5797e-01,  5.4624e-01,  3.4342e-01,  3.4873e-01,  4.3520e-01,\n",
      "         2.3482e-01,  4.1732e-01,  3.2889e-01,  4.3992e-01,  4.2161e-01,\n",
      "         2.6563e-01,  3.0258e-01,  3.5339e-01,  3.4098e-01,  3.4236e-01,\n",
      "         2.4246e-01,  3.4380e-01,  3.0679e-01,  2.9515e-01,  3.4549e-01,\n",
      "         4.1892e-01,  2.6971e-01,  4.8493e-01,  2.9598e-01,  3.9166e-01,\n",
      "         3.1999e-01,  3.3883e-01,  2.9127e-01,  4.7772e-01,  2.7427e-01,\n",
      "         2.8629e-01,  2.5999e-01,  4.2221e-01,  5.2428e-01,  3.4794e-01,\n",
      "         2.5056e-01,  3.9508e-01,  4.1420e-01,  3.7628e-01,  3.8408e-01,\n",
      "         3.9779e-01,  3.0177e-01,  3.2484e-01,  4.5798e-01,  4.0162e-01,\n",
      "         2.7455e-01,  2.9961e-01,  3.5733e-01,  3.4454e-01,  2.8375e-01,\n",
      "         3.8367e-01,  3.0408e-01,  4.2245e-01,  3.8709e-01,  2.6334e-01,\n",
      "         3.2053e-01,  3.6858e-01,  2.5001e-01,  4.5751e-01,  3.3752e-01,\n",
      "         2.6576e-01,  2.5398e-01,  2.7117e-01,  3.4824e-01,  4.1382e-01,\n",
      "         3.8953e-01,  3.3860e-01,  3.4510e-01,  5.6971e-01,  2.1736e-01,\n",
      "         3.1054e-01,  4.5021e-01,  2.7356e-01,  3.3373e-01,  4.3405e-01,\n",
      "         2.7889e-01,  2.5256e-01,  3.8229e-01,  4.5158e-01,  2.9073e-01,\n",
      "         4.6277e-01,  4.4135e-01,  2.4008e-01,  2.8067e-01,  2.4458e-01,\n",
      "         5.2236e-01,  4.9052e-01,  3.1900e-01,  3.8340e-01,  5.1776e-01,\n",
      "         2.1766e-39,  3.1315e-01,  3.3836e-01,  2.9912e-01,  2.8541e-01,\n",
      "         4.5850e-01,  2.9986e-01,  4.3393e-01,  3.9811e-01,  3.2805e-01,\n",
      "         2.2821e-01,  3.7584e-01,  3.4088e-01,  3.4563e-01,  3.3284e-01,\n",
      "         2.9816e-01,  2.0074e-01,  2.8876e-01,  4.5432e-01,  3.1366e-01,\n",
      "         3.3629e-01,  4.8258e-01,  3.7230e-01,  3.0698e-01,  4.5234e-01,\n",
      "         3.0098e-01,  2.2817e-01,  2.2799e-01,  4.9525e-01,  3.2044e-01,\n",
      "         3.3838e-01,  3.5104e-01,  2.9877e-01,  3.0098e-01,  2.5153e-01,\n",
      "         3.9374e-01,  3.2640e-01])), ('encoder.convolutions.0.1.bias', tensor([-3.3254e-01, -3.3488e-01, -2.6303e-01, -2.8399e-01, -1.9122e-01,\n",
      "        -1.6556e-01, -2.3552e-01, -2.0651e-01, -2.7866e-01, -1.9822e-01,\n",
      "        -2.9340e-01, -2.7487e-01, -2.8875e-01, -2.4769e-01, -3.3339e-01,\n",
      "        -2.7908e-01, -3.1379e-01, -2.5322e-01, -1.9850e-01, -3.3834e-01,\n",
      "        -2.2270e-01, -2.5299e-01, -2.5555e-01, -1.4833e-01, -1.7332e-01,\n",
      "        -2.3804e-01, -1.7462e-01, -2.3532e-01, -2.5293e-01, -1.6301e-01,\n",
      "        -1.6998e-12, -3.7939e-01, -2.6218e-01, -2.8879e-01, -1.8297e-01,\n",
      "        -2.7970e-01, -2.9164e-01, -1.4052e-01, -1.8633e-01, -2.7810e-01,\n",
      "        -3.8728e-01, -2.6793e-01, -2.7434e-01, -2.0944e-01, -2.9443e-01,\n",
      "        -2.3925e-01, -1.4437e-01, -2.3271e-01, -2.5484e-01, -2.4203e-01,\n",
      "        -3.2211e-01, -2.8284e-01, -2.7091e-01, -3.1037e-01, -2.1238e-01,\n",
      "        -1.5581e-01, -3.3778e-01, -1.9371e-01, -3.7247e-01, -2.7552e-01,\n",
      "        -2.4180e-01, -2.3938e-01, -2.8559e-01, -2.2173e-01, -3.9187e-01,\n",
      "        -2.2991e-01, -2.8283e-01, -2.4728e-01, -2.9403e-01, -2.1123e-01,\n",
      "        -3.3753e-01, -2.0907e-01, -2.8800e-01, -2.8541e-01, -2.8437e-01,\n",
      "        -2.4897e-01, -3.6461e-01, -2.0652e-01, -2.4567e-01, -3.5515e-01,\n",
      "        -2.1838e-01, -3.0713e-01, -2.2870e-01, -2.8950e-01, -3.0446e-01,\n",
      "        -2.8012e-01, -2.3085e-01, -2.0724e-01, -2.7257e-01, -2.3521e-01,\n",
      "        -3.7989e-01, -3.4869e-01, -2.5101e-01, -2.6948e-01, -3.2818e-01,\n",
      "        -2.7718e-01, -2.7746e-01, -3.0702e-01, -2.2025e-01, -1.8037e-01,\n",
      "        -1.7627e-01, -3.4530e-01, -1.7267e-01, -1.9425e-01, -1.9106e-01,\n",
      "        -3.5486e-01, -2.4242e-01, -2.8847e-01, -3.3279e-01, -2.6838e-01,\n",
      "        -4.4871e-01, -2.0701e-01, -3.9901e-01, -2.3885e-01, -2.5893e-01,\n",
      "        -2.4192e-01, -2.0707e-01, -3.3188e-01, -2.2243e-01, -2.9974e-01,\n",
      "        -2.3707e-01, -4.0646e-01, -2.8063e-01, -3.5176e-01, -2.1693e-01,\n",
      "        -2.0925e-01, -2.9460e-01, -3.6756e-01, -3.2068e-01, -1.3711e-01,\n",
      "        -3.0339e-01, -3.0806e-01, -2.5217e-01, -3.1245e-01, -2.7615e-01,\n",
      "        -3.5268e-01, -3.5176e-01, -2.6415e-01, -1.7463e-01, -2.1498e-01,\n",
      "        -4.0515e-01, -2.5996e-01, -3.0850e-01, -2.3242e-01, -2.1105e-01,\n",
      "        -2.5386e-01, -2.8441e-01, -4.0842e-01, -1.7288e-01, -2.3739e-01,\n",
      "        -3.5713e-01, -3.3395e-01, -1.4930e-01, -2.3901e-01, -2.5917e-01,\n",
      "        -2.6757e-01, -3.6164e-01, -2.3401e-01, -1.9790e-01, -2.3717e-01,\n",
      "        -2.6167e-01, -1.3260e-01, -1.9069e-01, -3.1540e-01, -2.1980e-01,\n",
      "        -3.2064e-01, -3.4564e-01, -2.4355e-01, -2.5379e-01, -2.3063e-01,\n",
      "        -2.0720e-01, -2.1043e-01, -3.1233e-01, -2.2302e-01, -2.0087e-01,\n",
      "        -2.8166e-01, -1.7360e-01, -2.4483e-01, -3.1667e-01, -2.8339e-01,\n",
      "        -2.1911e-01, -1.5874e-01, -2.9961e-01, -3.3538e-01, -2.4661e-01,\n",
      "        -2.9484e-01, -2.8598e-01, -3.3242e-01, -3.2896e-01, -2.1703e-01,\n",
      "        -2.9105e-01, -1.7264e-01, -2.2991e-01, -2.6148e-01, -2.6980e-01,\n",
      "        -3.1609e-01, -3.1373e-01, -2.2447e-01, -2.1923e-01, -2.8453e-01,\n",
      "        -3.5285e-01, -2.4731e-01, -3.2731e-01, -3.2708e-01, -3.3736e-01,\n",
      "        -1.2390e-01, -2.8050e-01, -3.2433e-01, -2.0770e-01, -2.3563e-01,\n",
      "        -2.1094e-01, -2.9192e-01, -2.0968e-01, -2.7412e-01, -2.2574e-01,\n",
      "        -2.0430e-01, -3.0333e-01, -3.3756e-01, -4.1549e-01, -2.2917e-01,\n",
      "        -2.1116e-01, -1.5196e-01, -2.2058e-01, -2.7885e-01, -2.2277e-01,\n",
      "        -2.7265e-01, -2.1590e-01, -2.3386e-01, -3.5228e-01, -3.5215e-01,\n",
      "        -3.6497e-01, -3.5272e-01, -3.1079e-01, -2.7537e-01, -1.8179e-01,\n",
      "        -1.4169e-01, -1.6089e-01, -2.8807e-01, -2.8356e-01, -2.5873e-01,\n",
      "        -2.7282e-01, -2.2866e-01, -2.6525e-01, -2.8285e-01, -2.9986e-01,\n",
      "        -2.9856e-01, -3.0374e-01, -2.7613e-01, -2.5296e-01, -2.5010e-01,\n",
      "        -3.1614e-01, -2.3299e-01, -2.6484e-01, -3.1700e-01, -2.0178e-01,\n",
      "        -4.0271e-01, -3.1714e-01, -1.4003e-01, -3.4349e-01, -3.6143e-01,\n",
      "        -3.8514e-01, -2.8611e-01, -3.5976e-01, -4.3071e-01, -2.8219e-01,\n",
      "        -2.7199e-01, -3.6802e-01, -3.1880e-01, -2.5950e-01, -3.0367e-01,\n",
      "        -3.2269e-01, -2.5440e-01, -3.8019e-01, -2.7581e-01, -2.5535e-01,\n",
      "        -2.4107e-01, -3.8807e-01, -2.5551e-01, -2.8082e-01, -2.2218e-01,\n",
      "        -1.8566e-01, -2.4321e-01, -3.4553e-01, -3.1214e-01, -1.7010e-37,\n",
      "        -3.5757e-01, -3.8084e-01, -2.9538e-01, -2.6695e-01, -3.0475e-01,\n",
      "        -1.6453e-01, -3.2641e-01, -2.9822e-01, -3.1005e-01, -2.4606e-01,\n",
      "        -2.2230e-01, -2.4795e-01, -3.1829e-01, -2.9975e-01, -1.7565e-01,\n",
      "        -2.1323e-01, -1.8804e-01, -2.8437e-01, -2.4226e-01, -1.7141e-01,\n",
      "        -3.4325e-01, -3.9878e-01, -3.1798e-01, -2.4127e-01, -2.4633e-01,\n",
      "        -3.1331e-01, -3.4173e-01, -2.5721e-01, -1.4219e-01, -2.5484e-01,\n",
      "        -2.7297e-01, -1.9597e-01, -2.2736e-01, -3.6830e-01, -1.9515e-01,\n",
      "        -2.4072e-01, -2.1455e-01, -2.5237e-01, -1.7351e-01, -2.6176e-01,\n",
      "        -3.8820e-01, -2.3971e-01, -3.2197e-01, -2.2421e-01, -2.8255e-01,\n",
      "        -2.6626e-01, -1.7112e-01, -1.6660e-01, -2.4146e-01, -2.2951e-01,\n",
      "        -2.3956e-01, -2.8351e-01, -2.5924e-01, -1.5504e-01, -3.3381e-01,\n",
      "        -2.7736e-01, -3.7048e-01, -2.9238e-01, -2.1961e-01, -3.0878e-01,\n",
      "        -2.9561e-01, -3.4201e-01, -2.5476e-01, -2.2691e-01, -2.3824e-01,\n",
      "        -3.3002e-01, -2.6033e-01, -3.4863e-01, -2.7904e-01, -2.6593e-01,\n",
      "        -2.9434e-01, -3.8213e-01, -2.2759e-01, -3.0080e-01, -2.7774e-01,\n",
      "        -1.9092e-01, -2.5480e-01, -2.8869e-01, -2.7766e-01, -3.2736e-01,\n",
      "        -2.8448e-01, -3.6299e-01, -4.2044e-01, -2.7233e-01, -2.2874e-01,\n",
      "        -2.0078e-01, -2.6280e-01, -2.3629e-01, -4.8662e-18, -2.7517e-01,\n",
      "        -3.7364e-01, -5.9687e-27, -2.2869e-01, -3.0998e-01, -2.1891e-01,\n",
      "        -2.3438e-01, -3.0190e-01, -2.5155e-01, -3.9102e-01, -2.6712e-01,\n",
      "        -2.2400e-01, -3.4893e-01, -2.5904e-01, -1.9721e-01, -3.1083e-01,\n",
      "        -1.9649e-01, -2.7755e-01, -2.8299e-01, -3.6698e-01, -3.3809e-01,\n",
      "        -2.0016e-01, -2.1954e-01, -2.9059e-01, -2.6619e-01, -2.2780e-01,\n",
      "        -1.7789e-01, -2.6930e-01, -1.8498e-01, -2.3433e-01, -2.7803e-01,\n",
      "        -2.8744e-01, -1.6250e-01, -3.9697e-01, -2.1928e-01, -3.8094e-01,\n",
      "        -2.2601e-01, -2.5773e-01, -3.3298e-01, -3.1590e-01, -2.1607e-01,\n",
      "        -2.1421e-01, -2.0313e-01, -3.3636e-01, -4.0336e-01, -2.4139e-01,\n",
      "        -1.7696e-01, -2.2076e-01, -2.4427e-01, -2.3766e-01, -2.4230e-01,\n",
      "        -3.3212e-01, -1.9210e-01, -2.6119e-01, -3.5282e-01, -2.7644e-01,\n",
      "        -1.3148e-01, -2.1420e-01, -3.1864e-01, -2.4835e-01, -2.7661e-01,\n",
      "        -2.9011e-01, -2.2205e-01, -3.3630e-01, -2.4748e-01, -2.1437e-01,\n",
      "        -2.5124e-01, -2.8845e-01, -2.1001e-01, -3.3332e-01, -1.9942e-01,\n",
      "        -2.3519e-01, -2.0714e-01, -2.2448e-01, -2.5987e-01, -3.1207e-01,\n",
      "        -2.9891e-01, -2.1404e-01, -2.1518e-01, -3.9440e-01, -1.6868e-01,\n",
      "        -2.2338e-01, -2.8330e-01, -1.5048e-01, -2.4199e-01, -3.3109e-01,\n",
      "        -2.0020e-01, -1.7951e-01, -2.9771e-01, -3.3356e-01, -2.2268e-01,\n",
      "        -3.7515e-01, -3.7187e-01, -2.0692e-01, -1.8604e-01, -2.0192e-01,\n",
      "        -3.5143e-01, -3.2595e-01, -2.4426e-01, -3.1026e-01, -3.6361e-01,\n",
      "        -1.3395e-39, -2.4072e-01, -2.6183e-01, -2.6577e-01, -2.2724e-01,\n",
      "        -3.8506e-01, -2.6463e-01, -3.1755e-01, -2.7543e-01, -1.6479e-01,\n",
      "        -1.8195e-01, -2.8713e-01, -2.3485e-01, -2.4395e-01, -2.5692e-01,\n",
      "        -2.3535e-01, -1.8161e-01, -2.1487e-01, -2.9933e-01, -2.2553e-01,\n",
      "        -2.4741e-01, -3.1022e-01, -2.4481e-01, -2.1521e-01, -2.8456e-01,\n",
      "        -2.0430e-01, -1.6427e-01, -1.7418e-01, -3.7286e-01, -2.2273e-01,\n",
      "        -2.3826e-01, -2.9728e-01, -1.4925e-01, -2.1473e-01, -1.9297e-01,\n",
      "        -2.4169e-01, -2.3891e-01])), ('encoder.convolutions.0.1.running_mean', tensor([-1.1246e-01, -2.5289e-02,  5.0915e-02, -2.0359e-02, -2.0855e-01,\n",
      "        -6.1414e-02, -1.4276e-01,  1.6842e-01,  1.4994e-02, -6.2448e-02,\n",
      "        -5.1405e-02, -7.6661e-02, -9.4351e-02, -5.1400e-02, -4.9916e-02,\n",
      "        -2.0347e-02, -1.9166e-01, -7.1446e-02,  1.6846e-02, -1.4733e-01,\n",
      "        -9.6553e-02, -1.4894e-01, -1.1110e-01,  1.8014e-02, -9.5939e-02,\n",
      "         4.4670e-03,  8.9703e-03, -2.1477e-03, -1.1616e-01, -1.4253e-02,\n",
      "        -5.6052e-45, -1.8681e-01, -1.9041e-01, -1.8247e-01,  2.8294e-02,\n",
      "        -8.7067e-02,  5.9137e-02,  9.2742e-03, -1.5975e-01,  3.6842e-02,\n",
      "        -1.3438e-01, -1.2067e-01, -6.7294e-02, -9.1712e-02, -1.8972e-01,\n",
      "        -1.1374e-01, -2.0033e-01,  4.1782e-03, -1.0958e-01,  2.4235e-03,\n",
      "         2.9125e-02,  1.7969e-01,  8.9632e-02, -7.5880e-02, -3.3392e-02,\n",
      "        -1.0933e-02, -9.5036e-02, -4.2845e-03, -5.3214e-02, -4.6865e-02,\n",
      "         8.1563e-02,  1.7401e-01, -2.9591e-02, -8.2433e-02, -1.0077e-01,\n",
      "        -7.5335e-02, -2.8687e-01, -1.0798e-01, -2.4587e-01, -1.8602e-01,\n",
      "        -7.6630e-02, -1.9366e-01, -1.7987e-01, -2.3932e-01, -6.6160e-03,\n",
      "        -1.7635e-01, -7.6790e-03, -1.6692e-01, -8.4105e-04, -2.1177e-01,\n",
      "        -2.4346e-01, -7.9190e-02,  1.1617e-01,  9.1697e-02, -1.2934e-01,\n",
      "         6.3852e-02, -6.9335e-02,  5.5234e-02, -1.6541e-01, -1.6568e-01,\n",
      "        -1.4152e-01, -9.2873e-02, -2.7109e-01, -1.3154e-01, -1.7710e-01,\n",
      "        -1.7182e-01, -9.2413e-02, -2.5499e-02, -6.6066e-02, -4.6442e-02,\n",
      "        -2.2499e-02, -6.0329e-02, -3.8950e-02, -8.8308e-02, -1.2805e-01,\n",
      "        -5.6362e-02, -5.4215e-02,  9.4173e-02, -1.0811e-01, -1.4449e-02,\n",
      "        -1.7261e-01,  3.9215e-02, -2.1213e-02, -1.9920e-01, -1.4192e-01,\n",
      "        -1.6579e-01,  7.4514e-02,  1.5652e-02, -1.3222e-01, -8.5835e-02,\n",
      "        -5.8238e-02,  8.8677e-03, -1.3251e-01,  1.7054e-01, -7.2270e-02,\n",
      "        -3.0027e-02, -1.4510e-02, -2.8094e-03, -1.3893e-01, -1.1691e-01,\n",
      "        -4.1418e-02, -1.5636e-01,  4.3439e-02, -1.3496e-01, -2.5557e-01,\n",
      "        -2.2507e-01, -1.0787e-01, -1.0026e-01,  4.6477e-02, -4.3335e-02,\n",
      "        -2.6832e-01, -1.9470e-01, -1.3792e-01,  1.5416e-01,  1.2541e-02,\n",
      "        -4.4221e-02, -1.8954e-02,  2.5972e-02, -6.7795e-02, -6.1211e-02,\n",
      "        -6.0670e-02,  3.5792e-02, -8.7384e-02, -2.0012e-01, -1.0871e-01,\n",
      "        -9.2472e-02, -1.1486e-01, -2.9219e-02, -4.8121e-02, -1.3740e-01,\n",
      "        -3.7869e-02, -8.6751e-02, -2.3847e-01, -1.7969e-01, -1.4964e-02,\n",
      "        -1.0365e-02, -1.6544e-01, -9.0701e-02,  1.0265e-02,  2.7498e-02,\n",
      "        -1.7957e-02, -1.6679e-02, -1.3617e-01, -1.0997e-01, -8.6278e-02,\n",
      "        -1.3235e-01, -4.5838e-02, -1.4623e-01, -4.2054e-02, -1.8272e-01,\n",
      "        -2.5008e-02, -1.2751e-01, -1.0094e-02, -9.2514e-02, -2.4693e-02,\n",
      "        -5.5723e-02, -4.5507e-02, -1.5142e-02, -4.1790e-02, -2.5950e-01,\n",
      "        -1.3750e-01, -2.3439e-02, -3.6597e-01, -1.8240e-01,  1.1336e-01,\n",
      "         2.5484e-02, -8.6594e-02, -6.9060e-02, -5.6341e-02, -4.4397e-02,\n",
      "        -8.4306e-02,  1.0415e-01,  5.2771e-02, -5.3294e-02,  9.5865e-02,\n",
      "        -1.2007e-01, -1.4351e-01, -7.2948e-02, -1.7528e-01,  6.3731e-02,\n",
      "        -3.8863e-03, -6.7607e-02, -1.3347e-01, -1.2615e-01,  6.6634e-02,\n",
      "        -1.3115e-01, -2.2392e-01, -8.2584e-02, -1.0778e-01, -8.0295e-02,\n",
      "         2.9099e-02, -2.6113e-03, -1.3038e-01,  1.0899e-02, -1.5739e-01,\n",
      "        -2.3993e-01, -1.7666e-02, -5.2255e-02, -1.1780e-01, -1.9900e-01,\n",
      "         7.4980e-02, -1.6103e-01, -1.0360e-01, -1.2757e-01,  6.2810e-02,\n",
      "        -2.9749e-02, -1.3451e-01, -1.9906e-01, -7.3818e-03, -9.4411e-02,\n",
      "        -1.6652e-01, -1.1497e-01,  3.9279e-02,  1.7711e-01, -1.4499e-01,\n",
      "         8.9334e-02, -4.6408e-02, -1.5474e-02,  1.9130e-02, -8.2787e-02,\n",
      "         2.8651e-02, -2.8063e-01, -4.4169e-03, -1.5755e-01, -2.0989e-01,\n",
      "        -1.8304e-01, -1.8403e-02, -1.1166e-01, -1.9217e-01, -2.7474e-01,\n",
      "        -1.1318e-01, -3.3042e-01, -1.0776e-01, -1.2230e-01,  9.8854e-02,\n",
      "        -1.7433e-01, -1.5432e-02, -1.7806e-01, -1.1504e-01, -1.6982e-01,\n",
      "        -1.4484e-01, -1.3581e-01, -4.4371e-02, -9.9497e-02, -1.0644e-01,\n",
      "        -1.5929e-01, -1.0490e-01,  1.2453e-02, -9.5724e-02,  9.9036e-03,\n",
      "         6.9032e-02, -3.0780e-01, -1.6080e-01,  1.4030e-02, -5.6052e-45,\n",
      "         7.2574e-03, -1.2101e-01,  2.9096e-02,  1.2783e-02, -8.8335e-02,\n",
      "        -6.2595e-02, -4.8581e-02,  5.8743e-02, -1.9363e-01, -1.6987e-02,\n",
      "        -4.9545e-02, -1.1112e-01, -7.3829e-03, -2.0966e-01, -1.3887e-01,\n",
      "         3.9567e-02, -1.5859e-01,  1.5351e-01, -1.6909e-01, -1.9563e-01,\n",
      "        -6.3599e-02, -1.6927e-01, -2.3206e-01, -8.2287e-02, -9.6279e-02,\n",
      "        -6.1801e-02,  1.2428e-01, -2.1556e-01, -1.0889e-01, -8.7128e-02,\n",
      "        -7.3293e-03, -2.5480e-01,  1.0142e-02, -2.2957e-02,  5.0981e-02,\n",
      "        -1.8896e-01, -2.1084e-02, -2.0024e-01,  8.4828e-02, -1.1239e-01,\n",
      "         6.7005e-02, -5.6615e-02, -7.5934e-02, -1.3733e-04,  5.8987e-02,\n",
      "        -1.0152e-01, -2.2092e-02, -5.6486e-03, -1.5920e-01,  1.9666e-05,\n",
      "        -3.7561e-02, -1.3235e-01, -2.0308e-01, -4.1819e-02,  5.0773e-02,\n",
      "         5.7406e-02, -1.4361e-01, -1.7560e-01,  3.1812e-02, -1.0376e-01,\n",
      "        -1.3977e-01, -4.3282e-02, -7.6844e-02, -1.0362e-01, -3.3027e-02,\n",
      "        -1.4510e-01, -2.1877e-01, -1.0253e-01, -2.4298e-01, -1.2207e-01,\n",
      "        -6.0204e-02, -7.5741e-02, -1.5659e-01, -1.5399e-01, -8.1496e-02,\n",
      "         1.4290e-02, -5.1988e-02, -3.4728e-02, -1.6508e-01, -5.4245e-03,\n",
      "        -2.5164e-02, -2.3604e-01,  1.6790e-03, -3.0388e-02, -2.7103e-01,\n",
      "        -1.1646e-02, -9.6171e-02, -1.1068e-01, -5.6052e-45,  7.8449e-02,\n",
      "         1.2570e-02,  5.6052e-45,  9.5376e-02, -1.8262e-01, -4.0115e-02,\n",
      "        -4.5632e-02, -6.6593e-02, -1.3826e-01, -3.6990e-02, -1.6198e-01,\n",
      "        -8.3752e-02, -1.4870e-01, -1.0912e-01, -6.2252e-02, -2.2762e-02,\n",
      "        -4.5915e-02, -9.2503e-02, -1.1210e-01,  6.9496e-02, -1.2418e-01,\n",
      "        -5.8603e-02, -1.5376e-01, -6.0186e-02, -2.2041e-01, -1.1793e-01,\n",
      "        -4.3842e-02,  8.5362e-02, -1.0140e-01, -9.4562e-02, -8.7648e-02,\n",
      "        -1.8733e-01,  1.4931e-02, -1.1599e-01, -2.5310e-01, -1.6580e-01,\n",
      "        -7.4357e-03, -7.1996e-02,  1.9951e-01, -8.7600e-02, -4.3651e-02,\n",
      "        -2.4411e-01, -1.2374e-01, -7.5186e-02, -1.8338e-01, -6.9272e-02,\n",
      "         1.8354e-02, -7.8748e-02,  5.0834e-02, -2.4889e-01, -8.5202e-02,\n",
      "        -7.4936e-02, -1.5107e-01, -1.4539e-01, -6.4530e-02, -1.2914e-01,\n",
      "        -1.2475e-01,  2.5335e-03, -1.9610e-01,  8.5176e-03, -1.7631e-01,\n",
      "        -1.5164e-01, -4.6468e-02,  1.2527e-01, -1.8761e-01, -2.7441e-02,\n",
      "         9.5136e-03, -1.0944e-01, -2.8784e-02, -6.0659e-03,  2.6243e-02,\n",
      "        -7.8437e-02, -8.2991e-02, -6.5209e-02, -2.2503e-02, -9.8298e-02,\n",
      "        -6.7578e-02, -2.2874e-01, -9.5062e-02, -1.2923e-01, -3.0213e-02,\n",
      "        -1.9610e-01, -7.6428e-02, -7.2521e-02,  1.3071e-01, -2.2228e-01,\n",
      "        -1.5027e-01, -7.2520e-02, -6.4278e-02, -6.8076e-02,  2.9331e-02,\n",
      "         8.8266e-02, -1.5930e-01,  3.2653e-02,  6.1261e-02,  3.4209e-02,\n",
      "        -8.7136e-02, -1.2901e-01, -2.1611e-01,  2.3996e-02, -7.0229e-02,\n",
      "        -5.6052e-45, -1.4502e-01, -1.5860e-01, -5.6846e-02, -4.6558e-02,\n",
      "        -8.1442e-02, -1.4054e-01, -8.8238e-02, -9.0164e-02,  8.7613e-03,\n",
      "        -2.7777e-02, -2.2252e-01, -5.6876e-02, -1.6474e-01, -6.3960e-02,\n",
      "        -1.7880e-01,  2.4359e-02, -1.1088e-01, -1.2221e-01, -2.9431e-02,\n",
      "        -1.3169e-01, -3.3964e-02,  3.4200e-02,  1.0944e-01,  4.1790e-02,\n",
      "        -1.4863e-01,  1.9323e-01,  1.5188e-01, -6.9169e-02, -1.5563e-01,\n",
      "         2.0185e-01, -5.3998e-02, -4.8845e-02, -6.1159e-02, -5.9897e-02,\n",
      "        -5.8947e-02,  5.1521e-02])), ('encoder.convolutions.0.1.running_var', tensor([3.2368e-02, 2.5313e-02, 2.1710e-02, 2.7062e-02, 1.7442e-02, 1.4850e-02,\n",
      "        2.4248e-02, 1.7917e-02, 2.6654e-02, 2.0521e-02, 2.6304e-02, 2.1122e-02,\n",
      "        2.6751e-02, 1.9879e-02, 2.9776e-02, 2.2788e-02, 3.1604e-02, 1.9074e-02,\n",
      "        1.9462e-02, 3.0150e-02, 2.7419e-02, 1.7881e-02, 2.2098e-02, 1.6154e-02,\n",
      "        1.8601e-02, 1.8281e-02, 1.8964e-02, 2.7383e-02, 2.2164e-02, 2.2470e-02,\n",
      "        5.6052e-45, 3.5985e-02, 2.2378e-02, 2.6342e-02, 2.7271e-02, 2.0987e-02,\n",
      "        2.6661e-02, 2.3845e-02, 2.0212e-02, 2.4401e-02, 2.0870e-02, 2.5791e-02,\n",
      "        2.1497e-02, 1.8115e-02, 1.8810e-02, 2.6770e-02, 1.9132e-02, 1.7716e-02,\n",
      "        2.6625e-02, 2.5086e-02, 2.5870e-02, 2.2678e-02, 2.5134e-02, 3.7082e-02,\n",
      "        2.1892e-02, 2.0907e-02, 2.8077e-02, 1.8217e-02, 2.4740e-02, 2.1946e-02,\n",
      "        2.4699e-02, 2.0835e-02, 2.9812e-02, 2.0680e-02, 3.2131e-02, 2.2408e-02,\n",
      "        2.7369e-02, 2.1366e-02, 3.2657e-02, 2.9505e-02, 2.6875e-02, 1.7471e-02,\n",
      "        2.4851e-02, 2.5274e-02, 2.5281e-02, 2.4205e-02, 3.7375e-02, 2.0873e-02,\n",
      "        2.6948e-02, 2.1694e-02, 2.7345e-02, 2.6561e-02, 2.1100e-02, 2.3232e-02,\n",
      "        2.8846e-02, 2.3362e-02, 2.1850e-02, 1.8879e-02, 2.6912e-02, 2.2129e-02,\n",
      "        3.5277e-02, 2.8734e-02, 2.4279e-02, 1.7559e-02, 2.8848e-02, 1.9530e-02,\n",
      "        1.9818e-02, 3.3651e-02, 2.2189e-02, 1.8996e-02, 1.7313e-02, 2.3012e-02,\n",
      "        1.6283e-02, 2.3773e-02, 1.7028e-02, 2.9791e-02, 2.5125e-02, 2.2371e-02,\n",
      "        2.8630e-02, 3.6890e-02, 3.9175e-02, 2.9702e-02, 3.5033e-02, 2.3333e-02,\n",
      "        2.2740e-02, 2.5716e-02, 1.8896e-02, 2.8889e-02, 2.2519e-02, 2.3871e-02,\n",
      "        2.6445e-02, 3.2661e-02, 2.3597e-02, 3.3682e-02, 2.2502e-02, 2.2298e-02,\n",
      "        2.8560e-02, 2.7872e-02, 3.5349e-02, 2.4959e-02, 2.7046e-02, 2.7934e-02,\n",
      "        2.5065e-02, 3.1507e-02, 3.1310e-02, 2.7063e-02, 3.1996e-02, 2.7558e-02,\n",
      "        2.0567e-02, 2.0920e-02, 3.9150e-02, 2.2595e-02, 3.3965e-02, 1.5442e-02,\n",
      "        2.3925e-02, 2.1180e-02, 2.6407e-02, 2.9580e-02, 2.1209e-02, 1.3830e-02,\n",
      "        2.8612e-02, 2.5909e-02, 1.7094e-02, 2.4536e-02, 2.3168e-02, 1.9117e-02,\n",
      "        2.0696e-02, 2.8135e-02, 1.9200e-02, 1.9071e-02, 2.6474e-02, 2.3394e-02,\n",
      "        1.9445e-02, 2.6238e-02, 3.2724e-02, 2.5952e-02, 2.3895e-02, 2.8785e-02,\n",
      "        2.5809e-02, 2.8692e-02, 2.0167e-02, 1.8930e-02, 2.3000e-02, 2.6029e-02,\n",
      "        2.0476e-02, 1.9940e-02, 2.4336e-02, 2.2161e-02, 2.8837e-02, 2.2582e-02,\n",
      "        2.6506e-02, 1.9905e-02, 2.8330e-02, 2.9818e-02, 2.4290e-02, 2.8685e-02,\n",
      "        2.1784e-02, 3.4112e-02, 2.5083e-02, 2.0336e-02, 2.3245e-02, 1.8708e-02,\n",
      "        2.1090e-02, 2.1366e-02, 2.6706e-02, 2.1001e-02, 2.8284e-02, 2.2177e-02,\n",
      "        1.9836e-02, 2.1524e-02, 3.5713e-02, 2.3415e-02, 3.2988e-02, 2.7230e-02,\n",
      "        2.6160e-02, 1.7363e-02, 2.5339e-02, 4.0673e-02, 1.8374e-02, 2.1281e-02,\n",
      "        2.3273e-02, 2.4743e-02, 2.2451e-02, 2.0421e-02, 1.6076e-02, 2.3679e-02,\n",
      "        2.3928e-02, 2.7551e-02, 2.6089e-02, 2.5147e-02, 1.9712e-02, 1.5260e-02,\n",
      "        2.7922e-02, 2.8318e-02, 2.6532e-02, 3.0000e-02, 2.5590e-02, 2.1428e-02,\n",
      "        2.8600e-02, 2.9706e-02, 3.0405e-02, 3.3952e-02, 2.9248e-02, 2.5003e-02,\n",
      "        1.6596e-02, 2.6496e-02, 3.0678e-02, 2.2254e-02, 2.6042e-02, 2.0365e-02,\n",
      "        2.2101e-02, 2.5427e-02, 2.5786e-02, 2.5897e-02, 2.4467e-02, 2.6013e-02,\n",
      "        2.8169e-02, 2.0749e-02, 2.1953e-02, 1.5383e-02, 3.1649e-02, 2.2677e-02,\n",
      "        2.1595e-02, 2.9922e-02, 2.4286e-02, 3.0654e-02, 2.3017e-02, 1.9180e-02,\n",
      "        3.1939e-02, 2.9666e-02, 2.8862e-02, 2.7442e-02, 2.4885e-02, 3.2022e-02,\n",
      "        2.2508e-02, 2.5928e-02, 3.7184e-02, 2.3293e-02, 2.0544e-02, 2.2662e-02,\n",
      "        2.9957e-02, 2.7254e-02, 3.0990e-02, 2.7131e-02, 2.7607e-02, 1.6234e-02,\n",
      "        3.5515e-02, 3.4813e-02, 2.2747e-02, 2.7962e-02, 2.7657e-02, 1.6870e-02,\n",
      "        3.2990e-02, 2.9549e-02, 5.6052e-45, 3.0877e-02, 2.9848e-02, 2.6316e-02,\n",
      "        2.7208e-02, 2.5101e-02, 2.0529e-02, 3.1254e-02, 2.4179e-02, 2.1643e-02,\n",
      "        1.6808e-02, 2.6106e-02, 2.5756e-02, 3.0896e-02, 3.2402e-02, 2.4694e-02,\n",
      "        2.9293e-02, 2.1926e-02, 2.3684e-02, 1.9745e-02, 2.5234e-02, 2.9602e-02,\n",
      "        3.0542e-02, 2.7159e-02, 2.5210e-02, 2.2639e-02, 2.2501e-02, 2.3235e-02,\n",
      "        2.1857e-02, 2.1691e-02, 2.1957e-02, 2.2141e-02, 1.7044e-02, 2.6585e-02,\n",
      "        3.6762e-02, 1.8665e-02, 2.4226e-02, 2.1187e-02, 1.6305e-02, 1.5444e-02,\n",
      "        2.8803e-02, 2.9486e-02, 2.1945e-02, 2.7412e-02, 2.2789e-02, 2.3863e-02,\n",
      "        2.1237e-02, 2.2512e-02, 1.7708e-02, 2.8363e-02, 2.8006e-02, 1.5226e-02,\n",
      "        2.3199e-02, 2.0545e-02, 2.5211e-02, 2.5271e-02, 2.1728e-02, 2.5368e-02,\n",
      "        2.3596e-02, 2.6639e-02, 2.3585e-02, 2.5715e-02, 2.9509e-02, 2.5808e-02,\n",
      "        2.2192e-02, 2.7341e-02, 3.0651e-02, 2.2074e-02, 3.2300e-02, 2.8512e-02,\n",
      "        3.6243e-02, 3.0593e-02, 3.1027e-02, 1.9899e-02, 2.3704e-02, 2.3984e-02,\n",
      "        2.4124e-02, 2.2666e-02, 2.5046e-02, 2.4065e-02, 2.7734e-02, 2.1346e-02,\n",
      "        2.7932e-02, 3.0146e-02, 1.9340e-02, 2.7695e-02, 1.6896e-02, 2.7282e-02,\n",
      "        1.9975e-02, 5.6052e-45, 2.8770e-02, 3.6866e-02, 5.6052e-45, 2.1860e-02,\n",
      "        2.4201e-02, 1.7111e-02, 2.1556e-02, 2.8034e-02, 2.2228e-02, 3.3042e-02,\n",
      "        1.7292e-02, 1.4772e-02, 3.1224e-02, 2.0729e-02, 2.6540e-02, 2.4638e-02,\n",
      "        1.8722e-02, 2.7119e-02, 2.5245e-02, 2.7518e-02, 3.0128e-02, 2.0745e-02,\n",
      "        2.0749e-02, 2.1211e-02, 2.2361e-02, 2.8237e-02, 1.8770e-02, 2.2230e-02,\n",
      "        2.2448e-02, 1.8030e-02, 2.7283e-02, 2.7746e-02, 1.9162e-02, 2.9731e-02,\n",
      "        2.2783e-02, 2.8056e-02, 1.9996e-02, 2.5846e-02, 2.2584e-02, 3.3450e-02,\n",
      "        1.8887e-02, 1.6138e-02, 1.7146e-02, 3.2145e-02, 2.9034e-02, 2.6859e-02,\n",
      "        2.0329e-02, 2.9207e-02, 3.1377e-02, 2.5171e-02, 2.6596e-02, 2.3942e-02,\n",
      "        2.4620e-02, 2.3658e-02, 3.0523e-02, 2.5841e-02, 2.1552e-02, 2.1222e-02,\n",
      "        2.3454e-02, 2.8033e-02, 1.9310e-02, 2.7053e-02, 2.1259e-02, 2.4865e-02,\n",
      "        2.2990e-02, 2.0503e-02, 2.0071e-02, 2.3299e-02, 1.7566e-02, 2.6515e-02,\n",
      "        2.3990e-02, 1.7919e-02, 1.7098e-02, 1.7766e-02, 2.0274e-02, 2.3571e-02,\n",
      "        2.1273e-02, 2.1412e-02, 2.7544e-02, 4.1347e-02, 1.7372e-02, 2.3688e-02,\n",
      "        3.7116e-02, 2.0048e-02, 2.4389e-02, 3.0964e-02, 1.7842e-02, 1.8707e-02,\n",
      "        2.6482e-02, 2.2534e-02, 2.1343e-02, 2.6810e-02, 2.6733e-02, 1.5602e-02,\n",
      "        2.2523e-02, 1.6039e-02, 2.9581e-02, 3.7454e-02, 2.5413e-02, 2.4608e-02,\n",
      "        4.3016e-02, 5.6052e-45, 2.1765e-02, 2.6989e-02, 2.0154e-02, 2.1134e-02,\n",
      "        2.9391e-02, 2.0690e-02, 2.8457e-02, 2.9238e-02, 3.1214e-02, 1.7191e-02,\n",
      "        2.6366e-02, 2.4894e-02, 2.3039e-02, 2.2162e-02, 1.7969e-02, 1.3717e-02,\n",
      "        1.9140e-02, 3.2648e-02, 2.3667e-02, 2.4688e-02, 3.7590e-02, 2.7250e-02,\n",
      "        2.4503e-02, 3.2881e-02, 2.2234e-02, 2.0534e-02, 1.6772e-02, 3.1245e-02,\n",
      "        2.3843e-02, 2.4003e-02, 2.0974e-02, 2.3737e-02, 2.0204e-02, 1.7432e-02,\n",
      "        2.5065e-02, 2.6074e-02])), ('encoder.convolutions.0.1.num_batches_tracked', tensor(18012)), ('encoder.convolutions.1.0.conv.weight', tensor([[[ 2.7133e-03,  6.7124e-03,  3.1116e-02,  5.6483e-03, -1.9771e-02],\n",
      "         [-3.6322e-02, -4.5292e-03,  7.2016e-03, -1.0809e-02,  5.7002e-03],\n",
      "         [-1.6750e-02, -2.9294e-03, -6.0191e-02, -4.4813e-02, -1.5179e-02],\n",
      "         ...,\n",
      "         [-4.7144e-03,  1.9112e-03,  3.3561e-02,  2.0176e-02, -5.6833e-03],\n",
      "         [ 9.1148e-03, -5.1219e-02, -5.6039e-02, -5.7709e-02, -1.4623e-02],\n",
      "         [ 2.6216e-02,  2.1862e-02,  2.9341e-02, -2.8450e-03, -2.9073e-02]],\n",
      "\n",
      "        [[ 8.1415e-03, -2.7458e-02,  1.6703e-02, -7.4050e-02,  2.3855e-02],\n",
      "         [-4.2007e-03,  1.3378e-02,  1.1411e-02,  1.5341e-02,  1.5083e-02],\n",
      "         [-2.4979e-03,  2.9622e-04, -6.4815e-03,  9.5628e-04, -5.4969e-03],\n",
      "         ...,\n",
      "         [ 1.0007e-02,  1.7320e-03, -2.0290e-02, -1.8274e-02,  1.6074e-02],\n",
      "         [ 6.7648e-03,  2.0236e-03, -3.0360e-05,  6.6405e-03,  6.8948e-03],\n",
      "         [-1.0620e-02,  1.3673e-02,  4.1194e-03,  1.8839e-02,  1.5593e-02]],\n",
      "\n",
      "        [[-4.2937e-02, -5.7184e-03,  1.4957e-02, -8.4169e-03, -1.1345e-02],\n",
      "         [-5.1379e-03, -6.6815e-02, -3.1012e-02, -2.1003e-02,  2.0950e-02],\n",
      "         [ 2.3573e-03,  9.0098e-03,  1.5808e-02, -2.9156e-02, -4.0090e-03],\n",
      "         ...,\n",
      "         [-1.5907e-02, -6.0951e-02, -4.2610e-02, -6.9147e-03, -3.1138e-02],\n",
      "         [-5.8045e-03, -5.0735e-03,  8.2300e-03,  1.4729e-02,  9.6058e-03],\n",
      "         [ 2.2479e-02,  6.9948e-03,  1.3583e-02,  7.1823e-03, -3.6520e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3289e-02,  7.7407e-03,  1.4573e-02, -1.3212e-02, -1.1187e-03],\n",
      "         [-1.0413e-02,  1.7696e-02, -1.2101e-03,  1.6291e-02,  2.6347e-02],\n",
      "         [-3.8823e-03,  1.5683e-02, -4.0556e-03, -2.2857e-03, -1.9900e-02],\n",
      "         ...,\n",
      "         [-1.6171e-02, -1.8974e-03,  1.2334e-02, -1.8400e-02, -3.6270e-03],\n",
      "         [ 1.4591e-02,  1.5759e-02,  1.5031e-02,  7.4561e-03,  8.4170e-03],\n",
      "         [ 5.8231e-03,  2.6846e-02,  3.9951e-02, -4.6014e-02,  5.4994e-05]],\n",
      "\n",
      "        [[ 2.7934e-02, -2.1483e-02,  1.7675e-02, -7.8464e-02,  2.1160e-02],\n",
      "         [-1.9145e-02, -4.4035e-02,  2.2294e-02,  1.9547e-02,  2.5359e-02],\n",
      "         [ 1.0849e-02,  9.5664e-03,  2.4870e-02,  9.9892e-03, -1.5866e-02],\n",
      "         ...,\n",
      "         [ 2.4274e-03,  1.3473e-03, -1.7049e-03,  7.2289e-03, -2.2957e-02],\n",
      "         [-5.5411e-03, -2.1007e-02,  9.2687e-03,  1.2330e-02, -2.6248e-02],\n",
      "         [ 5.6263e-03,  1.5446e-02,  6.6767e-03,  7.5797e-03, -5.1477e-03]],\n",
      "\n",
      "        [[ 9.9643e-03, -4.1666e-03,  1.1352e-02,  4.8316e-04,  2.9547e-02],\n",
      "         [ 4.6679e-04,  8.9052e-03,  4.9534e-03,  2.8780e-03,  9.0612e-03],\n",
      "         [-8.7087e-03, -2.8833e-02,  4.3147e-03,  9.8837e-03, -3.7970e-03],\n",
      "         ...,\n",
      "         [ 9.7856e-03, -2.4037e-02,  7.7056e-03, -1.4367e-02, -1.2395e-02],\n",
      "         [ 1.5530e-02, -1.0945e-03, -6.3667e-02, -7.4976e-02, -7.6379e-02],\n",
      "         [ 8.8255e-03,  1.9723e-02,  1.5762e-02,  5.8885e-03, -1.1802e-02]]])), ('encoder.convolutions.1.0.conv.bias', tensor([ 3.6148e-04, -5.5312e-05,  6.6524e-05,  5.6683e-04, -3.8867e-04,\n",
      "         2.5384e-04,  7.5565e-05,  4.7844e-04,  4.9159e-04,  4.5459e-04,\n",
      "         1.0962e-04, -4.7910e-04, -3.2072e-04,  5.3222e-04, -3.8138e-04,\n",
      "        -1.6183e-04, -3.8960e-04, -2.9339e-04, -4.1027e-04, -8.4040e-04,\n",
      "         4.1214e-04, -1.4120e-04,  2.0402e-05, -2.5266e-04, -8.4726e-05,\n",
      "        -2.3109e-04,  2.4345e-04,  5.2938e-04, -1.1807e-04,  2.7608e-04,\n",
      "        -7.4007e-04,  3.5482e-05,  1.1583e-04,  3.8622e-05, -1.1964e-04,\n",
      "         6.8173e-04,  1.9619e-04, -2.1554e-04,  5.2858e-04,  2.3960e-04,\n",
      "         6.5358e-04, -1.9427e-04,  2.8625e-04, -6.6732e-04,  4.3834e-04,\n",
      "        -6.4554e-05, -3.4510e-04,  4.6466e-04, -8.1434e-05,  2.5004e-04,\n",
      "        -5.1398e-04, -1.0700e-04, -3.7121e-05,  2.2986e-04, -2.0273e-04,\n",
      "         1.6810e-04,  6.4369e-05,  3.1242e-04, -2.5019e-04, -2.1301e-06,\n",
      "         7.0430e-04,  6.5628e-04,  3.0431e-06,  3.0876e-04,  1.7233e-04,\n",
      "        -4.0423e-04, -1.4019e-04,  2.2839e-04,  1.4102e-05,  4.3572e-05,\n",
      "        -4.9057e-04, -3.3684e-04, -5.5110e-05,  5.1031e-04, -2.6349e-04,\n",
      "         2.7263e-04, -6.3403e-04, -6.0196e-04,  2.3038e-04,  1.9393e-04,\n",
      "        -2.3141e-04,  1.2025e-03,  2.4208e-04,  1.6749e-04,  2.4035e-05,\n",
      "        -4.7881e-04,  7.0500e-04,  5.5324e-04,  6.0501e-04,  2.5682e-04,\n",
      "         1.3002e-04, -8.0279e-04,  5.1154e-04,  2.0459e-04,  5.8258e-04,\n",
      "         5.6180e-04, -1.5206e-05, -3.1879e-04,  1.1082e-04, -1.1773e-03,\n",
      "        -5.2325e-04, -6.5724e-04,  1.0404e-03,  3.6290e-04, -6.8055e-04,\n",
      "         8.2730e-04,  2.8763e-04, -1.5484e-04,  1.8143e-39,  6.2701e-04,\n",
      "         9.0287e-06,  6.2636e-04,  9.8095e-04, -3.5798e-04,  9.3015e-04,\n",
      "        -7.9474e-04, -1.7676e-04,  1.4215e-04, -1.1597e-04,  8.1287e-04,\n",
      "         1.4353e-04, -7.6327e-05,  1.7286e-04, -9.0800e-05, -1.0123e-03,\n",
      "        -6.6993e-04, -2.5379e-04, -5.6569e-39,  2.3708e-04,  6.5238e-04,\n",
      "        -9.4214e-04,  6.0870e-05, -8.4990e-05,  1.2654e-05,  3.1704e-04,\n",
      "        -7.4077e-04,  5.1021e-04,  1.5645e-04,  3.6228e-04, -1.0091e-03,\n",
      "        -8.6876e-04,  3.0822e-04, -3.9889e-04,  4.8808e-04, -2.1784e-04,\n",
      "         3.2568e-40,  9.9082e-04,  3.1788e-04, -1.6301e-04, -2.0905e-04,\n",
      "         3.6799e-04, -3.6553e-04,  5.7451e-04, -2.7923e-04, -5.5680e-04,\n",
      "         2.1764e-39,  2.9617e-04,  1.6989e-04, -4.3955e-04,  2.1476e-05,\n",
      "        -5.8733e-05,  3.6336e-39,  1.1097e-05, -7.3325e-04, -3.8339e-04,\n",
      "        -1.6550e-04, -1.8248e-05, -6.3337e-04,  1.4777e-04,  2.2400e-04,\n",
      "         2.2501e-04, -3.0757e-04, -7.7369e-04,  4.0782e-04,  1.3118e-04,\n",
      "        -1.5150e-03, -8.0447e-04,  1.4942e-04, -6.3540e-04, -7.0775e-04,\n",
      "        -5.3285e-04, -7.4102e-05, -3.8153e-04,  3.8515e-04,  2.6484e-04,\n",
      "        -1.3203e-04,  2.9068e-05, -2.4967e-04, -2.0751e-04, -3.5837e-04,\n",
      "        -2.2360e-04, -4.8468e-04,  3.7832e-05,  2.1398e-06,  5.4261e-05,\n",
      "        -2.0142e-04, -8.6935e-05,  2.1831e-04,  3.6164e-04,  7.1475e-05,\n",
      "        -3.3867e-04,  8.2402e-05,  7.9054e-04,  7.9224e-04, -2.6472e-04,\n",
      "         4.7161e-04, -3.2224e-04, -1.3614e-05, -8.9553e-05, -3.8153e-04,\n",
      "        -7.6037e-04,  6.8010e-05,  1.1334e-05, -1.0391e-03, -6.6261e-05,\n",
      "        -3.1812e-04, -1.1411e-05, -1.6719e-04,  3.1968e-04,  2.9759e-04,\n",
      "        -2.8133e-04, -3.9987e-04,  2.9188e-04, -3.9029e-05, -6.1853e-05,\n",
      "         3.3792e-04, -5.4698e-04, -4.6752e-04,  3.0824e-04,  1.6210e-04,\n",
      "         7.9241e-05, -6.5181e-04, -3.4960e-04, -7.7978e-04,  1.9262e-04,\n",
      "         4.7202e-04,  3.4233e-04,  3.5785e-05, -3.5165e-04, -1.3939e-04,\n",
      "        -8.3377e-04, -1.0006e-03,  8.0755e-04,  7.0442e-04,  3.3275e-04,\n",
      "        -2.2380e-04,  1.9942e-05,  4.8510e-05,  9.3225e-05, -7.8550e-05,\n",
      "        -5.1718e-39,  4.7773e-04, -2.8184e-05,  2.5250e-04, -6.6957e-04,\n",
      "         2.1836e-04,  2.0826e-04, -4.5855e-04,  6.3577e-04,  5.7166e-04,\n",
      "         3.0548e-04,  4.6728e-04,  4.1561e-04,  2.8567e-04,  8.3573e-04,\n",
      "        -3.5439e-04,  2.4033e-04,  1.8321e-04, -3.1534e-04, -3.9479e-04,\n",
      "         3.8030e-04,  7.8840e-04, -2.4228e-04,  2.6385e-04,  2.2682e-04,\n",
      "         9.1052e-04,  8.4492e-04,  4.0240e-04,  2.5792e-04, -1.9329e-04,\n",
      "         7.2833e-05,  3.9031e-04, -4.5915e-04, -5.3389e-39, -4.2233e-04,\n",
      "         3.2365e-04,  3.3796e-05,  2.6504e-04,  5.5492e-39,  3.0147e-04,\n",
      "        -8.3696e-05, -1.6844e-04,  3.3583e-04, -3.8791e-04, -3.4606e-04,\n",
      "         2.2053e-04,  5.3376e-04,  4.1965e-04,  3.9149e-04,  4.4223e-04,\n",
      "        -2.3549e-04, -6.3867e-05,  4.0133e-04,  1.1045e-04, -3.8067e-04,\n",
      "         1.3135e-04, -1.6621e-04, -8.3494e-05,  7.0801e-05, -4.4819e-05,\n",
      "        -1.0851e-04, -7.7525e-04, -2.3115e-04, -3.8557e-04, -3.0901e-04,\n",
      "         2.6382e-04, -6.5870e-04,  4.8899e-04,  8.0299e-04,  3.2091e-04,\n",
      "        -2.0674e-04, -4.9722e-04, -1.9369e-04,  3.4784e-04,  5.1263e-04,\n",
      "         4.5536e-04,  1.2598e-04,  5.3680e-04, -4.8949e-04,  2.5039e-04,\n",
      "         8.3679e-04,  2.5484e-05, -1.6987e-04, -2.9686e-04, -4.0143e-04,\n",
      "         5.2597e-07, -4.1228e-04, -2.6070e-04,  4.3403e-04, -8.7763e-05,\n",
      "        -7.8975e-04, -1.1414e-04,  3.0991e-04,  2.5464e-04,  5.0033e-04,\n",
      "         3.1821e-04,  3.3971e-05,  2.9949e-04, -2.6129e-04,  4.1288e-04,\n",
      "         5.6159e-04, -1.2097e-04,  5.2826e-39,  5.3866e-41, -5.6459e-04,\n",
      "         4.0925e-04, -5.2053e-40,  6.4949e-05, -4.3335e-04, -4.8311e-04,\n",
      "         2.6137e-04,  2.5032e-39, -5.2829e-04, -1.7736e-04, -6.4375e-05,\n",
      "        -2.9980e-04,  2.7058e-04,  9.8402e-06,  2.3282e-04,  1.7311e-04,\n",
      "         2.1377e-04, -3.9451e-04,  5.3080e-04,  4.2993e-05,  3.3747e-04,\n",
      "        -5.1003e-05,  2.1411e-04,  3.0418e-04,  2.6838e-04, -8.0826e-04,\n",
      "        -1.8631e-05, -1.3241e-04, -5.5904e-04, -2.8196e-04,  6.0689e-04,\n",
      "        -7.8016e-04, -8.9272e-05,  6.2021e-04, -8.5192e-04,  3.4069e-04,\n",
      "        -1.8299e-04,  9.9281e-05, -3.0908e-04, -9.2029e-04,  5.7720e-05,\n",
      "        -6.8095e-04,  3.3919e-04, -3.1526e-04, -1.1859e-04, -2.3501e-04,\n",
      "         4.4287e-04,  2.6586e-04,  1.7131e-04,  2.6641e-05, -3.7563e-04,\n",
      "        -7.7364e-04, -2.4540e-04, -2.4468e-04, -2.6849e-04, -1.7728e-04,\n",
      "         3.4989e-05,  3.1676e-04, -3.6432e-04, -3.4604e-04, -8.0464e-05,\n",
      "         3.0266e-04, -2.1775e-04,  7.5589e-05, -2.0543e-04, -9.9135e-04,\n",
      "         6.4197e-04, -4.1276e-04,  6.2569e-04,  3.4355e-04,  4.2372e-04,\n",
      "         1.0350e-04, -8.1131e-05, -5.0736e-04, -2.7469e-04,  2.4810e-04,\n",
      "        -1.0533e-04, -1.1722e-04, -4.0070e-04,  8.2995e-04,  5.6013e-05,\n",
      "         5.4661e-04,  1.3246e-04, -4.1848e-04,  1.4845e-04, -1.3457e-05,\n",
      "        -3.7461e-04, -1.0721e-04, -4.9448e-04, -2.2577e-04, -3.5495e-04,\n",
      "        -6.0302e-05,  4.7713e-04,  3.0160e-39,  1.6731e-04, -4.4896e-04,\n",
      "         1.2873e-04,  3.2860e-39, -1.2128e-04, -2.5921e-04,  7.4728e-05,\n",
      "         9.1525e-05, -2.7913e-04,  1.3842e-04,  3.1863e-04, -1.9756e-04,\n",
      "         1.8678e-04,  4.3396e-04, -3.4184e-04,  3.6924e-04, -2.4893e-05,\n",
      "         3.8815e-04,  4.4530e-05,  9.0763e-05,  2.0248e-04, -8.9451e-04,\n",
      "        -1.0824e-04, -7.2151e-05, -5.1077e-04, -4.5536e-04,  2.7527e-04,\n",
      "         1.3827e-04,  2.0109e-04,  4.6776e-06,  4.2170e-04,  3.3942e-04,\n",
      "         7.8422e-05,  6.6968e-04,  5.2955e-05,  1.3283e-04, -2.6064e-04,\n",
      "         4.4491e-04,  4.5024e-04,  1.3022e-04,  5.4600e-04, -4.0077e-41,\n",
      "        -3.3704e-04,  2.8800e-04, -9.5679e-05,  2.9708e-04, -1.5186e-04,\n",
      "        -3.7319e-04, -5.3468e-04, -4.9268e-06, -1.0991e-04,  7.4697e-05,\n",
      "         9.3020e-05,  8.6799e-05, -4.8418e-39, -2.5926e-04, -7.1865e-04,\n",
      "        -1.2516e-04,  2.3850e-04,  1.2360e-04, -4.8349e-04, -4.0416e-04,\n",
      "         3.3336e-04,  2.7730e-05])), ('encoder.convolutions.1.1.weight', tensor([ 2.9164e-01,  4.6044e-01,  4.6883e-01,  4.2187e-01,  3.0487e-01,\n",
      "         3.2647e-01,  5.1025e-01,  5.5650e-01,  4.0910e-01,  5.3600e-01,\n",
      "         3.6725e-01,  3.3415e-01,  4.2851e-01,  2.6069e-01,  3.9928e-01,\n",
      "         4.1822e-01,  2.9851e-01,  4.7641e-01,  3.1613e-01,  3.0985e-01,\n",
      "         3.3555e-01,  4.4592e-01,  5.1207e-01,  2.1491e-01,  3.5541e-01,\n",
      "         2.6662e-01,  4.2548e-01,  5.2361e-01,  5.1561e-01,  5.3131e-01,\n",
      "         4.6122e-01,  4.6612e-01,  2.2810e-01,  3.0596e-01,  4.6327e-01,\n",
      "         4.5027e-01,  3.7946e-01,  2.2998e-01,  3.4689e-01,  3.4596e-01,\n",
      "         4.2516e-01,  4.8998e-01,  5.9029e-01,  3.4857e-01,  2.8432e-01,\n",
      "         3.4658e-01,  4.2540e-01,  3.6258e-01,  4.1427e-01,  3.0338e-01,\n",
      "         4.2242e-01,  2.3164e-01,  3.0220e-01,  4.7385e-01,  2.5012e-01,\n",
      "         4.0477e-01,  4.4425e-01,  5.1568e-01,  3.1291e-01,  4.7338e-01,\n",
      "         3.4955e-01,  4.6280e-01,  3.1983e-01,  3.6862e-01,  5.7543e-01,\n",
      "         4.6477e-01,  5.0918e-01,  5.4268e-01,  3.2298e-01,  2.0955e-01,\n",
      "         4.3397e-01,  5.0555e-01,  4.4151e-01,  3.3254e-01,  4.7519e-01,\n",
      "         3.9696e-01,  5.1923e-01,  4.9657e-01,  2.5507e-01,  2.6466e-01,\n",
      "         2.8424e-01,  3.2835e-01,  2.7725e-01,  5.8756e-01,  3.4130e-01,\n",
      "         4.9909e-01,  3.5281e-01,  3.0521e-01,  4.2693e-01,  3.1987e-01,\n",
      "         4.0337e-01,  5.1676e-01,  3.5744e-01,  4.3554e-01,  4.2083e-01,\n",
      "         4.9767e-01,  4.3526e-01,  3.1177e-01,  5.2914e-01,  4.4708e-01,\n",
      "         3.9158e-01,  3.6788e-01,  4.1613e-01,  4.1516e-01,  5.1276e-01,\n",
      "         4.1922e-01,  4.1083e-01,  3.1312e-01,  2.5891e-12,  4.9654e-01,\n",
      "         4.3074e-01,  3.4418e-01,  3.1828e-01,  3.1522e-01,  4.2020e-01,\n",
      "         5.6042e-01,  3.9261e-01,  4.3781e-01,  3.9628e-01,  4.5953e-01,\n",
      "         4.1846e-01,  3.4159e-01,  5.0769e-01,  3.6038e-01,  4.6297e-01,\n",
      "         3.1464e-01,  3.4590e-01,  2.3272e-14,  4.2475e-01,  4.0107e-01,\n",
      "         4.6295e-01,  5.2919e-01,  3.5466e-01,  3.5453e-01,  5.9549e-01,\n",
      "         3.6962e-01,  4.4634e-01,  4.0175e-01,  3.9328e-01,  3.8385e-01,\n",
      "         3.6449e-01,  2.9388e-01,  3.9356e-01,  3.2840e-01,  3.8388e-01,\n",
      "         9.6056e-33,  4.8538e-01,  3.1369e-01,  3.8303e-01,  3.5889e-01,\n",
      "         2.1820e-01,  4.6457e-01,  3.0247e-01,  3.6034e-01,  5.0388e-01,\n",
      "         8.7612e-24,  4.6022e-01,  3.7594e-01,  4.4706e-01,  3.6450e-01,\n",
      "         4.9226e-01,  1.8475e-13,  5.1506e-01,  4.0173e-01,  5.1201e-01,\n",
      "         3.9096e-01,  6.5757e-01,  3.7607e-01,  3.5038e-01,  4.2405e-01,\n",
      "         4.1920e-01,  5.7870e-01,  3.0538e-01,  3.3616e-01,  2.9269e-01,\n",
      "         5.3602e-01,  4.7219e-01,  3.6726e-01,  3.6805e-01,  2.1707e-01,\n",
      "         4.8675e-01,  2.9556e-01,  3.6334e-01,  2.7988e-01,  3.9477e-01,\n",
      "         3.7063e-01,  4.8730e-01,  3.2695e-01,  2.9769e-01,  2.3379e-01,\n",
      "         3.4375e-01,  5.4583e-01,  3.2972e-01,  3.5527e-01,  3.8982e-01,\n",
      "         5.0779e-01,  2.6482e-01,  2.8857e-01,  3.6864e-01,  4.1139e-01,\n",
      "         2.9875e-01,  5.2085e-01,  3.0518e-01,  4.3832e-01,  3.9191e-01,\n",
      "         3.5978e-01,  2.5682e-01,  2.9881e-01,  3.6604e-01,  4.7966e-01,\n",
      "         4.5504e-01,  4.4187e-01,  2.9854e-01,  4.4991e-01,  4.6603e-01,\n",
      "         2.7431e-01,  4.9467e-01,  3.1769e-01,  4.7711e-01,  3.5178e-01,\n",
      "         5.0875e-01,  2.5119e-01,  3.1104e-01,  3.0521e-01,  4.5819e-01,\n",
      "         3.2977e-01,  3.3360e-01,  3.2335e-01,  3.0798e-01,  2.9853e-01,\n",
      "         4.4247e-01,  5.2123e-01,  4.6255e-01,  3.3971e-01,  4.5449e-01,\n",
      "         4.2499e-01,  3.2343e-01,  3.1436e-01,  4.1736e-01,  3.6258e-01,\n",
      "         5.0188e-01,  3.7790e-01,  4.8722e-01,  2.9574e-01,  3.1108e-01,\n",
      "         3.1391e-01,  3.3143e-01,  5.5365e-01,  3.4241e-01,  4.8367e-01,\n",
      "         3.5386e-13,  3.0172e-01,  3.0654e-01,  4.8453e-01,  5.0670e-01,\n",
      "         4.6625e-01,  4.9987e-01,  3.6190e-01,  4.3787e-01,  3.9079e-01,\n",
      "         5.3157e-01,  3.9688e-01,  2.4598e-01,  2.9757e-01,  5.1548e-01,\n",
      "         2.8444e-01,  4.6922e-01,  4.2879e-01,  4.4476e-01,  3.3745e-01,\n",
      "         3.8795e-01,  5.4748e-01,  3.2220e-01,  3.2441e-01,  3.9816e-01,\n",
      "         4.2969e-01,  4.5758e-01,  4.2297e-01,  4.6838e-01,  3.6399e-01,\n",
      "         3.3284e-01,  4.4632e-01,  4.5010e-01,  2.4545e-18,  3.4106e-01,\n",
      "         4.3938e-01,  3.8658e-01,  4.8934e-01,  9.1868e-22,  2.9374e-01,\n",
      "         4.0093e-01,  3.9669e-01,  3.8710e-01,  3.4716e-01,  3.5822e-01,\n",
      "         2.7040e-01,  4.7260e-01,  5.8900e-01,  3.8589e-01,  4.4097e-01,\n",
      "         5.9238e-01,  4.2675e-01,  4.3318e-01,  4.5376e-01,  4.3940e-01,\n",
      "         4.0213e-01,  5.0220e-01,  3.4376e-01,  4.3574e-01,  4.2529e-01,\n",
      "         4.5453e-01,  5.1799e-01,  3.0560e-01,  3.4305e-01,  2.9847e-01,\n",
      "         4.7820e-01,  4.6397e-01,  2.6166e-01,  3.8318e-01,  3.0984e-01,\n",
      "         4.0431e-01,  5.2938e-01,  5.0438e-01,  4.2039e-01,  4.0569e-01,\n",
      "         4.0736e-01,  3.2934e-01,  3.6881e-01,  4.4891e-01,  3.6954e-01,\n",
      "         4.2035e-01,  3.9960e-01,  3.3311e-01,  4.2368e-01,  3.1217e-01,\n",
      "         4.1043e-01,  3.7486e-01,  5.1543e-01,  4.5456e-01,  4.2007e-01,\n",
      "         4.7489e-01,  2.7641e-01,  3.6770e-01,  4.0756e-01,  2.6998e-01,\n",
      "         3.9800e-01,  3.8098e-01,  4.2461e-01,  3.4356e-01,  3.5457e-01,\n",
      "         4.5280e-01,  3.4744e-01,  3.4284e-26,  1.5398e-18,  4.0368e-01,\n",
      "         4.5846e-01,  1.7516e-19,  4.4891e-01,  3.3718e-01,  4.7758e-01,\n",
      "         3.3353e-01, -3.9762e-39,  3.4245e-01,  3.1796e-01,  4.1970e-01,\n",
      "         4.0884e-01,  3.3527e-01,  4.4538e-01,  3.8217e-01,  4.2753e-01,\n",
      "         3.4981e-01,  3.6938e-01,  4.3713e-01,  2.9194e-01,  4.8137e-01,\n",
      "         2.1697e-01,  3.0605e-01,  3.4140e-01,  3.3024e-01,  2.2754e-01,\n",
      "         4.4714e-01,  5.5859e-01,  4.1751e-01,  2.7621e-01,  4.5774e-01,\n",
      "         3.9968e-01,  4.2927e-01,  2.8646e-01,  3.0100e-01,  3.9154e-01,\n",
      "         3.7975e-01,  4.8608e-01,  3.9163e-01,  3.1594e-01,  4.8991e-01,\n",
      "         4.3645e-01,  4.7918e-01,  6.5394e-01,  3.8220e-01,  2.9625e-01,\n",
      "         4.7393e-01,  3.9356e-01,  3.6746e-01,  3.8575e-01,  3.6075e-01,\n",
      "         4.4794e-01,  4.3089e-01,  3.7782e-01,  4.0340e-01,  3.5235e-01,\n",
      "         2.7856e-01,  4.6096e-01,  3.9267e-01,  1.8837e-01,  4.5304e-01,\n",
      "         5.1776e-01,  2.8624e-01,  5.4522e-01,  3.0379e-01,  3.1795e-01,\n",
      "         4.2338e-01,  4.2544e-01,  4.4541e-01,  4.8365e-01,  4.2010e-01,\n",
      "         4.1549e-01,  3.4218e-01,  4.0028e-01,  3.8711e-01,  2.7285e-01,\n",
      "         4.6694e-01,  4.6612e-01,  4.8298e-01,  5.2597e-01,  2.8676e-01,\n",
      "         3.1431e-01,  3.6080e-01,  2.8807e-01,  4.3002e-01,  5.3792e-01,\n",
      "         2.9785e-01,  2.9470e-01,  3.3919e-01,  3.5979e-01,  2.5794e-01,\n",
      "         4.4764e-01,  5.0562e-01,  1.4750e-39,  2.5393e-01,  2.8470e-01,\n",
      "         5.3277e-01,  5.4751e-13,  2.2197e-01,  5.0544e-01,  2.8301e-01,\n",
      "         4.3693e-01,  5.2700e-01,  3.9002e-01,  3.4118e-01,  2.7057e-01,\n",
      "         2.8990e-01,  3.0433e-01,  2.4839e-01,  3.5779e-01,  4.5745e-01,\n",
      "         3.4775e-01,  3.0493e-01,  6.0373e-01,  3.5503e-01,  3.3746e-01,\n",
      "         3.7273e-01,  3.8157e-01,  4.8184e-01,  4.1877e-01,  4.4841e-01,\n",
      "         4.1416e-01,  4.0192e-01,  5.5027e-01,  3.3596e-01,  4.8022e-01,\n",
      "         5.8190e-01,  4.1084e-01,  4.4966e-01,  3.5032e-01,  3.1957e-01,\n",
      "         4.0340e-01,  4.0233e-01,  3.7430e-01,  3.5580e-01,  6.3939e-22,\n",
      "         3.9040e-01,  4.0852e-01,  2.7261e-01,  5.0908e-01,  3.2574e-01,\n",
      "         5.1920e-01,  2.0624e-01,  4.3399e-01,  4.5866e-01,  3.6016e-01,\n",
      "         3.2416e-01,  3.2089e-01, -2.0034e-37,  5.3417e-01,  4.3672e-01,\n",
      "         3.2445e-01,  4.0526e-01,  3.7231e-01,  3.4276e-01,  4.2498e-01,\n",
      "         4.2129e-01,  2.7571e-01])), ('encoder.convolutions.1.1.bias', tensor([-2.3969e-01, -2.4847e-01, -3.4692e-01, -3.3541e-01, -2.3496e-01,\n",
      "        -2.3137e-01, -2.5477e-01, -2.9915e-01, -3.1287e-01, -4.2838e-01,\n",
      "        -3.0970e-01, -2.7829e-01, -2.4202e-01, -2.1235e-01, -3.4000e-01,\n",
      "        -3.8949e-01, -2.0691e-01, -3.0412e-01, -2.2521e-01, -2.3297e-01,\n",
      "        -2.3518e-01, -2.7576e-01, -3.0788e-01, -1.4841e-01, -2.9950e-01,\n",
      "        -2.3418e-01, -3.4143e-01, -3.8970e-01, -4.1277e-01, -2.6224e-01,\n",
      "        -3.3562e-01, -3.1321e-01, -1.6512e-01, -2.4398e-01, -2.3635e-01,\n",
      "        -3.2907e-01, -2.9735e-01, -1.6937e-01, -2.9586e-01, -2.5397e-01,\n",
      "        -2.7374e-01, -3.6032e-01, -4.1402e-01, -2.4682e-01, -2.3115e-01,\n",
      "        -2.7788e-01, -3.3037e-01, -2.7457e-01, -2.8812e-01, -2.1052e-01,\n",
      "        -3.0374e-01, -1.6199e-01, -2.1169e-01, -2.8985e-01, -1.7738e-01,\n",
      "        -3.2660e-01, -3.4929e-01, -4.1108e-01, -1.9873e-01, -3.4609e-01,\n",
      "        -2.5939e-01, -3.1360e-01, -2.0077e-01, -3.9516e-01, -3.0061e-01,\n",
      "        -3.3162e-01, -4.1704e-01, -3.3355e-01, -2.1290e-01, -1.5266e-01,\n",
      "        -3.1710e-01, -3.7629e-01, -3.4877e-01, -2.2391e-01, -3.9130e-01,\n",
      "        -3.1599e-01, -4.1358e-01, -2.6160e-01, -2.0068e-01, -1.8562e-01,\n",
      "        -2.0197e-01, -2.3840e-01, -2.3224e-01, -4.2023e-01, -2.8698e-01,\n",
      "        -4.1262e-01, -2.4321e-01, -2.1528e-01, -3.0193e-01, -2.2462e-01,\n",
      "        -2.8591e-01, -4.2335e-01, -2.8689e-01, -5.1865e-01, -2.9323e-01,\n",
      "        -3.7127e-01, -3.0787e-01, -2.0964e-01, -2.6939e-01, -3.4649e-01,\n",
      "        -2.8741e-01, -2.1908e-01, -3.3501e-01, -3.2324e-01, -2.9744e-01,\n",
      "        -3.2119e-01, -2.7308e-01, -2.1585e-01, -1.1719e-13, -3.9728e-01,\n",
      "        -3.8354e-01, -2.4496e-01, -2.3076e-01, -2.4741e-01, -2.5945e-01,\n",
      "        -2.5982e-01, -3.0539e-01, -3.5746e-01, -2.5107e-01, -3.2415e-01,\n",
      "        -3.1588e-01, -2.1515e-01, -2.6548e-01, -2.7329e-01, -3.7462e-01,\n",
      "        -2.3432e-01, -2.4911e-01, -1.0518e-14, -3.6875e-01, -3.0617e-01,\n",
      "        -3.6024e-01, -3.1979e-01, -2.6218e-01, -2.8358e-01, -3.1402e-01,\n",
      "        -2.6432e-01, -3.4567e-01, -2.9133e-01, -2.9413e-01, -2.7601e-01,\n",
      "        -2.9025e-01, -2.3020e-01, -3.1525e-01, -2.0210e-01, -3.3726e-01,\n",
      "         6.2371e-39, -3.1655e-01, -1.9302e-01, -2.4982e-01, -3.0141e-01,\n",
      "        -1.7857e-01, -4.1716e-01, -2.3672e-01, -2.8763e-01, -3.5599e-01,\n",
      "        -1.8408e-23, -3.9301e-01, -3.0040e-01, -3.2764e-01, -2.9530e-01,\n",
      "        -3.3876e-01, -1.3139e-14, -4.1656e-01, -3.5819e-01, -3.4352e-01,\n",
      "        -2.8782e-01, -2.3644e-01, -2.3792e-01, -2.8512e-01, -2.6271e-01,\n",
      "        -3.1930e-01, -2.5710e-01, -1.9593e-01, -2.3112e-01, -1.7818e-01,\n",
      "        -2.3937e-01, -3.3893e-01, -2.3527e-01, -2.8302e-01, -1.5260e-01,\n",
      "        -3.2744e-01, -2.2857e-01, -3.3420e-01, -2.2310e-01, -2.5734e-01,\n",
      "        -2.8988e-01, -4.0237e-01, -2.7068e-01, -1.6755e-01, -1.7216e-01,\n",
      "        -2.3917e-01, -2.5852e-01, -2.4681e-01, -2.7391e-01, -3.4721e-01,\n",
      "        -3.5335e-01, -2.2311e-01, -1.9307e-01, -3.0709e-01, -2.9327e-01,\n",
      "        -2.0100e-01, -3.2890e-01, -2.2784e-01, -3.6065e-01, -3.1657e-01,\n",
      "        -3.3763e-01, -2.3300e-01, -2.2782e-01, -2.5439e-01, -3.1639e-01,\n",
      "        -3.6439e-01, -3.6646e-01, -2.5900e-01, -3.5359e-01, -3.3629e-01,\n",
      "        -2.0901e-01, -3.6416e-01, -2.5201e-01, -4.8464e-01, -2.3090e-01,\n",
      "        -3.6383e-01, -1.7800e-01, -2.0304e-01, -2.5343e-01, -3.1531e-01,\n",
      "        -2.6332e-01, -2.4044e-01, -2.3014e-01, -2.2462e-01, -2.6004e-01,\n",
      "        -3.0780e-01, -3.0552e-01, -4.1047e-01, -2.4085e-01, -3.6624e-01,\n",
      "        -3.7157e-01, -2.6037e-01, -2.5031e-01, -2.8426e-01, -2.3194e-01,\n",
      "        -3.4048e-01, -2.9843e-01, -3.7526e-01, -2.3988e-01, -2.0967e-01,\n",
      "        -1.8912e-01, -2.6831e-01, -4.6833e-01, -2.5284e-01, -4.1417e-01,\n",
      "        -2.3813e-13, -2.3526e-01, -2.5001e-01, -2.7699e-01, -4.6476e-01,\n",
      "        -3.3775e-01, -3.5711e-01, -2.1820e-01, -2.7107e-01, -3.0109e-01,\n",
      "        -4.2414e-01, -2.6833e-01, -1.7849e-01, -2.2213e-01, -3.0160e-01,\n",
      "        -1.9031e-01, -3.7052e-01, -3.1147e-01, -4.1657e-01, -2.5589e-01,\n",
      "        -2.8056e-01, -3.4452e-01, -2.4751e-01, -2.6327e-01, -3.5087e-01,\n",
      "        -2.9774e-01, -3.5493e-01, -3.3468e-01, -4.3123e-01, -3.1317e-01,\n",
      "        -2.6779e-01, -2.7142e-01, -3.3764e-01, -2.5151e-19, -2.1930e-01,\n",
      "        -2.2904e-01, -2.0764e-01, -4.0464e-01, -1.1342e-22, -2.3390e-01,\n",
      "        -2.9141e-01, -3.0163e-01, -2.9133e-01, -2.5903e-01, -2.8344e-01,\n",
      "        -1.9196e-01, -2.4596e-01, -4.0278e-01, -2.7523e-01, -2.7716e-01,\n",
      "        -2.7938e-01, -3.2288e-01, -3.1855e-01, -3.2179e-01, -3.3538e-01,\n",
      "        -3.6890e-01, -4.5959e-01, -1.9502e-01, -3.3125e-01, -3.4634e-01,\n",
      "        -3.4237e-01, -2.7869e-01, -2.2988e-01, -2.7417e-01, -1.9974e-01,\n",
      "        -4.0892e-01, -3.3878e-01, -1.7384e-01, -3.2579e-01, -1.8550e-01,\n",
      "        -3.0003e-01, -4.2667e-01, -2.2528e-01, -3.0816e-01, -2.8763e-01,\n",
      "        -3.6546e-01, -2.9387e-01, -2.0180e-01, -3.3374e-01, -3.0358e-01,\n",
      "        -2.8926e-01, -2.4010e-01, -2.2075e-01, -2.9074e-01, -2.4464e-01,\n",
      "        -3.0944e-01, -2.8921e-01, -4.1326e-01, -3.1778e-01, -3.2198e-01,\n",
      "        -3.6466e-01, -2.6528e-01, -3.0277e-01, -2.7024e-01, -2.3533e-01,\n",
      "        -2.9868e-01, -3.1114e-01, -3.4891e-01, -2.5362e-01, -2.7630e-01,\n",
      "        -2.7225e-01, -2.5393e-01, -2.3562e-39, -1.8668e-21, -3.1486e-01,\n",
      "        -3.6297e-01, -1.9421e-24, -3.8678e-01, -2.9749e-01, -3.6463e-01,\n",
      "        -2.1420e-01, -1.1190e-39, -2.3893e-01, -2.6552e-01, -2.8225e-01,\n",
      "        -3.0748e-01, -2.2917e-01, -3.4012e-01, -2.7378e-01, -3.4913e-01,\n",
      "        -2.6717e-01, -2.7505e-01, -4.3835e-01, -2.5926e-01, -2.8670e-01,\n",
      "        -1.5244e-01, -2.2424e-01, -2.6778e-01, -2.2355e-01, -1.7479e-01,\n",
      "        -3.6859e-01, -2.6601e-01, -3.9606e-01, -2.1434e-01, -3.5844e-01,\n",
      "        -2.6629e-01, -3.3224e-01, -2.1946e-01, -2.1956e-01, -3.6174e-01,\n",
      "        -2.2253e-01, -4.4267e-01, -3.1848e-01, -2.7463e-01, -3.8415e-01,\n",
      "        -3.2807e-01, -3.7624e-01, -2.1338e-01, -3.0091e-01, -2.5314e-01,\n",
      "        -3.2979e-01, -2.8688e-01, -2.6517e-01, -3.0481e-01, -2.5552e-01,\n",
      "        -3.0718e-01, -3.9900e-01, -2.8794e-01, -3.5399e-01, -2.8430e-01,\n",
      "        -2.2582e-01, -3.0579e-01, -2.9473e-01, -1.3914e-01, -3.0690e-01,\n",
      "        -3.9900e-01, -1.7834e-01, -2.4376e-01, -2.1853e-01, -1.9543e-01,\n",
      "        -3.5180e-01, -3.6147e-01, -3.7410e-01, -3.8421e-01, -3.2321e-01,\n",
      "        -2.3181e-01, -2.7260e-01, -3.7027e-01, -3.1457e-01, -1.7753e-01,\n",
      "        -2.8149e-01, -3.8491e-01, -3.4419e-01, -3.8052e-01, -2.1088e-01,\n",
      "        -2.6037e-01, -2.6242e-01, -3.0192e-01, -3.4058e-01, -2.4592e-01,\n",
      "        -2.2393e-01, -2.1175e-01, -3.2058e-01, -2.8040e-01, -1.7842e-01,\n",
      "        -2.7266e-01, -3.6942e-01, -3.2453e-39, -1.8469e-01, -2.1835e-01,\n",
      "        -4.0149e-01, -2.7534e-14, -1.4749e-01, -3.7271e-01, -2.0424e-01,\n",
      "        -3.2970e-01, -3.5599e-01, -3.1304e-01, -2.5995e-01, -2.3172e-01,\n",
      "        -2.3321e-01, -2.4905e-01, -1.6519e-01, -2.9763e-01, -3.6201e-01,\n",
      "        -3.0145e-01, -2.0891e-01, -3.0559e-01, -2.6078e-01, -3.1517e-01,\n",
      "        -2.9346e-01, -2.8976e-01, -3.4492e-01, -3.0561e-01, -3.5469e-01,\n",
      "        -2.7830e-01, -2.7739e-01, -3.3494e-01, -2.1024e-01, -4.0956e-01,\n",
      "        -4.1668e-01, -2.7184e-01, -2.9955e-01, -2.4998e-01, -2.2512e-01,\n",
      "        -2.7329e-01, -3.8601e-01, -2.6746e-01, -2.6127e-01, -1.9723e-27,\n",
      "        -2.9047e-01, -3.3252e-01, -1.8929e-01, -3.2373e-01, -2.5597e-01,\n",
      "        -3.8473e-01, -1.2876e-01, -3.0744e-01, -4.2923e-01, -1.7953e-01,\n",
      "        -2.4685e-01, -2.5246e-01, -9.0595e-36, -4.0488e-01, -3.9660e-01,\n",
      "        -2.2736e-01, -3.1670e-01, -2.6896e-01, -2.2618e-01, -2.4260e-01,\n",
      "        -2.8634e-01, -1.9355e-01])), ('encoder.convolutions.1.1.running_mean', tensor([-1.3075e-01, -2.0460e-01, -2.0108e-01, -2.2941e-01, -1.5806e-01,\n",
      "        -1.2659e-01, -2.0421e-01, -1.9251e-01, -2.0473e-01, -2.1576e-01,\n",
      "        -1.7291e-01, -1.7375e-01, -2.1082e-01, -1.7518e-01, -1.2147e-01,\n",
      "        -1.7873e-01, -7.9231e-02, -2.1874e-01, -1.9140e-01, -9.6088e-02,\n",
      "        -2.1888e-01, -2.1707e-01, -2.7932e-01, -1.0480e-01, -1.6908e-01,\n",
      "        -1.6975e-01, -1.8840e-01, -2.4838e-01, -2.3128e-01, -1.8030e-01,\n",
      "        -2.4679e-01, -2.3412e-01, -3.4501e-03, -1.0076e-01, -2.4160e-01,\n",
      "        -1.6862e-01, -1.7132e-01, -1.0787e-01, -1.9739e-01, -2.0727e-01,\n",
      "        -2.5411e-01, -2.4577e-01, -2.7865e-01, -1.5431e-01, -1.6107e-01,\n",
      "        -1.4174e-01, -1.7564e-01, -1.7570e-01, -2.2822e-01, -2.0805e-01,\n",
      "        -1.8603e-01, -1.0267e-01, -1.5846e-01, -1.9611e-01, -1.4032e-01,\n",
      "        -2.2702e-01, -2.2577e-01, -2.4579e-01, -1.5100e-01, -2.1648e-01,\n",
      "        -2.1053e-01, -1.9957e-01, -2.5000e-01, -2.1065e-01, -2.1710e-01,\n",
      "        -2.0427e-01, -3.0072e-01, -2.5862e-01, -1.6161e-01, -9.8628e-02,\n",
      "        -2.5625e-01, -2.4212e-01, -2.4077e-01, -1.9946e-01, -2.5114e-01,\n",
      "        -1.9876e-01, -2.4142e-01, -1.3289e-01, -9.6293e-02, -1.0822e-01,\n",
      "        -6.8341e-02, -2.5694e-01, -1.6588e-01, -2.7503e-01, -1.5451e-01,\n",
      "        -2.3483e-01, -1.7509e-01, -1.0073e-01, -2.4703e-01, -1.3566e-01,\n",
      "        -2.1051e-01, -1.9680e-01, -2.0279e-01, -2.2009e-01, -1.9040e-01,\n",
      "        -2.4849e-01, -2.1293e-01, -1.0904e-01, -1.2856e-01, -2.5176e-01,\n",
      "        -1.9314e-01, -2.5344e-01, -2.4747e-01, -2.3475e-01, -2.7437e-01,\n",
      "        -2.2770e-01, -2.2640e-01, -1.9060e-01,  5.6052e-45, -2.1884e-01,\n",
      "        -1.7157e-01, -1.8944e-01, -1.3914e-01, -1.9367e-01, -1.8528e-01,\n",
      "        -1.7653e-01, -2.3135e-01, -1.3414e-01, -2.1716e-01, -2.4187e-01,\n",
      "        -1.7551e-01, -1.8630e-01, -2.0486e-01, -2.3785e-01, -2.3759e-01,\n",
      "        -1.4885e-01, -2.2287e-01, -5.6052e-45, -1.7737e-01, -1.5356e-01,\n",
      "        -1.6411e-01, -2.3724e-01, -1.7535e-01, -2.1755e-01, -1.4156e-01,\n",
      "        -1.5977e-01, -1.9959e-01, -2.3803e-01, -2.5209e-01, -1.5953e-01,\n",
      "        -1.6904e-01, -1.6176e-01, -2.3796e-01, -1.4937e-01, -2.1283e-01,\n",
      "         5.6052e-45, -1.8208e-01, -1.4690e-01, -2.2913e-01, -1.4824e-01,\n",
      "        -4.4639e-02, -1.1960e-01, -1.4469e-01, -1.7232e-01, -2.3890e-01,\n",
      "        -5.6052e-45, -1.9048e-01, -2.4222e-01, -1.7855e-01, -2.4509e-01,\n",
      "        -2.2144e-01,  5.6052e-45, -2.2423e-01, -1.7354e-01, -2.0963e-01,\n",
      "        -1.6612e-01, -1.8999e-01, -2.4608e-01, -1.1183e-01, -2.5432e-01,\n",
      "        -2.0483e-01, -1.9557e-01, -1.8922e-01, -1.1537e-01, -1.5063e-01,\n",
      "        -2.0778e-01, -2.7267e-01, -2.5882e-01, -1.8806e-01, -1.0559e-01,\n",
      "        -2.4491e-01, -1.0551e-01, -1.9163e-01, -1.7565e-01, -1.5494e-01,\n",
      "        -1.9667e-01, -2.0219e-01, -1.5178e-01, -2.0043e-01, -1.4886e-01,\n",
      "        -2.1204e-01, -1.7719e-01, -1.7545e-01, -1.7828e-01, -2.0578e-01,\n",
      "        -2.8368e-01, -6.1493e-02, -1.1080e-01, -1.6165e-01, -2.2309e-01,\n",
      "        -1.2732e-01, -2.5024e-01, -1.1104e-01, -1.9215e-01, -1.6847e-01,\n",
      "        -2.0057e-01, -1.1932e-01, -1.3564e-01, -1.9558e-01, -1.8368e-01,\n",
      "        -2.1584e-01, -1.7644e-01, -1.6860e-01, -2.2697e-01, -2.3654e-01,\n",
      "        -1.8999e-01, -2.6285e-01, -5.8910e-02, -2.3314e-01, -1.8475e-01,\n",
      "        -2.4502e-01, -1.8253e-01, -1.9679e-01, -1.2237e-01, -1.7206e-01,\n",
      "        -1.8002e-01, -1.0600e-01, -1.8224e-01, -1.3003e-01, -9.3117e-02,\n",
      "        -1.6273e-01, -2.2457e-01, -2.0498e-01, -1.5126e-01, -1.9435e-01,\n",
      "        -2.3693e-01, -1.7846e-01, -1.3741e-01, -2.1731e-01, -2.1820e-01,\n",
      "        -1.9862e-01, -1.9293e-01, -2.4020e-01, -2.4329e-01, -1.5742e-01,\n",
      "        -2.1716e-01, -1.5748e-01, -2.7690e-01, -2.1657e-01, -2.1272e-01,\n",
      "         5.6052e-45, -5.3583e-02, -1.0247e-01, -1.1202e-01, -1.5146e-01,\n",
      "        -2.0033e-01, -1.9307e-01, -2.3119e-01, -2.1821e-01, -2.2668e-01,\n",
      "        -2.6901e-01, -2.5252e-01, -1.1927e-01, -7.9330e-02, -2.3335e-01,\n",
      "        -1.5032e-01, -1.8134e-01, -2.4983e-01, -1.5749e-01, -2.2459e-01,\n",
      "        -1.4963e-01, -2.5037e-01, -1.8190e-01, -6.1264e-02, -2.0559e-01,\n",
      "        -2.4775e-01, -2.0804e-01, -1.7831e-01, -1.8880e-01, -1.5421e-01,\n",
      "        -1.8496e-01, -1.5721e-01, -2.1608e-01,  5.6052e-45, -1.6328e-01,\n",
      "        -1.9653e-01, -1.2696e-01, -2.2687e-01, -5.6052e-45, -7.8088e-02,\n",
      "        -1.3784e-01, -1.5924e-01, -2.3215e-01, -1.3874e-01, -1.8380e-01,\n",
      "        -1.2741e-01, -2.1217e-01, -2.2130e-01, -1.9216e-01, -2.1640e-01,\n",
      "        -1.5686e-01, -1.7200e-01, -2.3777e-01, -2.3654e-01, -2.2103e-01,\n",
      "        -1.7867e-01, -2.1229e-01, -1.9028e-01, -2.2898e-01, -1.4346e-01,\n",
      "        -1.9861e-01, -2.3284e-01, -1.3807e-01, -2.3618e-01, -1.5731e-01,\n",
      "        -2.1838e-01, -2.1809e-01, -1.2749e-01, -1.7045e-01, -1.8526e-01,\n",
      "        -2.0632e-01, -2.3147e-01, -1.6887e-01, -2.9079e-01, -2.0844e-01,\n",
      "        -1.9579e-01, -1.7079e-01, -1.6345e-01, -1.9302e-01, -2.3248e-01,\n",
      "        -2.9031e-01, -2.2704e-01, -1.5484e-01, -1.8617e-01, -2.7953e-01,\n",
      "        -2.2770e-01, -1.8505e-01, -2.0825e-01, -1.8651e-01, -1.8423e-01,\n",
      "        -2.4385e-01, -1.2650e-01, -1.2787e-01, -1.3579e-01,  6.7770e-03,\n",
      "        -1.2758e-01, -2.0779e-01, -1.1637e-01, -1.4765e-01, -1.4526e-01,\n",
      "        -2.4816e-01, -1.8086e-01,  5.6052e-45,  5.6052e-45, -2.2437e-01,\n",
      "        -1.7875e-01,  5.6052e-45, -1.8541e-01, -1.0338e-01, -2.3997e-01,\n",
      "        -1.5935e-01,  5.6052e-45, -1.7895e-01, -1.6904e-01, -2.1111e-01,\n",
      "        -2.1205e-01, -1.7715e-01, -2.1021e-01, -2.7203e-01, -1.4996e-01,\n",
      "        -2.1575e-01, -1.9009e-01, -2.4284e-01, -1.7783e-01, -2.2950e-01,\n",
      "        -6.9749e-02, -1.7823e-01, -1.1110e-01, -1.3959e-01, -9.9429e-02,\n",
      "        -1.7966e-01, -1.6641e-01, -2.0612e-01, -1.0190e-01, -2.3104e-01,\n",
      "        -1.8691e-01, -2.3432e-01, -1.1179e-01, -1.1088e-01, -1.6560e-01,\n",
      "        -1.4044e-01, -2.2910e-01, -1.7069e-01, -1.6191e-01, -2.7899e-01,\n",
      "        -2.6044e-01, -2.0669e-01, -2.0409e-01, -2.9158e-01, -1.2094e-01,\n",
      "        -2.6903e-01, -1.6821e-01, -1.9537e-01, -2.0284e-01, -2.1852e-01,\n",
      "        -1.7259e-01, -1.8430e-01, -1.7574e-01, -1.7016e-01, -2.0803e-01,\n",
      "        -1.5433e-01, -2.3360e-01, -2.0954e-01, -3.5030e-02, -2.5375e-01,\n",
      "        -2.3114e-01, -1.8992e-01, -2.0285e-01, -1.9408e-01, -1.9234e-01,\n",
      "        -1.7441e-01, -1.9673e-01, -1.9955e-01, -2.0213e-01, -1.4818e-01,\n",
      "        -1.5597e-01, -2.5669e-01, -4.7727e-02, -1.7336e-01, -1.2933e-01,\n",
      "        -2.3754e-01, -2.3574e-01, -2.0748e-01, -2.5799e-01, -1.2285e-01,\n",
      "        -1.1659e-01, -2.1170e-01,  6.7533e-02, -2.0785e-01, -2.0494e-01,\n",
      "        -1.4428e-01, -2.0681e-01, -1.7727e-01, -1.1871e-01, -9.0870e-02,\n",
      "        -2.0248e-01, -1.9945e-01,  5.6052e-45, -2.3697e-02, -1.5305e-01,\n",
      "        -2.3970e-01,  5.6052e-45, -1.3427e-01, -1.8514e-01, -1.3645e-01,\n",
      "        -2.6215e-01, -2.0666e-01, -1.7529e-01, -1.4396e-01, -1.5902e-01,\n",
      "        -1.2269e-01, -1.6164e-01, -1.8807e-01, -1.9609e-01, -1.5466e-01,\n",
      "        -2.7423e-01, -2.0255e-01, -2.6168e-01, -1.6785e-01, -1.6608e-01,\n",
      "        -1.8212e-01, -2.2127e-01, -2.1955e-01, -2.0607e-01, -2.4014e-01,\n",
      "        -2.0883e-01, -2.3818e-01, -2.2004e-01, -1.7009e-01, -1.9346e-01,\n",
      "        -2.0812e-01, -2.4734e-01, -2.5361e-01, -1.2729e-01, -1.7391e-01,\n",
      "        -2.4717e-01, -2.0337e-01, -2.4752e-01, -1.5673e-01,  5.6052e-45,\n",
      "        -2.0715e-01, -1.2919e-01, -1.6844e-01, -2.1833e-01, -1.6482e-01,\n",
      "        -2.7406e-01, -1.4221e-01, -2.0798e-01, -1.7130e-01, -1.3038e-01,\n",
      "        -1.3885e-01, -1.5281e-01, -5.6052e-45, -2.4163e-01, -2.0970e-01,\n",
      "        -1.8930e-01, -2.1714e-01, -1.6665e-01, -2.0744e-01, -9.0326e-02,\n",
      "        -1.8840e-01, -1.6884e-01])), ('encoder.convolutions.1.1.running_var', tensor([2.3935e-02, 4.4448e-02, 3.6638e-02, 3.1371e-02, 2.7289e-02, 3.1154e-02,\n",
      "        4.7690e-02, 4.2828e-02, 3.0338e-02, 3.7316e-02, 2.6336e-02, 3.7836e-02,\n",
      "        4.1407e-02, 2.5711e-02, 3.0870e-02, 2.9952e-02, 3.4782e-02, 3.0923e-02,\n",
      "        3.5138e-02, 2.4564e-02, 3.6394e-02, 4.4364e-02, 4.1954e-02, 2.4354e-02,\n",
      "        3.0354e-02, 2.1671e-02, 3.3982e-02, 3.6066e-02, 3.6355e-02, 4.9710e-02,\n",
      "        3.5427e-02, 3.6688e-02, 2.4992e-02, 3.2738e-02, 3.9214e-02, 4.2976e-02,\n",
      "        3.0268e-02, 2.0263e-02, 2.6664e-02, 3.2012e-02, 5.6372e-02, 3.3795e-02,\n",
      "        4.2204e-02, 3.1501e-02, 2.6158e-02, 2.8139e-02, 3.4417e-02, 2.9259e-02,\n",
      "        3.8829e-02, 2.6193e-02, 3.2856e-02, 2.3807e-02, 2.6911e-02, 3.9599e-02,\n",
      "        2.5687e-02, 4.0612e-02, 3.4271e-02, 3.5067e-02, 3.2057e-02, 3.6448e-02,\n",
      "        2.9588e-02, 3.3761e-02, 2.8917e-02, 2.7604e-02, 6.0359e-02, 4.3721e-02,\n",
      "        3.8042e-02, 4.5044e-02, 3.2337e-02, 2.0326e-02, 3.6810e-02, 3.3508e-02,\n",
      "        3.0325e-02, 2.6707e-02, 3.6438e-02, 3.4687e-02, 3.8251e-02, 4.7528e-02,\n",
      "        2.7567e-02, 2.8171e-02, 2.6028e-02, 2.7942e-02, 2.7589e-02, 5.2508e-02,\n",
      "        2.9301e-02, 3.6007e-02, 3.0158e-02, 3.2875e-02, 3.6996e-02, 2.6581e-02,\n",
      "        3.3370e-02, 4.0881e-02, 3.3125e-02, 3.3573e-02, 3.3997e-02, 3.2134e-02,\n",
      "        3.6648e-02, 2.9595e-02, 4.7287e-02, 3.4172e-02, 3.3867e-02, 3.4899e-02,\n",
      "        3.2946e-02, 2.8826e-02, 6.7683e-02, 4.4643e-02, 3.6856e-02, 2.9537e-02,\n",
      "        5.6052e-45, 3.1644e-02, 3.2242e-02, 2.9904e-02, 2.8223e-02, 2.9395e-02,\n",
      "        3.3145e-02, 4.5646e-02, 2.8839e-02, 3.3382e-02, 3.4845e-02, 3.8728e-02,\n",
      "        3.4140e-02, 2.9546e-02, 3.8591e-02, 2.5985e-02, 2.8371e-02, 3.1400e-02,\n",
      "        2.5128e-02, 5.6052e-45, 3.2880e-02, 3.1282e-02, 3.5574e-02, 4.3133e-02,\n",
      "        2.7509e-02, 3.3724e-02, 4.2580e-02, 3.6851e-02, 3.1600e-02, 3.1439e-02,\n",
      "        3.4047e-02, 3.3615e-02, 3.9192e-02, 2.5248e-02, 3.3015e-02, 3.1172e-02,\n",
      "        3.1836e-02, 5.6052e-45, 3.5602e-02, 3.0140e-02, 3.0220e-02, 2.8348e-02,\n",
      "        2.0658e-02, 3.7129e-02, 2.9861e-02, 2.8811e-02, 3.3658e-02, 5.6052e-45,\n",
      "        3.5540e-02, 3.8243e-02, 3.8102e-02, 3.1887e-02, 4.0479e-02, 5.6052e-45,\n",
      "        3.6372e-02, 3.1059e-02, 3.8265e-02, 3.4978e-02, 5.1418e-02, 3.3917e-02,\n",
      "        2.7664e-02, 3.6883e-02, 3.6596e-02, 4.4090e-02, 2.8236e-02, 3.0656e-02,\n",
      "        2.6518e-02, 4.4795e-02, 3.5991e-02, 3.0195e-02, 2.7721e-02, 1.8423e-02,\n",
      "        3.2384e-02, 2.8151e-02, 3.3417e-02, 2.4010e-02, 3.3482e-02, 3.4175e-02,\n",
      "        3.5909e-02, 2.9065e-02, 2.7844e-02, 2.4805e-02, 3.0367e-02, 3.7864e-02,\n",
      "        3.0649e-02, 2.9706e-02, 2.9005e-02, 3.9024e-02, 2.4081e-02, 2.8574e-02,\n",
      "        2.7239e-02, 3.6829e-02, 2.8840e-02, 3.6516e-02, 3.0041e-02, 2.8873e-02,\n",
      "        2.8110e-02, 2.9486e-02, 2.0978e-02, 2.9236e-02, 3.1254e-02, 4.0050e-02,\n",
      "        3.3446e-02, 3.4959e-02, 2.8408e-02, 3.8241e-02, 3.9991e-02, 2.6809e-02,\n",
      "        3.5548e-02, 2.5344e-02, 3.7100e-02, 3.2784e-02, 4.2281e-02, 3.1338e-02,\n",
      "        2.8999e-02, 3.1782e-02, 3.7955e-02, 3.7659e-02, 3.3995e-02, 2.7732e-02,\n",
      "        2.7419e-02, 2.7457e-02, 3.8196e-02, 3.4868e-02, 3.5705e-02, 3.1316e-02,\n",
      "        3.5119e-02, 3.5451e-02, 2.6495e-02, 2.9089e-02, 3.7669e-02, 2.9776e-02,\n",
      "        4.1687e-02, 2.9646e-02, 3.9081e-02, 2.8839e-02, 2.7146e-02, 3.2248e-02,\n",
      "        2.9080e-02, 3.6455e-02, 3.3458e-02, 4.0215e-02, 5.6052e-45, 3.0982e-02,\n",
      "        2.7930e-02, 3.1999e-02, 3.4693e-02, 3.3268e-02, 4.2898e-02, 3.1598e-02,\n",
      "        4.5685e-02, 3.3226e-02, 3.5085e-02, 3.2775e-02, 2.3480e-02, 2.8170e-02,\n",
      "        4.3476e-02, 2.8345e-02, 3.5441e-02, 3.2596e-02, 3.3482e-02, 2.5720e-02,\n",
      "        3.2094e-02, 5.8187e-02, 2.6309e-02, 3.0210e-02, 2.9259e-02, 3.5680e-02,\n",
      "        2.7116e-02, 3.1715e-02, 3.5795e-02, 2.8094e-02, 2.6349e-02, 2.8371e-02,\n",
      "        3.2382e-02, 5.6052e-45, 3.1766e-02, 4.2202e-02, 3.6160e-02, 3.6548e-02,\n",
      "        5.6052e-45, 2.4789e-02, 3.4522e-02, 3.5101e-02, 3.7965e-02, 3.1714e-02,\n",
      "        3.1063e-02, 3.0134e-02, 5.4194e-02, 4.4136e-02, 3.5375e-02, 3.7311e-02,\n",
      "        4.9673e-02, 3.4026e-02, 3.3079e-02, 3.2950e-02, 3.0032e-02, 3.0792e-02,\n",
      "        3.3980e-02, 3.4960e-02, 3.4605e-02, 2.9114e-02, 3.3816e-02, 4.8723e-02,\n",
      "        2.6354e-02, 3.2532e-02, 3.0906e-02, 3.4601e-02, 3.7918e-02, 2.5589e-02,\n",
      "        2.7999e-02, 3.0225e-02, 3.3348e-02, 4.1701e-02, 4.4680e-02, 2.8490e-02,\n",
      "        3.6428e-02, 3.1676e-02, 3.0637e-02, 3.7685e-02, 3.4464e-02, 3.2778e-02,\n",
      "        3.9400e-02, 5.1538e-02, 3.1639e-02, 5.3522e-02, 3.0115e-02, 2.9999e-02,\n",
      "        3.4314e-02, 4.0772e-02, 3.5705e-02, 3.4683e-02, 3.7039e-02, 2.3350e-02,\n",
      "        3.1087e-02, 4.2084e-02, 2.5044e-02, 3.6390e-02, 3.3264e-02, 3.2131e-02,\n",
      "        2.9466e-02, 3.1566e-02, 3.9820e-02, 3.3920e-02, 5.6052e-45, 5.6052e-45,\n",
      "        3.0053e-02, 3.3865e-02, 5.6052e-45, 3.6573e-02, 2.5283e-02, 3.6736e-02,\n",
      "        2.9493e-02, 5.6052e-45, 2.6308e-02, 2.5839e-02, 3.9247e-02, 4.0452e-02,\n",
      "        2.9480e-02, 3.2679e-02, 2.7068e-02, 3.3357e-02, 2.5879e-02, 3.0224e-02,\n",
      "        3.4599e-02, 2.7444e-02, 4.0893e-02, 2.2316e-02, 2.8504e-02, 2.6359e-02,\n",
      "        2.8352e-02, 2.3559e-02, 2.9485e-02, 5.0148e-02, 3.2957e-02, 2.8635e-02,\n",
      "        3.4696e-02, 3.2856e-02, 3.0991e-02, 2.5268e-02, 3.2006e-02, 3.1884e-02,\n",
      "        3.5435e-02, 3.3846e-02, 3.1879e-02, 2.6605e-02, 4.1141e-02, 3.2257e-02,\n",
      "        4.7680e-02, 5.6833e-02, 3.0872e-02, 2.4363e-02, 3.6887e-02, 3.5393e-02,\n",
      "        3.1311e-02, 3.3390e-02, 3.2023e-02, 3.5421e-02, 3.4058e-02, 4.2569e-02,\n",
      "        3.2386e-02, 3.2618e-02, 2.6674e-02, 4.0690e-02, 3.0582e-02, 2.0518e-02,\n",
      "        3.6029e-02, 4.1977e-02, 3.0379e-02, 4.0253e-02, 2.5195e-02, 2.7663e-02,\n",
      "        3.2983e-02, 3.7074e-02, 3.4254e-02, 3.6992e-02, 3.5971e-02, 2.9556e-02,\n",
      "        3.7878e-02, 3.1604e-02, 2.6370e-02, 2.7387e-02, 5.7703e-02, 3.3497e-02,\n",
      "        4.5044e-02, 3.5390e-02, 3.2110e-02, 2.7264e-02, 2.8810e-02, 3.8455e-02,\n",
      "        2.8315e-02, 4.6006e-02, 2.9267e-02, 2.4054e-02, 2.6206e-02, 3.1877e-02,\n",
      "        3.0338e-02, 3.7963e-02, 3.5383e-02, 5.6052e-45, 2.7036e-02, 2.8549e-02,\n",
      "        3.9329e-02, 5.6052e-45, 2.2073e-02, 3.6394e-02, 2.8031e-02, 3.0524e-02,\n",
      "        4.0952e-02, 2.9152e-02, 3.2903e-02, 2.5370e-02, 2.3584e-02, 2.7960e-02,\n",
      "        3.1189e-02, 2.9469e-02, 4.1867e-02, 2.8530e-02, 2.8971e-02, 4.7867e-02,\n",
      "        2.7900e-02, 2.9657e-02, 2.8383e-02, 3.2075e-02, 3.5209e-02, 3.1982e-02,\n",
      "        3.2984e-02, 3.3289e-02, 3.4915e-02, 4.2600e-02, 3.1622e-02, 3.3949e-02,\n",
      "        4.8557e-02, 5.1978e-02, 3.5982e-02, 3.5379e-02, 2.8652e-02, 3.3552e-02,\n",
      "        3.2817e-02, 3.0648e-02, 2.9475e-02, 5.6052e-45, 3.2189e-02, 3.5166e-02,\n",
      "        2.2508e-02, 3.5773e-02, 3.0832e-02, 3.2409e-02, 2.5869e-02, 3.3648e-02,\n",
      "        3.7061e-02, 3.1230e-02, 3.0633e-02, 2.9066e-02, 5.6052e-45, 3.2296e-02,\n",
      "        3.2041e-02, 3.0007e-02, 3.1367e-02, 2.8426e-02, 3.0111e-02, 3.0841e-02,\n",
      "        3.4280e-02, 2.5589e-02])), ('encoder.convolutions.1.1.num_batches_tracked', tensor(18012)), ('encoder.convolutions.2.0.conv.weight', tensor([[[-1.9917e-02, -2.8457e-02, -2.8301e-02, -1.8627e-02, -2.9953e-02],\n",
      "         [ 1.3634e-02,  1.2243e-02,  6.6724e-03, -7.2807e-04,  1.5299e-03],\n",
      "         [ 1.1018e-04, -2.8003e-02, -2.2529e-02, -3.4588e-03, -2.1252e-02],\n",
      "         ...,\n",
      "         [-2.0689e-02, -2.6034e-02,  3.1366e-03, -1.6032e-02, -7.3228e-03],\n",
      "         [ 7.4458e-03,  7.5741e-03,  2.9390e-02, -1.8489e-02,  2.0385e-03],\n",
      "         [-1.7387e-02, -1.1675e-02,  3.4044e-03, -1.3927e-02, -3.4550e-03]],\n",
      "\n",
      "        [[-7.0071e-03,  6.4785e-03, -1.8307e-02, -3.7339e-02, -3.4175e-02],\n",
      "         [ 6.4531e-03,  3.3081e-02,  1.4568e-02,  1.7405e-02,  8.7037e-03],\n",
      "         [-1.3274e-02, -3.9932e-02, -4.3926e-02, -1.5482e-02, -1.8834e-02],\n",
      "         ...,\n",
      "         [-2.2339e-02, -8.4511e-03, -1.6550e-03, -5.6671e-03, -9.8541e-03],\n",
      "         [ 1.9136e-02,  7.0354e-04,  6.1520e-05, -2.4349e-02,  5.3407e-03],\n",
      "         [ 1.1016e-02,  8.8768e-03,  1.5401e-04, -1.1214e-02,  7.3351e-03]],\n",
      "\n",
      "        [[-8.9489e-03, -2.8473e-02,  1.3630e-02,  1.6164e-02, -2.8171e-02],\n",
      "         [ 6.1701e-03, -1.9658e-02, -8.0460e-02, -7.7644e-02, -2.7368e-02],\n",
      "         [ 3.1185e-03,  2.1786e-02,  1.1998e-02,  1.4016e-02,  1.8999e-02],\n",
      "         ...,\n",
      "         [-7.2841e-03, -4.8434e-03, -1.5191e-02, -4.7031e-02, -2.5130e-02],\n",
      "         [-9.1567e-03, -9.7754e-03,  1.2361e-02,  2.2407e-02,  1.0282e-02],\n",
      "         [ 8.6905e-03, -1.3456e-02, -5.7194e-02, -9.3076e-03, -8.6327e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.2971e-03, -3.2556e-03, -3.9411e-02, -3.0853e-02, -5.6780e-03],\n",
      "         [ 3.4189e-03,  2.9727e-03, -2.8588e-02, -2.8830e-02, -1.3598e-02],\n",
      "         [-4.7884e-03,  7.3290e-03, -2.5921e-02, -3.3219e-02, -3.8435e-02],\n",
      "         ...,\n",
      "         [-1.6416e-03, -7.9399e-03,  8.2004e-03, -5.6766e-02, -4.5262e-02],\n",
      "         [ 6.9381e-03, -8.6656e-03,  9.3938e-03,  8.3310e-03, -1.5935e-02],\n",
      "         [ 4.7789e-03,  8.8057e-03, -8.0090e-03,  1.2978e-02,  2.6522e-03]],\n",
      "\n",
      "        [[-2.2822e-04,  8.9434e-03, -1.7328e-02, -2.9170e-02,  3.6109e-03],\n",
      "         [-6.6044e-03,  8.5892e-03,  2.8420e-03, -3.8689e-03, -1.2836e-02],\n",
      "         [-3.0075e-03, -6.3219e-03, -2.6132e-02, -1.0395e-02,  2.2557e-03],\n",
      "         ...,\n",
      "         [-3.2387e-03,  2.0996e-03,  1.1575e-02, -7.9686e-03,  3.9149e-03],\n",
      "         [ 4.4098e-03,  8.2615e-03,  4.4156e-03,  1.4935e-02,  2.5179e-03],\n",
      "         [-1.8534e-02, -4.4581e-03, -7.8761e-03, -2.5765e-03, -2.7770e-03]],\n",
      "\n",
      "        [[ 8.8637e-03,  5.6745e-03,  2.4646e-02,  1.9370e-02, -4.2455e-03],\n",
      "         [ 3.3085e-03,  4.7667e-04,  1.3077e-02, -9.4747e-03, -3.1968e-02],\n",
      "         [ 1.7766e-02, -5.7931e-03, -4.0979e-03, -4.6497e-02, -4.8848e-02],\n",
      "         ...,\n",
      "         [-1.5364e-02,  2.8245e-03, -7.2353e-03, -1.4105e-02, -1.4017e-02],\n",
      "         [-1.1109e-02, -3.9164e-02, -7.9856e-02, -5.4165e-02, -3.7786e-03],\n",
      "         [-2.3211e-03, -9.7232e-03, -2.3854e-02, -4.3393e-02, -3.4062e-03]]])), ('encoder.convolutions.2.0.conv.bias', tensor([-5.5913e-05,  4.2432e-04, -1.8794e-04, -5.9000e-05, -1.9578e-04,\n",
      "        -7.0077e-05, -3.5957e-05, -2.5776e-05, -2.1025e-04, -6.9202e-05,\n",
      "         6.2051e-05,  2.4095e-04,  2.6867e-04, -3.8458e-04,  3.0436e-04,\n",
      "         1.4949e-05,  9.3063e-06, -1.8790e-04, -3.2543e-04, -2.3290e-04,\n",
      "         1.4729e-04,  2.0044e-04,  4.4603e-05,  9.8390e-05,  4.1234e-05,\n",
      "         2.3137e-04,  2.9234e-04, -3.3360e-04,  1.4420e-04, -2.9423e-05,\n",
      "        -1.4945e-04,  3.9225e-05, -5.3032e-06,  1.6999e-04, -1.3349e-04,\n",
      "         4.3577e-04,  4.5604e-04, -3.3182e-04,  1.1331e-04, -1.9598e-06,\n",
      "        -1.7537e-04,  3.5382e-04,  1.5710e-04, -1.7000e-04,  9.6595e-05,\n",
      "         8.8895e-05,  3.5368e-04, -2.1741e-04, -5.5172e-04,  3.3284e-05,\n",
      "        -1.3976e-04, -2.0652e-04,  5.6919e-05,  1.0381e-04, -6.2738e-05,\n",
      "        -2.4123e-04,  6.2387e-06,  6.4759e-05, -2.9386e-05,  5.0101e-04,\n",
      "        -2.1042e-04,  5.4442e-04,  5.0380e-05,  8.9056e-07,  2.7591e-04,\n",
      "         1.8258e-04, -3.4620e-04,  6.4566e-05, -3.4759e-05,  1.1336e-05,\n",
      "         2.0041e-04, -4.5328e-05, -7.3331e-05,  4.6809e-04, -2.5629e-05,\n",
      "         2.3104e-04, -1.3380e-04,  1.5417e-04, -1.5600e-04,  4.0577e-04,\n",
      "        -2.9467e-04,  1.2668e-04,  8.2339e-05,  2.7277e-04, -5.1330e-05,\n",
      "         4.2083e-04, -2.3896e-04, -5.7272e-05,  4.3763e-04, -1.4515e-04,\n",
      "        -3.8048e-04,  3.4018e-04,  9.7203e-05,  1.1473e-04,  2.2225e-05,\n",
      "        -3.6190e-06,  9.6638e-05, -1.3624e-04,  2.9472e-04, -1.2391e-04,\n",
      "         2.4999e-04, -1.5916e-04,  1.2027e-05,  5.9714e-05, -3.6722e-06,\n",
      "         2.4842e-04,  3.1356e-04, -3.7125e-04,  6.5131e-05, -3.1401e-04,\n",
      "         1.0004e-04, -1.3957e-04, -4.9444e-05, -1.2635e-04,  1.3659e-04,\n",
      "        -3.7418e-04,  2.6695e-04,  9.2901e-05, -4.4446e-05, -9.3227e-06,\n",
      "        -1.2133e-04,  1.5192e-04,  3.0147e-06,  1.3889e-04, -2.7420e-04,\n",
      "         2.4181e-04, -9.7757e-05,  3.5689e-04,  5.6803e-05,  1.6025e-04,\n",
      "         2.7896e-04,  2.2199e-05, -2.8590e-05,  2.2485e-04,  7.0760e-05,\n",
      "        -1.1197e-04,  1.0495e-04,  1.0985e-04,  2.4150e-04, -1.0702e-04,\n",
      "        -3.6519e-04,  1.3325e-04, -4.9676e-04,  2.5751e-05,  1.3322e-04,\n",
      "        -1.2640e-04,  1.9998e-05,  3.5480e-04, -1.4712e-04,  4.0899e-04,\n",
      "        -6.9590e-04, -8.7534e-05, -6.0277e-05,  2.3717e-04, -1.3661e-04,\n",
      "        -1.1446e-05, -2.4362e-04,  1.1719e-04, -1.1105e-04, -3.1692e-04,\n",
      "         2.4594e-04, -2.2660e-05, -1.3879e-04,  2.2579e-05,  3.2451e-04,\n",
      "         3.7562e-05,  2.7987e-04,  1.8558e-04, -4.9208e-04,  1.6908e-04,\n",
      "         1.4553e-04, -6.0088e-04, -2.2664e-04, -5.0510e-05,  1.6227e-04,\n",
      "        -1.8420e-04,  9.2066e-05,  1.1569e-05,  3.3234e-04, -8.1813e-05,\n",
      "         2.5356e-04, -7.4164e-05, -9.8191e-05,  1.8266e-04,  1.9595e-04,\n",
      "        -1.8240e-04,  6.1014e-06,  1.8361e-04, -7.3634e-05,  2.5494e-04,\n",
      "        -3.8493e-05, -2.1237e-04,  6.7055e-05, -3.6989e-04, -2.4152e-04,\n",
      "         3.3568e-04,  2.7000e-04,  4.1650e-04, -4.8511e-05,  2.1928e-04,\n",
      "        -9.3994e-05,  4.0695e-05, -2.8266e-04, -3.2149e-04, -2.5203e-04,\n",
      "        -7.5857e-05,  3.4511e-05, -1.4604e-05, -1.5721e-05, -1.5247e-04,\n",
      "         5.7773e-05, -3.1833e-05,  6.5488e-05,  3.8697e-04, -1.3178e-04,\n",
      "        -2.7700e-04, -1.9499e-04,  3.8077e-05, -4.2866e-04,  5.4851e-05,\n",
      "        -4.2974e-04,  1.2430e-05, -1.7480e-04,  5.7415e-05, -5.6226e-05,\n",
      "         1.5436e-04,  6.8179e-05,  5.1311e-05,  1.3904e-06, -3.3571e-04,\n",
      "         7.1505e-05,  3.0779e-04,  5.2263e-05, -2.7831e-05, -1.0331e-04,\n",
      "         1.6502e-04,  3.2864e-04, -1.6504e-04, -3.2786e-05,  2.9885e-04,\n",
      "        -8.4522e-05,  2.3036e-04,  1.9828e-04, -1.9269e-04, -2.5393e-04,\n",
      "         1.6493e-04, -2.4112e-04, -2.1024e-05,  8.6610e-06, -7.1295e-05,\n",
      "         1.9756e-04,  3.0551e-04,  6.5346e-05, -1.6765e-04, -2.7869e-04,\n",
      "         1.5046e-04, -5.0498e-04,  2.0723e-04, -3.5927e-04,  1.4284e-04,\n",
      "         2.2870e-04, -2.8791e-04,  2.7909e-04,  3.5666e-05, -1.8789e-04,\n",
      "         2.0487e-04, -3.4643e-04,  1.9172e-04,  1.2190e-04,  1.7823e-04,\n",
      "        -1.5308e-04, -3.7446e-04, -1.3523e-04,  2.1248e-04, -1.6646e-04,\n",
      "        -5.4212e-04,  1.0444e-04,  1.4977e-04,  4.6516e-05,  1.0401e-05,\n",
      "        -2.9935e-04, -3.2616e-04, -1.8130e-04,  3.2921e-04, -1.0200e-04,\n",
      "         1.4259e-04,  4.2191e-04, -6.0243e-04, -1.3939e-04,  2.8692e-04,\n",
      "         1.0296e-04,  2.4567e-04, -6.3658e-04,  5.1800e-05, -2.2921e-04,\n",
      "        -4.6054e-04, -3.5140e-04,  4.2872e-04, -1.3751e-05, -1.0132e-04,\n",
      "        -1.9637e-04,  1.5901e-04, -1.6287e-04,  2.5257e-04, -8.7749e-05,\n",
      "         3.9419e-04,  2.0350e-04,  2.9880e-04,  1.1063e-04,  3.9839e-04,\n",
      "         3.4174e-05,  3.4246e-04,  3.5895e-04,  2.6966e-04, -6.7654e-05,\n",
      "         3.7101e-04,  2.7099e-04, -2.0898e-06, -1.7294e-04,  2.6303e-04,\n",
      "        -1.3079e-04,  2.1866e-04,  1.7344e-04,  2.0463e-04,  1.8247e-04,\n",
      "        -2.1136e-05, -4.7949e-05, -5.0660e-06, -1.2640e-04, -3.1593e-04,\n",
      "         5.9666e-05,  4.7832e-04,  1.9964e-04,  9.8751e-05,  5.0674e-04,\n",
      "         1.1555e-04,  4.7912e-05,  4.4925e-05,  3.4170e-04, -1.6167e-04,\n",
      "        -5.1839e-05, -1.7447e-04,  9.8834e-05,  2.1233e-04,  2.9848e-04,\n",
      "         1.2814e-04,  1.1185e-04, -4.2158e-05,  3.6797e-04, -1.3250e-04,\n",
      "         2.8478e-04,  1.1840e-05,  7.9311e-05,  3.0985e-04,  1.7891e-04,\n",
      "         2.1981e-04,  1.7651e-04, -4.7875e-05,  5.7113e-04, -3.0446e-04,\n",
      "        -1.6744e-04,  4.3870e-04, -6.2060e-04, -8.9550e-05, -1.4812e-04,\n",
      "         2.0883e-04,  6.6860e-04,  1.2075e-04, -3.0252e-04,  2.5387e-04,\n",
      "         1.0859e-04, -4.4119e-04,  1.4314e-04,  1.5427e-04,  1.4538e-04,\n",
      "        -7.2963e-05,  3.5669e-04,  1.8712e-04,  1.9990e-04, -1.5635e-04,\n",
      "        -1.2520e-04,  2.1266e-05, -1.6327e-04, -3.4033e-05, -2.5607e-04,\n",
      "        -3.6628e-05, -8.0297e-05,  5.3944e-04, -2.7626e-04,  1.1048e-04,\n",
      "        -2.4873e-04,  2.1024e-39,  3.6970e-04,  1.3142e-04,  2.3194e-04,\n",
      "         1.3208e-04,  2.4016e-04,  4.8648e-04, -3.5027e-05,  9.6012e-06,\n",
      "         2.8552e-04, -2.9065e-04,  4.5007e-05, -1.9176e-04,  1.7275e-04,\n",
      "        -9.4925e-05, -2.4367e-04,  1.9824e-04, -9.5932e-05,  3.2698e-04,\n",
      "         1.0123e-04,  4.1740e-05,  1.6648e-06, -1.3082e-04, -9.3807e-04,\n",
      "         2.0851e-04, -2.3672e-04,  9.5998e-06, -3.0563e-05,  1.5544e-04,\n",
      "         5.6439e-05,  3.1368e-04,  2.5219e-04,  5.4814e-04, -3.0798e-04,\n",
      "         6.5608e-05, -2.7152e-04,  3.0711e-04,  3.6083e-04,  3.9973e-05,\n",
      "        -4.8157e-05,  5.3508e-05,  6.0943e-06, -1.2479e-04, -3.7035e-04,\n",
      "        -3.3241e-04,  1.8595e-04, -8.0202e-05, -2.1257e-04,  5.5434e-05,\n",
      "        -2.6234e-04,  6.4376e-05, -4.1804e-05, -8.6530e-06, -4.1669e-04,\n",
      "        -2.6665e-04,  3.1438e-04,  4.8893e-04,  4.2028e-05,  1.2058e-04,\n",
      "        -6.4580e-05, -4.6417e-04,  3.6387e-04,  6.6681e-04,  2.0475e-05,\n",
      "         3.3669e-04, -2.3426e-05,  8.2196e-05,  5.2847e-04, -6.8478e-04,\n",
      "        -1.7941e-05,  1.7494e-05,  2.1061e-04,  7.6554e-05, -3.8671e-04,\n",
      "         3.3927e-04, -4.1631e-04, -2.8078e-04,  2.5414e-04, -1.7469e-04,\n",
      "        -6.6533e-05,  7.4148e-05, -1.4261e-04, -5.9997e-04,  8.5982e-06,\n",
      "         4.5425e-04,  4.0608e-05, -1.4035e-04, -5.0757e-09, -2.3643e-04,\n",
      "         6.1530e-05,  2.6223e-04,  1.2981e-04,  2.9325e-04, -2.0363e-04,\n",
      "         3.0151e-04, -2.0121e-04, -3.1313e-04, -3.4645e-04, -1.3418e-04,\n",
      "        -8.3228e-05, -3.8088e-04, -1.0753e-04, -1.8051e-04, -2.8332e-05,\n",
      "         1.5251e-04, -6.3241e-04, -3.6570e-05, -1.3530e-05, -2.1606e-04,\n",
      "        -4.1564e-06,  2.3378e-05,  1.6928e-04, -1.5993e-04,  2.3117e-05,\n",
      "        -2.6416e-39,  8.7091e-05,  1.0745e-04, -9.9156e-05,  2.9623e-04,\n",
      "         1.7568e-04,  1.7482e-04])), ('encoder.convolutions.2.1.weight', tensor([8.8449e-01, 7.7729e-01, 4.7780e-01, 6.5734e-01, 7.9842e-01, 4.7671e-01,\n",
      "        8.9379e-01, 7.8686e-01, 5.5080e-01, 8.6408e-01, 6.9328e-01, 5.5348e-01,\n",
      "        6.2247e-01, 6.0184e-01, 5.8788e-01, 5.9689e-01, 3.4491e-01, 8.3304e-01,\n",
      "        8.2454e-01, 5.7903e-01, 4.6708e-01, 8.3878e-01, 7.5462e-01, 8.0160e-01,\n",
      "        4.2069e-01, 7.1525e-01, 6.1045e-01, 4.3710e-01, 5.3334e-01, 8.3917e-01,\n",
      "        5.5996e-01, 8.4017e-01, 6.8926e-01, 6.4273e-01, 7.5001e-01, 6.8445e-01,\n",
      "        8.5593e-01, 8.5186e-01, 7.7350e-01, 3.4642e-01, 8.9734e-01, 6.6471e-01,\n",
      "        7.3163e-01, 1.0629e+00, 6.4965e-01, 7.3325e-01, 7.7650e-01, 7.1843e-01,\n",
      "        4.3738e-01, 7.1827e-01, 8.7572e-01, 8.7836e-01, 1.0865e+00, 4.9213e-01,\n",
      "        5.0712e-01, 8.2743e-01, 6.8414e-01, 7.2244e-01, 4.7309e-01, 7.7012e-01,\n",
      "        6.2607e-01, 6.3074e-01, 4.8168e-01, 4.4426e-01, 5.8130e-01, 7.0964e-01,\n",
      "        4.1709e-01, 7.9448e-01, 8.6550e-01, 8.3173e-01, 7.5727e-01, 9.6042e-01,\n",
      "        8.0643e-01, 4.2942e-01, 5.9271e-01, 3.2264e-01, 7.5420e-01, 4.3920e-01,\n",
      "        5.7516e-01, 9.2280e-01, 9.2004e-01, 5.8639e-01, 6.5868e-01, 5.2665e-01,\n",
      "        6.1878e-01, 8.3675e-01, 5.4175e-01, 4.1207e-01, 6.8222e-01, 5.1494e-01,\n",
      "        6.9807e-01, 4.6444e-01, 6.3252e-01, 9.0529e-01, 8.7851e-01, 4.6113e-01,\n",
      "        5.0997e-01, 6.7382e-01, 4.5790e-01, 6.2193e-01, 7.8442e-01, 9.1006e-01,\n",
      "        5.8525e-01, 5.1206e-01, 7.2356e-01, 8.2429e-01, 8.2699e-01, 3.9822e-01,\n",
      "        7.3187e-01, 5.3123e-01, 9.1290e-01, 5.7746e-01, 5.0827e-01, 7.4445e-01,\n",
      "        4.3126e-01, 7.3664e-01, 7.7183e-01, 9.5489e-01, 6.5196e-01, 7.6136e-01,\n",
      "        6.6633e-01, 9.2058e-01, 5.7326e-01, 6.6650e-01, 5.3209e-01, 8.7042e-01,\n",
      "        5.4455e-01, 4.6042e-01, 6.5098e-01, 8.6551e-01, 4.4483e-01, 4.0323e-01,\n",
      "        3.5837e-01, 6.1561e-01, 2.8369e-01, 6.2299e-01, 3.8443e-01, 4.1205e-01,\n",
      "        4.4549e-01, 4.4777e-01, 7.0880e-01, 7.3535e-01, 7.0207e-01, 5.8527e-01,\n",
      "        4.7359e-01, 4.6142e-01, 7.4999e-01, 5.9781e-01, 1.0790e+00, 2.5435e-01,\n",
      "        3.6688e-01, 6.1918e-01, 4.4207e-01, 6.3115e-01, 5.3154e-01, 5.6827e-01,\n",
      "        9.5489e-01, 5.0894e-01, 5.7335e-01, 6.1528e-01, 3.6736e-01, 3.9421e-01,\n",
      "        3.5682e-01, 8.5619e-01, 7.7990e-01, 9.1637e-01, 8.0625e-01, 1.0403e+00,\n",
      "        7.3527e-01, 5.6587e-01, 8.0377e-01, 6.5179e-01, 7.7758e-01, 9.6055e-01,\n",
      "        5.2415e-01, 4.3735e-01, 4.2756e-01, 5.6579e-01, 5.3107e-01, 6.0979e-01,\n",
      "        5.3833e-01, 6.3444e-01, 5.7935e-01, 4.1679e-01, 8.6476e-01, 7.6908e-01,\n",
      "        9.7704e-01, 6.7872e-01, 4.4345e-01, 5.4298e-01, 7.5591e-01, 7.4755e-01,\n",
      "        8.0127e-01, 6.7042e-01, 1.1039e+00, 4.2990e-01, 7.8724e-01, 5.9958e-01,\n",
      "        8.3720e-01, 5.0219e-01, 7.7089e-01, 5.4152e-01, 5.6809e-01, 3.9569e-01,\n",
      "        6.5351e-01, 5.4508e-01, 4.4160e-01, 8.8692e-01, 9.9624e-01, 8.3552e-01,\n",
      "        8.7664e-01, 4.4746e-01, 3.7632e-01, 4.6230e-01, 8.6635e-01, 7.1005e-01,\n",
      "        1.0922e+00, 9.2728e-01, 7.2093e-01, 5.9386e-01, 6.0896e-01, 5.5683e-01,\n",
      "        8.1520e-01, 7.0333e-01, 5.9284e-01, 4.8752e-01, 5.4280e-01, 7.1593e-01,\n",
      "        6.5123e-01, 8.4580e-01, 3.2729e-01, 7.6715e-01, 1.0101e+00, 4.6782e-01,\n",
      "        4.4409e-01, 7.8004e-01, 6.7693e-01, 3.7845e-01, 9.3329e-01, 8.5171e-01,\n",
      "        4.8747e-01, 5.5804e-01, 6.8486e-01, 8.7337e-01, 8.0894e-01, 6.0086e-01,\n",
      "        6.6704e-01, 5.5974e-01, 5.4485e-01, 6.4339e-01, 1.0023e+00, 7.1075e-01,\n",
      "        4.4283e-01, 5.5272e-01, 8.8225e-01, 5.9896e-01, 4.6245e-01, 4.9823e-01,\n",
      "        4.4690e-01, 7.6238e-01, 5.1855e-01, 8.7780e-01, 6.5516e-01, 7.7143e-01,\n",
      "        5.3267e-01, 9.0258e-01, 8.7716e-01, 4.6972e-01, 6.5447e-01, 6.5327e-01,\n",
      "        7.4618e-01, 6.8662e-01, 7.3787e-01, 4.9596e-01, 8.2791e-01, 4.5707e-01,\n",
      "        4.9020e-01, 6.7546e-01, 4.8127e-01, 5.6778e-01, 6.0340e-01, 7.6612e-01,\n",
      "        6.4606e-01, 5.0043e-01, 5.2309e-01, 5.6519e-01, 4.1801e-01, 8.2703e-01,\n",
      "        5.6778e-01, 6.6460e-01, 4.4959e-01, 5.6433e-01, 9.1712e-01, 5.8891e-01,\n",
      "        5.5670e-01, 5.2578e-01, 5.9959e-01, 8.5398e-01, 2.8782e-01, 4.7278e-01,\n",
      "        8.6964e-01, 1.0232e+00, 6.1532e-01, 4.9196e-01, 4.4734e-01, 3.7079e-01,\n",
      "        4.3979e-01, 8.4282e-01, 8.5944e-01, 5.9566e-01, 7.3886e-01, 6.9772e-01,\n",
      "        8.4903e-01, 1.0130e+00, 7.5071e-01, 4.9327e-01, 6.9155e-01, 5.1983e-01,\n",
      "        8.5048e-01, 7.2452e-01, 9.2243e-01, 8.2708e-01, 8.6874e-01, 6.5019e-01,\n",
      "        9.6708e-01, 5.4632e-01, 9.1967e-01, 5.8719e-01, 9.1286e-01, 7.0165e-01,\n",
      "        9.7103e-01, 4.7822e-01, 1.0058e+00, 3.7317e-01, 9.1380e-01, 3.5366e-01,\n",
      "        9.1248e-01, 7.9067e-01, 5.6150e-01, 7.8094e-01, 5.0995e-01, 4.7113e-01,\n",
      "        9.0264e-01, 6.5406e-01, 6.7429e-01, 4.3882e-01, 8.6351e-01, 7.6078e-01,\n",
      "        9.3863e-01, 1.0214e+00, 4.1182e-01, 4.5820e-01, 7.0943e-01, 7.6217e-01,\n",
      "        3.9186e-01, 4.6083e-01, 6.4254e-01, 8.3236e-01, 3.9865e-01, 5.9231e-01,\n",
      "        7.7555e-01, 6.9451e-01, 4.9716e-01, 8.3054e-01, 4.7146e-01, 9.5164e-01,\n",
      "        9.1958e-01, 7.4189e-01, 8.5380e-01, 5.5269e-01, 7.4060e-01, 5.7317e-01,\n",
      "        7.5905e-01, 6.2933e-01, 8.1031e-01, 4.5138e-01, 3.9893e-01, 4.6014e-01,\n",
      "        5.3363e-01, 8.4433e-01, 6.5152e-01, 3.6091e-01, 4.3887e-01, 6.2248e-01,\n",
      "        7.3892e-01, 4.7914e-01, 7.9235e-01, 9.0769e-01, 6.9166e-01, 7.1222e-01,\n",
      "        6.1826e-01, 1.4601e-10, 3.8704e-01, 8.8630e-01, 6.5483e-01, 6.2110e-01,\n",
      "        6.4138e-01, 7.3716e-01, 6.4674e-01, 4.0590e-01, 8.9256e-01, 4.8886e-01,\n",
      "        5.6832e-01, 7.0054e-01, 6.1156e-01, 9.7663e-01, 4.0425e-01, 4.0171e-01,\n",
      "        5.3827e-01, 8.5122e-01, 4.9697e-01, 3.7257e-01, 4.1996e-01, 7.1309e-01,\n",
      "        7.0775e-01, 7.6619e-01, 6.5529e-01, 5.6202e-01, 1.0023e+00, 7.1438e-01,\n",
      "        9.1693e-01, 8.4866e-01, 8.8437e-01, 7.4169e-01, 4.7809e-01, 5.2931e-01,\n",
      "        5.2460e-01, 5.0183e-01, 8.4282e-01, 5.6937e-01, 5.2287e-01, 3.2022e-01,\n",
      "        9.5757e-01, 6.7168e-01, 8.5646e-01, 7.9202e-01, 5.6779e-01, 3.5745e-01,\n",
      "        8.3589e-01, 7.3340e-01, 5.3296e-01, 6.5860e-01, 3.6429e-01, 7.5278e-01,\n",
      "        4.5547e-01, 3.9134e-01, 8.8182e-01, 8.1042e-01, 5.6178e-01, 5.5586e-01,\n",
      "        9.7622e-01, 5.7126e-01, 9.0031e-01, 7.2701e-01, 4.4972e-01, 6.9524e-01,\n",
      "        4.7584e-01, 9.1047e-01, 7.4708e-01, 7.5853e-01, 6.1086e-01, 4.3494e-01,\n",
      "        1.0661e+00, 4.1754e-01, 4.9803e-01, 2.3994e-01, 6.9509e-01, 4.6801e-01,\n",
      "        8.7645e-01, 8.0585e-01, 9.3678e-01, 6.8978e-01, 5.7411e-01, 6.4267e-01,\n",
      "        1.0154e+00, 5.6267e-01, 5.5049e-01, 5.0500e-01, 6.3855e-01, 8.5417e-01,\n",
      "        4.8882e-01, 8.1935e-01, 7.7430e-01, 8.7841e-01, 8.8261e-01, 4.6142e-01,\n",
      "        9.2544e-01, 5.2659e-01, 3.0656e-01, 5.7765e-01, 6.4451e-01, 5.8837e-01,\n",
      "        6.5252e-01, 5.3787e-01, 6.0240e-01, 5.6367e-01, 6.9185e-01, 9.9717e-01,\n",
      "        4.0114e-01, 5.6426e-01, 5.0284e-01, 8.2094e-01, 9.7870e-01, 4.6515e-01,\n",
      "        3.9340e-01, 2.6862e-11, 5.7062e-01, 8.7151e-01, 4.9084e-01, 5.7393e-01,\n",
      "        5.6089e-01, 8.2282e-01])), ('encoder.convolutions.2.1.bias', tensor([-1.6244e-01, -8.9071e-02, -1.4660e-01, -4.3328e-02, -1.4765e-01,\n",
      "        -1.7569e-01, -7.2301e-02, -9.9336e-02, -1.1328e-01, -1.4252e-01,\n",
      "        -1.9036e-01, -1.0536e-01, -1.4221e-01, -1.0403e-01, -1.6957e-01,\n",
      "        -1.9481e-01, -9.9148e-02, -6.5519e-02, -1.4529e-01, -8.0693e-02,\n",
      "        -8.9284e-02, -1.3735e-01, -2.2863e-01, -1.3539e-01, -9.2730e-02,\n",
      "        -2.1876e-01, -2.1896e-01, -1.6208e-01, -1.1817e-01, -1.1597e-01,\n",
      "        -1.2780e-01, -9.9480e-02, -2.1594e-01, -1.0532e-01, -1.6252e-01,\n",
      "        -1.1138e-01, -1.5435e-01, -9.9796e-02, -1.6846e-01, -1.0737e-01,\n",
      "        -2.3608e-01, -2.3858e-01, -3.9430e-01, -1.4920e-01, -1.6059e-01,\n",
      "        -1.1710e-01, -1.0628e-01, -1.1205e-01, -1.8617e-01, -7.7049e-02,\n",
      "        -8.6417e-02, -2.5339e-01, -1.3533e-01, -1.1420e-01, -1.5137e-01,\n",
      "        -9.1451e-02, -1.2418e-01, -1.8423e-01, -1.9437e-01, -1.3649e-01,\n",
      "        -1.0641e-01, -1.6512e-01, -1.0379e-01, -1.0098e-01, -1.3855e-01,\n",
      "        -1.4418e-01, -1.5000e-01, -1.0535e-01, -2.8538e-01, -9.5263e-02,\n",
      "        -1.9271e-01, -1.7468e-01, -1.4133e-01, -1.0540e-01, -1.4808e-01,\n",
      "        -6.1765e-02, -1.6275e-01, -9.7496e-02, -1.7825e-01, -9.2607e-02,\n",
      "        -1.5463e-01, -1.2185e-01, -1.2688e-01, -2.0686e-01, -9.7451e-02,\n",
      "        -1.6661e-01, -1.0462e-01, -1.3378e-01, -1.5621e-01, -8.8856e-02,\n",
      "        -2.0243e-01, -1.5185e-01, -1.4862e-01, -2.1458e-01, -9.4204e-02,\n",
      "        -9.7890e-02, -1.1140e-01, -1.1067e-01, -1.0988e-01, -5.8905e-02,\n",
      "        -1.2833e-01, -1.0001e-01, -1.2622e-01, -1.5893e-01, -1.1850e-01,\n",
      "        -9.9740e-02, -8.7587e-02, -4.1611e-02, -1.0239e-01, -7.9523e-02,\n",
      "        -9.1064e-02, -1.4293e-01, -1.5437e-01, -1.3369e-01, -9.9863e-02,\n",
      "        -1.4788e-01, -1.5703e-01, -1.3171e-01, -1.1287e-01, -1.3351e-01,\n",
      "        -1.6200e-01, -1.1887e-01, -7.0052e-02, -1.9823e-01, -1.3948e-01,\n",
      "        -8.9014e-02, -1.3656e-01, -1.4207e-01, -7.5212e-02, -1.1085e-01,\n",
      "        -1.3182e-01, -8.0025e-02, -7.4001e-02, -1.6228e-01, -8.9670e-02,\n",
      "        -3.0607e-01, -1.0094e-01, -9.0294e-02, -1.1139e-01, -1.7667e-01,\n",
      "        -2.1026e-01, -1.6741e-01, -1.4209e-01, -7.7609e-02, -1.9664e-01,\n",
      "        -9.5443e-02, -2.5037e-01, -1.2897e-01, -2.6879e-01, -3.4129e-02,\n",
      "        -9.9706e-02, -1.3533e-01, -7.9868e-02, -1.0383e-01, -1.3273e-01,\n",
      "        -2.7525e-01, -1.5977e-01, -8.7307e-02, -9.3508e-02, -1.6115e-01,\n",
      "        -5.4115e-02, -1.2722e-01, -1.0798e-01, -1.1224e-01, -2.3175e-01,\n",
      "        -1.2914e-01, -1.0834e-01, -1.4275e-01, -8.3786e-02, -1.4839e-01,\n",
      "        -1.6968e-01, -1.3459e-01, -1.2473e-01, -1.0554e-01, -1.0824e-01,\n",
      "        -1.1845e-01, -1.1920e-01, -1.3914e-01, -1.7191e-01, -1.1148e-01,\n",
      "        -1.3606e-01, -8.8295e-02, -1.4081e-01, -8.6634e-02, -2.2247e-01,\n",
      "        -6.5859e-02, -1.5577e-01, -1.7238e-01, -1.7354e-01, -1.7383e-01,\n",
      "        -1.4447e-01, -1.3447e-01, -6.3107e-02, -1.1971e-01, -1.9490e-01,\n",
      "        -8.1712e-02, -1.4208e-01, -1.0029e-01, -9.3301e-02, -1.7362e-01,\n",
      "        -1.1662e-01, -1.5343e-01, -1.1172e-01, -1.3720e-01, -1.0451e-01,\n",
      "        -1.0532e-01, -1.2237e-01, -1.3243e-01, -1.4336e-01, -2.0801e-01,\n",
      "        -1.3488e-01, -8.4591e-02, -9.0161e-02, -1.0425e-01, -2.2391e-01,\n",
      "        -1.0561e-01, -2.1861e-01, -1.5093e-01, -3.0812e-01, -9.2415e-02,\n",
      "        -8.2979e-02, -1.9611e-01, -1.3162e-01, -8.2483e-02, -1.2418e-01,\n",
      "        -1.0106e-01, -1.1666e-01, -1.7084e-01, -1.7463e-01, -1.2868e-01,\n",
      "        -9.1479e-02, -2.6149e-01, -1.3678e-01, -2.3946e-01, -8.0272e-02,\n",
      "        -1.3645e-01, -7.4686e-02, -1.1651e-01, -1.4695e-01, -7.3403e-02,\n",
      "        -1.3637e-01, -1.0275e-01, -1.3836e-01, -1.1379e-01, -1.7146e-01,\n",
      "        -1.6480e-01, -1.6076e-01, -1.4638e-01, -1.8120e-01, -8.1346e-02,\n",
      "        -1.0781e-01, -1.0144e-01, -1.1047e-01, -1.1903e-01, -1.1938e-01,\n",
      "        -2.7968e-01, -1.3882e-01, -6.6110e-02, -1.1823e-01, -1.0351e-01,\n",
      "        -1.2010e-01, -9.0226e-02, -1.1448e-01, -1.2458e-01, -1.5525e-01,\n",
      "        -1.7551e-01, -9.7758e-02, -1.9662e-01, -3.4030e-01, -1.0772e-01,\n",
      "        -1.5019e-01, -1.0320e-01, -1.2440e-01, -1.2999e-01, -9.2927e-02,\n",
      "        -8.3516e-02, -3.1834e-01, -1.6144e-01, -2.0472e-01, -1.1110e-01,\n",
      "        -1.6950e-01, -2.2976e-01, -1.3472e-01, -9.7949e-02, -7.9604e-02,\n",
      "        -1.6909e-01, -2.0083e-01, -1.4658e-01, -2.6186e-01, -1.1479e-01,\n",
      "        -8.0198e-02, -9.6035e-02, -6.3646e-02, -1.3896e-01, -1.2097e-01,\n",
      "        -1.6202e-01, -1.3405e-01, -1.1852e-01, -6.9197e-02, -1.6146e-01,\n",
      "        -9.0086e-02, -1.3064e-01, -2.0997e-01, -1.1537e-01, -1.5277e-01,\n",
      "        -1.1633e-01, -2.0521e-01, -1.5536e-01, -1.6129e-01, -1.1992e-01,\n",
      "        -2.2991e-01, -1.2977e-01, -1.2498e-01, -1.4451e-01, -1.1325e-01,\n",
      "        -1.9988e-01, -1.3069e-01, -1.6950e-01, -1.1613e-01, -1.1402e-01,\n",
      "        -1.0598e-01, -1.3455e-01, -1.2859e-01, -9.5392e-02, -1.0175e-01,\n",
      "        -1.2007e-01, -1.8852e-01, -1.1379e-01, -2.0650e-01, -1.4015e-01,\n",
      "        -1.8584e-01, -2.1604e-01, -7.5108e-02, -8.9041e-02, -1.0372e-01,\n",
      "        -5.8826e-02, -1.4086e-01, -1.1007e-01, -1.2424e-01, -1.5215e-01,\n",
      "        -2.5366e-01, -1.5637e-01, -2.1883e-01, -1.2021e-01, -1.3853e-01,\n",
      "        -1.8555e-01, -1.1413e-01, -1.4875e-01, -8.9335e-02, -2.4175e-01,\n",
      "        -1.2959e-01, -1.2538e-01, -1.0854e-01, -1.2879e-01, -1.0902e-01,\n",
      "        -1.0070e-01, -1.2468e-01, -1.0396e-01, -1.3436e-01, -1.2531e-01,\n",
      "        -1.6981e-01, -9.4341e-02, -1.0421e-01, -1.0225e-01, -1.0775e-01,\n",
      "        -1.1092e-01, -1.2490e-01, -1.7962e-01, -6.5540e-02, -1.0618e-01,\n",
      "        -1.1701e-01, -9.6281e-02, -1.1544e-01, -1.4189e-01, -1.5019e-01,\n",
      "        -1.2187e-01, -6.7508e-02, -1.3226e-01, -1.3454e-01, -1.6675e-01,\n",
      "        -1.6013e-01, -1.3265e-01, -8.9383e-02, -1.0279e-01, -2.2611e-01,\n",
      "        -1.7554e-01, -2.4770e-01, -1.5982e-01, -7.3749e-02, -1.1779e-01,\n",
      "        -1.0546e-01, -2.2508e-09, -1.4957e-01, -1.7893e-01, -1.5955e-01,\n",
      "        -8.5240e-02, -1.1702e-01, -1.5976e-01, -1.5389e-01, -9.8648e-02,\n",
      "        -5.3153e-02, -1.2949e-01, -1.3157e-01, -2.0346e-01, -1.8986e-01,\n",
      "        -1.8103e-01, -1.5233e-01, -6.9192e-02, -1.4554e-01, -6.8914e-02,\n",
      "        -1.0375e-01, -1.3666e-01, -1.2775e-01, -9.8626e-02, -9.5208e-02,\n",
      "        -1.1805e-01, -1.8927e-01, -1.2893e-01, -2.1996e-01, -2.4527e-01,\n",
      "        -3.1170e-01, -1.5523e-01, -1.9340e-01, -1.5365e-01, -1.1875e-01,\n",
      "        -1.6384e-01, -1.5037e-01, -1.2173e-01, -1.4216e-01, -1.0334e-01,\n",
      "        -1.0670e-01, -5.2248e-02, -1.5711e-01, -8.9406e-02, -9.6597e-02,\n",
      "        -7.4623e-02, -1.3983e-01, -1.4474e-01, -1.9366e-01, -1.8215e-01,\n",
      "        -2.1842e-01, -1.7996e-01, -9.8666e-02, -1.7134e-01, -9.5054e-02,\n",
      "        -1.0627e-01, -3.3712e-01, -2.7799e-01, -1.6569e-01, -1.0166e-01,\n",
      "        -1.4764e-01, -1.1268e-01, -1.0044e-01, -1.4588e-01, -1.7092e-01,\n",
      "        -1.1919e-01, -1.7605e-01, -3.4242e-01, -2.0127e-01, -1.1823e-01,\n",
      "        -9.5473e-02, -2.2635e-01, -1.8985e-01, -1.8878e-01, -7.7442e-02,\n",
      "        -4.3328e-02, -1.2290e-01, -2.4118e-01, -1.2087e-01, -8.8767e-02,\n",
      "        -1.0883e-01, -1.1457e-01, -2.2431e-01, -2.2311e-01, -9.1357e-02,\n",
      "        -7.8867e-02, -1.2461e-01, -1.2415e-01, -1.4734e-01, -2.2637e-01,\n",
      "        -1.3566e-01, -1.2424e-01, -1.2452e-01, -1.0271e-01, -8.0078e-02,\n",
      "        -1.3246e-01, -1.5209e-01, -1.0010e-01, -8.4038e-02, -1.0051e-01,\n",
      "        -1.0136e-01, -1.4617e-01, -2.2105e-01, -1.4880e-01, -8.1957e-02,\n",
      "        -2.8781e-01, -2.4880e-01, -9.2806e-02, -8.2119e-02, -1.3565e-01,\n",
      "        -9.5429e-02, -1.3430e-01, -1.5487e-01, -1.2902e-01, -1.5259e-01,\n",
      "        -1.8191e-12, -1.5714e-01, -1.4572e-01, -1.5885e-01, -7.9955e-02,\n",
      "        -9.2464e-02, -1.2264e-01])), ('encoder.convolutions.2.1.running_mean', tensor([-2.4260e-01, -2.1875e-01, -2.5142e-01, -1.3944e-01, -2.2571e-01,\n",
      "        -1.3157e-01, -2.8147e-01, -2.9738e-01, -2.8858e-01, -2.3291e-01,\n",
      "        -2.4760e-01, -2.1757e-01, -2.5233e-01, -2.3206e-01, -2.8275e-01,\n",
      "        -3.5797e-01, -5.7875e-02, -2.1405e-01, -3.2407e-01, -1.6876e-01,\n",
      "        -2.1350e-01, -2.6885e-01, -2.2320e-01, -2.3113e-01, -1.7544e-01,\n",
      "        -2.9275e-01, -2.1214e-01, -2.0202e-01, -2.1462e-01, -2.3338e-01,\n",
      "        -2.5920e-01, -2.9215e-01, -2.8754e-01, -2.9999e-01, -3.1941e-01,\n",
      "        -3.2499e-01, -2.8148e-01, -1.9875e-01, -2.4883e-01, -1.6260e-01,\n",
      "        -4.6442e-02, -2.2239e-01, -3.1237e-01, -2.0084e-01, -3.0396e-01,\n",
      "        -1.8855e-01, -2.5058e-01, -2.2113e-01, -2.8050e-01, -3.2536e-01,\n",
      "        -3.2752e-01, -1.9913e-01, -1.8172e-01, -1.9833e-01, -1.9042e-01,\n",
      "        -3.3488e-01, -3.1497e-01, -2.2042e-01, -2.7087e-01, -3.3395e-01,\n",
      "        -4.0083e-01, -4.4479e-01, -1.8979e-01, -1.5410e-01, -2.3736e-01,\n",
      "        -2.7570e-01, -2.3170e-01, -2.2754e-01, -2.9461e-01, -3.8880e-01,\n",
      "        -3.1492e-01, -2.9149e-01, -3.0813e-01, -1.7972e-01, -2.8766e-01,\n",
      "        -1.1619e-01, -3.0335e-01, -2.9039e-01, -1.5554e-01, -2.2694e-01,\n",
      "        -3.0744e-01, -1.5254e-01, -3.1649e-01, -2.5508e-01, -2.0325e-01,\n",
      "        -1.9683e-01, -2.5270e-01, -1.9601e-01, -2.0474e-01, -2.5527e-01,\n",
      "        -2.2455e-01, -2.4850e-01, -1.5616e-01, -2.2822e-01, -2.8134e-01,\n",
      "        -1.2812e-01, -2.5017e-01, -2.1335e-01, -2.2066e-01, -1.6219e-01,\n",
      "        -2.9100e-01, -2.0101e-01, -1.4245e-01, -2.4932e-01, -3.0364e-01,\n",
      "        -2.8370e-01, -2.3642e-01, -1.6812e-01, -2.7151e-01, -2.0726e-01,\n",
      "        -2.4223e-01, -2.1795e-01, -1.9067e-01, -2.5124e-01, -2.3294e-01,\n",
      "        -2.8615e-01, -1.9575e-01, -3.7541e-01, -2.0048e-01, -2.8749e-01,\n",
      "        -2.1190e-01, -2.9932e-01, -2.7243e-01, -1.7214e-01, -2.6712e-01,\n",
      "        -2.6423e-01, -2.9807e-01, -1.8859e-01, -2.1696e-01, -2.5277e-01,\n",
      "        -3.0102e-01, -2.0695e-01, -8.9526e-02, -2.6782e-01, -1.2533e-01,\n",
      "        -2.7740e-01, -3.1113e-01, -1.3270e-01, -1.5610e-01, -1.8243e-01,\n",
      "        -1.9409e-01, -2.8522e-01, -1.4452e-01, -1.2229e-01, -2.1028e-01,\n",
      "        -2.6714e-01, -2.9028e-01, -2.8279e-01, -1.9517e-01, -1.3162e-01,\n",
      "        -1.7126e-01, -3.6718e-01, -1.8546e-01, -2.2830e-01, -2.2748e-01,\n",
      "        -2.4433e-01, -1.3772e-01, -1.0903e-01, -1.3101e-01, -1.8927e-01,\n",
      "        -5.8252e-02, -9.9533e-02, -2.3985e-01, -2.9670e-01, -1.6254e-01,\n",
      "        -2.5304e-01, -3.4249e-01, -2.3363e-01, -2.4498e-01, -1.0637e-01,\n",
      "        -2.9578e-01, -3.2733e-01, -2.6968e-01, -3.0817e-01, -2.0355e-01,\n",
      "        -9.0133e-02, -2.5248e-01, -2.0979e-01, -1.9194e-01, -3.1948e-01,\n",
      "        -2.1485e-01, -2.8671e-01, -1.9044e-01, -1.4122e-01, -2.7390e-01,\n",
      "        -2.1693e-01, -1.8026e-01, -2.3551e-01, -2.7451e-01, -1.1994e-01,\n",
      "        -3.1138e-01, -2.4353e-01, -9.1988e-02, -2.8629e-01, -2.1358e-01,\n",
      "        -1.8210e-01, -2.2493e-01, -2.6063e-01, -3.2167e-01, -1.8645e-01,\n",
      "        -2.5873e-01, -2.4759e-01, -3.2072e-01, -2.3983e-01, -1.7289e-01,\n",
      "        -9.3535e-02, -2.7239e-01, -2.6662e-01, -2.3036e-01, -2.8102e-01,\n",
      "        -2.4094e-01, -2.2871e-01, -1.9019e-01, -3.1073e-01, -2.6657e-01,\n",
      "        -2.4613e-01, -1.7234e-01, -3.3522e-01, -2.7437e-01, -1.9473e-01,\n",
      "        -2.4200e-01, -2.3155e-01, -3.5022e-01, -1.6882e-01, -1.9232e-01,\n",
      "        -2.0415e-01, -1.5956e-01, -2.9579e-01, -1.9380e-01, -3.7814e-01,\n",
      "        -1.0145e-01, -2.8367e-01, -2.1187e-01, -2.2627e-01, -1.9269e-01,\n",
      "        -3.2589e-01, -3.1902e-01, -2.2572e-01, -3.5015e-01, -2.3397e-01,\n",
      "        -1.5505e-01, -2.2161e-01, -2.4427e-01, -2.1056e-01, -2.8387e-01,\n",
      "        -1.9087e-01, -1.8706e-01, -2.7672e-01, -2.3063e-01, -2.1194e-01,\n",
      "        -2.1556e-01, -3.4047e-01, -1.8053e-01, -3.0958e-01, -1.8738e-01,\n",
      "        -1.9892e-01, -2.0826e-01, -1.2504e-01, -1.7540e-01, -2.9366e-01,\n",
      "        -2.8180e-01, -2.3139e-01, -2.2827e-01, -2.0527e-01, -2.3692e-01,\n",
      "        -2.2201e-01, -3.3273e-01, -2.9955e-01, -1.2182e-01, -3.2990e-01,\n",
      "        -2.1557e-01, -1.8979e-01, -2.4322e-01, -2.0556e-01, -2.4204e-01,\n",
      "        -1.6340e-01, -3.4967e-01, -3.0569e-01, -2.0474e-01, -1.7697e-01,\n",
      "        -1.7844e-01, -1.1348e-02, -2.6876e-01, -2.2071e-01, -2.3328e-01,\n",
      "        -2.3916e-01, -1.8383e-01, -2.8679e-01, -2.6067e-01, -2.4565e-01,\n",
      "        -1.5897e-01, -1.4992e-01, -3.8396e-01, -1.5810e-01, -2.4260e-01,\n",
      "        -2.0138e-01, -2.3530e-01, -2.8233e-01, -1.6807e-01, -3.3248e-01,\n",
      "        -2.7681e-01, -1.7978e-01, -2.6476e-01, -2.4387e-01, -2.2898e-01,\n",
      "        -1.3215e-01, -2.6363e-01, -2.3758e-01, -1.5882e-01, -1.6458e-01,\n",
      "        -2.4754e-01, -3.0424e-01, -3.2206e-01, -2.3657e-01, -2.4171e-01,\n",
      "        -1.6395e-01, -2.1321e-01, -1.4979e-01, -3.1901e-01, -1.5553e-01,\n",
      "        -2.4102e-01, -1.4906e-01, -2.9790e-01, -1.4108e-01, -2.7997e-01,\n",
      "        -1.8450e-01, -2.8743e-01, -2.4628e-01, -3.1747e-01, -2.5367e-01,\n",
      "        -2.7320e-01, -3.4863e-01, -1.9324e-01, -1.7981e-01, -2.1156e-01,\n",
      "        -3.9239e-02, -1.9292e-01, -1.7821e-01, -3.3008e-01, -2.2203e-01,\n",
      "        -1.6155e-01, -1.3006e-01, -2.2173e-01, -2.9786e-01, -3.6848e-01,\n",
      "        -7.5794e-02, -2.7275e-01, -2.4223e-01, -3.0333e-01, -2.1404e-01,\n",
      "        -1.5862e-01, -1.8081e-01, -3.6358e-01, -2.5834e-01, -2.5177e-01,\n",
      "        -2.5588e-01, -1.6409e-01, -1.8198e-01, -2.7779e-01, -2.8529e-01,\n",
      "        -2.6346e-01, -2.6639e-01, -2.5888e-01, -1.7500e-01, -2.9693e-01,\n",
      "        -2.2573e-01, -2.8158e-01, -1.6009e-01, -2.7139e-01, -2.7774e-01,\n",
      "        -2.5043e-01, -2.3310e-01, -2.3813e-01, -3.1931e-01, -3.3792e-01,\n",
      "        -2.8489e-01, -2.4422e-01, -2.6352e-01, -2.1668e-01, -3.2999e-01,\n",
      "        -1.8661e-01, -1.6416e-01, -1.8571e-01, -3.4639e-01, -1.8231e-01,\n",
      "        -2.0870e-01, -2.3808e-01, -2.1342e-01, -3.4452e-01, -2.1490e-01,\n",
      "        -2.8683e-01, -5.6052e-45, -2.1025e-01, -2.2803e-01, -2.1937e-01,\n",
      "        -1.9394e-01, -2.2484e-01, -2.1642e-01, -2.2092e-01, -2.0422e-01,\n",
      "        -2.4611e-01, -1.8301e-01, -3.3665e-01, -1.9573e-01, -3.5994e-01,\n",
      "        -3.6125e-01, -2.6929e-01, -2.1585e-01, -2.5815e-01, -2.2508e-01,\n",
      "        -2.7357e-01, -1.9712e-01, -1.9556e-01, -2.1455e-01, -3.1333e-01,\n",
      "        -1.8073e-01, -2.8314e-01, -2.6269e-01, -2.5191e-01, -2.4925e-01,\n",
      "        -3.3864e-01, -2.2843e-01, -1.7130e-01, -3.2968e-01, -2.3772e-01,\n",
      "        -2.9353e-01, -2.3700e-01, -1.9890e-01, -2.9442e-01, -2.7057e-01,\n",
      "        -2.3640e-01, -1.2693e-01, -3.9046e-01, -2.5841e-01, -2.9911e-01,\n",
      "        -2.6840e-01, -1.3621e-01, -2.9242e-01, -2.9895e-01, -2.6046e-01,\n",
      "        -2.5496e-01, -1.8498e-01, -1.2504e-01, -2.1619e-01, -1.2104e-01,\n",
      "        -1.5684e-01, -1.6222e-01, -2.8107e-01, -2.4833e-01, -2.0623e-01,\n",
      "        -1.6363e-01, -2.4174e-01, -3.3370e-01, -2.4452e-01, -2.5794e-01,\n",
      "        -2.8130e-01, -2.0617e-01, -1.7267e-01, -1.9638e-01, -2.7405e-01,\n",
      "        -1.3797e-01, -2.4198e-01, -1.8809e-01, -2.9032e-01, -1.9623e-01,\n",
      "        -8.7875e-02, -2.2827e-01, -2.0960e-01, -2.1374e-01, -2.2819e-01,\n",
      "        -2.7411e-01, -3.0378e-01, -1.7606e-01, -2.9026e-01, -2.2725e-01,\n",
      "        -2.5403e-01, -2.6370e-01, -2.1964e-01, -2.4614e-01, -2.4062e-01,\n",
      "        -3.5742e-01, -3.3770e-01, -2.6021e-01, -2.8946e-01, -2.6964e-01,\n",
      "        -2.1164e-01, -1.7142e-01, -2.7281e-01, -1.7286e-01, -1.9907e-01,\n",
      "        -2.5532e-01, -1.4864e-01, -1.5678e-01, -2.2025e-01, -2.3803e-01,\n",
      "        -1.5723e-01, -1.9144e-01, -2.0314e-01, -1.5786e-01, -3.6996e-01,\n",
      "        -1.4969e-01, -1.9972e-01, -3.2768e-01, -1.5564e-01, -2.2443e-01,\n",
      "        -5.6052e-45, -2.2209e-01, -2.8928e-01, -2.2661e-01, -2.5998e-01,\n",
      "        -3.0229e-01, -2.8325e-01])), ('encoder.convolutions.2.1.running_var', tensor([1.1167e-01, 1.1653e-01, 7.2890e-02, 1.4341e-01, 1.2946e-01, 7.8082e-02,\n",
      "        1.8409e-01, 1.1203e-01, 1.0529e-01, 1.1795e-01, 1.3227e-01, 7.6845e-02,\n",
      "        1.0360e-01, 1.0745e-01, 8.8903e-02, 8.7067e-02, 6.2424e-02, 1.8147e-01,\n",
      "        1.0160e-01, 1.0392e-01, 7.9236e-02, 1.1057e-01, 1.1558e-01, 1.1138e-01,\n",
      "        9.8360e-02, 8.9835e-02, 7.9418e-02, 8.1006e-02, 8.2471e-02, 1.3652e-01,\n",
      "        7.6083e-02, 1.3651e-01, 1.1402e-01, 9.9893e-02, 1.0867e-01, 1.1507e-01,\n",
      "        1.2018e-01, 1.8132e-01, 1.1696e-01, 5.9645e-02, 1.3866e-01, 9.8974e-02,\n",
      "        9.3080e-02, 1.7289e-01, 1.1005e-01, 9.7030e-02, 1.3720e-01, 1.3089e-01,\n",
      "        6.8699e-02, 1.2661e-01, 1.3856e-01, 1.3044e-01, 1.9473e-01, 9.2165e-02,\n",
      "        8.7659e-02, 1.1007e-01, 1.3485e-01, 1.0605e-01, 5.8486e-02, 1.0809e-01,\n",
      "        9.4332e-02, 7.9046e-02, 7.5410e-02, 9.9885e-02, 1.0645e-01, 9.9106e-02,\n",
      "        8.2999e-02, 1.3656e-01, 1.0596e-01, 1.1659e-01, 1.0114e-01, 1.0436e-01,\n",
      "        1.1752e-01, 8.2798e-02, 9.1535e-02, 6.0865e-02, 1.1335e-01, 7.5760e-02,\n",
      "        1.2513e-01, 1.3850e-01, 1.3283e-01, 1.3134e-01, 1.0368e-01, 9.2154e-02,\n",
      "        9.5937e-02, 1.2121e-01, 9.5137e-02, 7.2874e-02, 1.0156e-01, 7.8734e-02,\n",
      "        1.0846e-01, 6.0245e-02, 1.2135e-01, 9.9531e-02, 1.3004e-01, 9.2461e-02,\n",
      "        8.1861e-02, 9.5098e-02, 7.1235e-02, 1.0989e-01, 1.0386e-01, 1.7642e-01,\n",
      "        1.2611e-01, 6.9547e-02, 1.1162e-01, 1.2969e-01, 1.2183e-01, 7.5721e-02,\n",
      "        1.0705e-01, 9.7847e-02, 1.2276e-01, 8.3354e-02, 7.2078e-02, 1.1467e-01,\n",
      "        7.1297e-02, 1.2031e-01, 1.2043e-01, 1.4051e-01, 9.2973e-02, 1.0712e-01,\n",
      "        1.0118e-01, 1.4865e-01, 1.0301e-01, 1.2093e-01, 8.1531e-02, 1.3206e-01,\n",
      "        6.8309e-02, 8.7775e-02, 8.6297e-02, 1.2550e-01, 7.3056e-02, 6.6941e-02,\n",
      "        6.5280e-02, 8.2805e-02, 4.6333e-02, 8.4078e-02, 6.7719e-02, 5.7101e-02,\n",
      "        6.9456e-02, 8.1670e-02, 8.2973e-02, 8.5754e-02, 1.3731e-01, 1.1163e-01,\n",
      "        7.3451e-02, 7.0003e-02, 9.4265e-02, 1.0852e-01, 1.3946e-01, 4.0494e-02,\n",
      "        5.8701e-02, 8.8972e-02, 7.9770e-02, 9.6651e-02, 7.5578e-02, 7.4973e-02,\n",
      "        1.5301e-01, 8.9701e-02, 9.2806e-02, 1.1028e-01, 5.5302e-02, 6.3527e-02,\n",
      "        6.7546e-02, 1.1580e-01, 1.3252e-01, 1.4552e-01, 1.1978e-01, 1.8142e-01,\n",
      "        1.0296e-01, 8.8561e-02, 1.3006e-01, 1.0204e-01, 1.1856e-01, 1.1058e-01,\n",
      "        7.9307e-02, 6.8876e-02, 7.5091e-02, 9.1098e-02, 7.8335e-02, 8.8633e-02,\n",
      "        7.9241e-02, 1.1229e-01, 1.0341e-01, 6.6896e-02, 1.0671e-01, 1.3533e-01,\n",
      "        1.4239e-01, 9.9345e-02, 7.4621e-02, 8.7901e-02, 1.1787e-01, 1.1337e-01,\n",
      "        1.2353e-01, 9.4344e-02, 1.6428e-01, 9.5858e-02, 1.0173e-01, 1.0100e-01,\n",
      "        1.1509e-01, 5.8363e-02, 1.1524e-01, 7.3854e-02, 8.5521e-02, 6.7456e-02,\n",
      "        9.9213e-02, 1.1688e-01, 6.9637e-02, 1.3377e-01, 1.6418e-01, 1.3385e-01,\n",
      "        1.1489e-01, 7.7441e-02, 6.8692e-02, 8.5648e-02, 1.2686e-01, 1.1979e-01,\n",
      "        1.4859e-01, 1.3249e-01, 8.9103e-02, 7.7916e-02, 1.0850e-01, 9.0741e-02,\n",
      "        1.2071e-01, 1.2648e-01, 8.8701e-02, 8.8561e-02, 9.5423e-02, 1.0876e-01,\n",
      "        1.2763e-01, 1.2844e-01, 6.1585e-02, 9.0153e-02, 1.8088e-01, 6.9250e-02,\n",
      "        8.6065e-02, 1.2060e-01, 1.1413e-01, 6.1959e-02, 1.3204e-01, 1.5042e-01,\n",
      "        7.3201e-02, 7.4232e-02, 1.1933e-01, 1.2502e-01, 1.0823e-01, 8.5852e-02,\n",
      "        8.3506e-02, 9.5401e-02, 7.7517e-02, 8.8728e-02, 1.4907e-01, 1.1503e-01,\n",
      "        7.7428e-02, 8.9537e-02, 1.6709e-01, 8.6553e-02, 6.5430e-02, 1.2908e-01,\n",
      "        8.1796e-02, 1.0108e-01, 8.3900e-02, 1.6356e-01, 9.2348e-02, 1.1089e-01,\n",
      "        1.0205e-01, 1.2856e-01, 1.3162e-01, 7.1251e-02, 8.3593e-02, 9.7564e-02,\n",
      "        9.2692e-02, 1.0706e-01, 1.1620e-01, 8.2196e-02, 1.6754e-01, 7.4683e-02,\n",
      "        7.9943e-02, 1.0685e-01, 9.7541e-02, 8.0063e-02, 9.1755e-02, 1.0309e-01,\n",
      "        9.5058e-02, 8.6266e-02, 8.0865e-02, 6.9595e-02, 5.8481e-02, 1.2228e-01,\n",
      "        8.1374e-02, 1.0774e-01, 5.7792e-02, 9.6503e-02, 1.4113e-01, 1.0315e-01,\n",
      "        8.6576e-02, 9.6109e-02, 7.9699e-02, 1.1071e-01, 4.5163e-02, 8.2077e-02,\n",
      "        1.2360e-01, 1.8571e-01, 7.6043e-02, 7.5675e-02, 6.3908e-02, 7.0711e-02,\n",
      "        6.2849e-02, 1.0992e-01, 1.2967e-01, 8.6572e-02, 9.4436e-02, 9.5353e-02,\n",
      "        1.1979e-01, 1.7288e-01, 1.1489e-01, 6.3671e-02, 8.7006e-02, 9.0628e-02,\n",
      "        1.2104e-01, 1.4027e-01, 1.2181e-01, 1.3578e-01, 1.2970e-01, 9.6719e-02,\n",
      "        1.4982e-01, 8.4737e-02, 1.4214e-01, 9.7329e-02, 1.2375e-01, 1.1960e-01,\n",
      "        1.3126e-01, 7.1524e-02, 1.9648e-01, 6.0425e-02, 1.2729e-01, 6.6788e-02,\n",
      "        1.1365e-01, 1.1164e-01, 7.4175e-02, 1.2490e-01, 7.0621e-02, 6.8720e-02,\n",
      "        1.3445e-01, 1.0432e-01, 9.6787e-02, 5.9626e-02, 1.0356e-01, 1.1576e-01,\n",
      "        1.3768e-01, 1.2976e-01, 7.5931e-02, 7.9947e-02, 1.0888e-01, 1.3809e-01,\n",
      "        6.6293e-02, 8.2994e-02, 9.9213e-02, 1.2217e-01, 5.7878e-02, 7.9966e-02,\n",
      "        1.0231e-01, 1.2139e-01, 7.6508e-02, 1.1033e-01, 8.2590e-02, 1.5128e-01,\n",
      "        1.4438e-01, 1.2965e-01, 1.3827e-01, 8.3636e-02, 1.1814e-01, 8.3460e-02,\n",
      "        1.2154e-01, 8.5718e-02, 1.1925e-01, 8.9589e-02, 8.1065e-02, 6.9751e-02,\n",
      "        8.9626e-02, 1.6031e-01, 1.0525e-01, 5.9360e-02, 6.5112e-02, 9.3544e-02,\n",
      "        1.2167e-01, 8.5247e-02, 1.0902e-01, 1.3533e-01, 1.0885e-01, 8.9147e-02,\n",
      "        1.1347e-01, 5.6052e-45, 6.4690e-02, 9.7260e-02, 8.6513e-02, 9.0519e-02,\n",
      "        8.9635e-02, 9.1845e-02, 9.9796e-02, 8.1682e-02, 1.2796e-01, 8.5497e-02,\n",
      "        7.9221e-02, 1.2865e-01, 8.1798e-02, 1.3693e-01, 6.5164e-02, 7.9029e-02,\n",
      "        9.0580e-02, 1.6738e-01, 7.8145e-02, 6.6162e-02, 6.7981e-02, 1.0764e-01,\n",
      "        1.1292e-01, 1.0912e-01, 8.4244e-02, 1.0054e-01, 1.1201e-01, 8.5830e-02,\n",
      "        1.0230e-01, 1.4104e-01, 1.2358e-01, 1.0707e-01, 8.2022e-02, 8.2765e-02,\n",
      "        7.3375e-02, 7.8672e-02, 1.2643e-01, 8.9536e-02, 7.6664e-02, 5.7854e-02,\n",
      "        1.1673e-01, 1.0178e-01, 1.3034e-01, 1.3439e-01, 1.1836e-01, 6.9786e-02,\n",
      "        1.0991e-01, 1.0053e-01, 9.4832e-02, 9.4857e-02, 6.3037e-02, 1.0548e-01,\n",
      "        8.7265e-02, 6.0621e-02, 1.0445e-01, 1.0435e-01, 6.9314e-02, 8.0265e-02,\n",
      "        1.2723e-01, 9.3493e-02, 1.2421e-01, 1.0938e-01, 6.3824e-02, 1.1463e-01,\n",
      "        8.2501e-02, 1.0142e-01, 9.1078e-02, 1.1200e-01, 1.0715e-01, 7.9761e-02,\n",
      "        1.2638e-01, 6.5038e-02, 8.4356e-02, 4.3662e-02, 1.1156e-01, 6.8968e-02,\n",
      "        1.4681e-01, 1.4315e-01, 1.1835e-01, 1.0566e-01, 9.7532e-02, 9.3923e-02,\n",
      "        1.6263e-01, 9.3208e-02, 7.5725e-02, 8.4747e-02, 1.1198e-01, 1.1140e-01,\n",
      "        7.9804e-02, 1.3101e-01, 1.1846e-01, 1.0335e-01, 1.4618e-01, 7.4718e-02,\n",
      "        1.5468e-01, 9.0376e-02, 5.0024e-02, 1.0006e-01, 1.0021e-01, 9.1151e-02,\n",
      "        7.0428e-02, 7.2763e-02, 7.3124e-02, 7.7670e-02, 9.2984e-02, 1.9778e-01,\n",
      "        5.7311e-02, 9.8233e-02, 9.8298e-02, 1.1850e-01, 1.3982e-01, 7.3060e-02,\n",
      "        6.4637e-02, 5.6052e-45, 9.9202e-02, 1.2738e-01, 8.4206e-02, 9.0713e-02,\n",
      "        9.4443e-02, 1.2619e-01])), ('encoder.convolutions.2.1.num_batches_tracked', tensor(18012)), ('encoder.lstm.weight_ih_l0', tensor([[ 0.0066,  0.0051,  0.0071,  ...,  0.0068,  0.0071,  0.0043],\n",
      "        [-0.0626, -0.0337, -0.0349,  ...,  0.0486, -0.0257,  0.0154],\n",
      "        [ 0.0419,  0.0978, -0.0391,  ..., -0.0667, -0.0215,  0.0551],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0142, -0.0135,  ..., -0.0104,  0.0305,  0.0039],\n",
      "        [-0.0227, -0.0299, -0.0203,  ..., -0.0220, -0.0348, -0.0467],\n",
      "        [ 0.0370,  0.0457,  0.0200,  ...,  0.0322, -0.0060,  0.0037]])), ('encoder.lstm.weight_hh_l0', tensor([[-3.8660e-03,  1.6100e-03,  8.4437e-03,  ...,  8.5442e-03,\n",
      "         -3.2168e-03, -1.3456e-03],\n",
      "        [-6.2125e-04, -5.0744e-02, -7.7226e-03,  ...,  9.0537e-02,\n",
      "          2.3383e-04, -3.4283e-02],\n",
      "        [-2.1614e-05,  1.2085e-01,  7.0408e-02,  ..., -1.8902e-02,\n",
      "          8.2158e-03,  9.8318e-03],\n",
      "        ...,\n",
      "        [-1.8132e-02, -2.4839e-02, -4.2425e-03,  ...,  5.8579e-03,\n",
      "         -1.7717e-02, -3.7463e-02],\n",
      "        [ 7.1337e-03, -3.6080e-02,  3.5164e-02,  ..., -4.8805e-02,\n",
      "          3.2836e-03,  4.2137e-02],\n",
      "        [-1.3803e-02,  5.3523e-02,  3.5604e-02,  ..., -2.3826e-02,\n",
      "         -5.2354e-03,  2.2923e-03]])), ('encoder.lstm.bias_ih_l0', tensor([ 0.0428,  0.0153,  0.0866,  ...,  0.0319, -0.0691,  0.0850])), ('encoder.lstm.bias_hh_l0', tensor([ 0.0386,  0.0357,  0.0918,  ...,  0.0346, -0.0485,  0.0694])), ('encoder.lstm.weight_ih_l0_reverse', tensor([[-0.0115, -0.0079,  0.0119,  ...,  0.0136, -0.0108,  0.0182],\n",
      "        [-0.0006, -0.0056, -0.0080,  ..., -0.0106, -0.0065, -0.0127],\n",
      "        [-0.0482,  0.0042, -0.0029,  ..., -0.0194,  0.0145, -0.0115],\n",
      "        ...,\n",
      "        [ 0.0079,  0.0079,  0.0120,  ...,  0.0143, -0.0028,  0.0203],\n",
      "        [-0.0121, -0.0233,  0.0074,  ..., -0.0149,  0.0258,  0.0209],\n",
      "        [ 0.0039, -0.0230,  0.0223,  ...,  0.0044, -0.0203, -0.0580]])), ('encoder.lstm.weight_hh_l0_reverse', tensor([[-0.0138,  0.0089,  0.0306,  ..., -0.0154,  0.0175,  0.0390],\n",
      "        [ 0.0041,  0.0104,  0.0074,  ..., -0.0244,  0.0007, -0.0112],\n",
      "        [ 0.0066, -0.0152,  0.0555,  ..., -0.0085,  0.0197,  0.0303],\n",
      "        ...,\n",
      "        [ 0.0047,  0.0213, -0.0055,  ..., -0.0897, -0.0223, -0.0048],\n",
      "        [ 0.0071, -0.0271,  0.0341,  ...,  0.0683, -0.0832, -0.0128],\n",
      "        [ 0.0057, -0.0229,  0.0441,  ...,  0.0123, -0.0254,  0.0624]])), ('encoder.lstm.bias_ih_l0_reverse', tensor([-0.0460, -0.0126, -0.0008,  ...,  0.0846,  0.0077, -0.0346])), ('encoder.lstm.bias_hh_l0_reverse', tensor([-0.0242,  0.0085,  0.0164,  ...,  0.0404,  0.0197, -0.0095])), ('decoder.range_predictor.lstm.weight_ih_l0', tensor([[ 0.0226, -0.0004, -0.0328,  ...,  0.0220, -0.0254,  0.0375],\n",
      "        [ 0.0024, -0.0073, -0.0169,  ...,  0.0247, -0.0345, -0.0167],\n",
      "        [ 0.0041, -0.0408, -0.0359,  ...,  0.0388, -0.0095,  0.0380],\n",
      "        ...,\n",
      "        [ 0.0194,  0.0101, -0.0125,  ..., -0.0285,  0.0083, -0.0374],\n",
      "        [ 0.0035,  0.0433, -0.0033,  ..., -0.0191, -0.0008,  0.0379],\n",
      "        [ 0.0398, -0.0169,  0.0252,  ..., -0.0004,  0.0004, -0.0317]])), ('decoder.range_predictor.lstm.weight_hh_l0', tensor([[ 0.0087, -0.0191, -0.0206,  ...,  0.0167,  0.0066, -0.0191],\n",
      "        [-0.0308,  0.0014,  0.0326,  ...,  0.0179,  0.0359, -0.0047],\n",
      "        [-0.0257,  0.0227,  0.0249,  ..., -0.0153, -0.0202, -0.0013],\n",
      "        ...,\n",
      "        [ 0.0260,  0.0375,  0.0423,  ..., -0.0333,  0.0419, -0.0083],\n",
      "        [ 0.0188,  0.0268, -0.0188,  ...,  0.0132, -0.0256, -0.0161],\n",
      "        [-0.0362, -0.0205,  0.0195,  ..., -0.0419, -0.0025, -0.0050]])), ('decoder.range_predictor.lstm.bias_ih_l0', tensor([-0.0061, -0.0351,  0.0297,  ...,  0.0299, -0.0330,  0.0341])), ('decoder.range_predictor.lstm.bias_hh_l0', tensor([-0.0442, -0.0241,  0.0418,  ..., -0.0283, -0.0033,  0.0198])), ('decoder.range_predictor.lstm.weight_ih_l0_reverse', tensor([[-0.0124,  0.0027, -0.0114,  ..., -0.0208,  0.0438,  0.0002],\n",
      "        [ 0.0017, -0.0017,  0.0331,  ...,  0.0013, -0.0023,  0.0118],\n",
      "        [-0.0435, -0.0163, -0.0090,  ...,  0.0245,  0.0086,  0.0266],\n",
      "        ...,\n",
      "        [ 0.0073,  0.0134, -0.0040,  ...,  0.0085,  0.0062,  0.0143],\n",
      "        [-0.0004, -0.0428,  0.0106,  ...,  0.0114,  0.0422, -0.0039],\n",
      "        [ 0.0128, -0.0347, -0.0083,  ...,  0.0222, -0.0109, -0.0113]])), ('decoder.range_predictor.lstm.weight_hh_l0_reverse', tensor([[-0.0295, -0.0425,  0.0048,  ..., -0.0026,  0.0190, -0.0063],\n",
      "        [-0.0142, -0.0354,  0.0116,  ..., -0.0379,  0.0262,  0.0005],\n",
      "        [-0.0380,  0.0202,  0.0294,  ..., -0.0101, -0.0177,  0.0437],\n",
      "        ...,\n",
      "        [-0.0244,  0.0331,  0.0111,  ...,  0.0251, -0.0387,  0.0395],\n",
      "        [ 0.0223, -0.0181, -0.0322,  ..., -0.0435, -0.0334, -0.0223],\n",
      "        [-0.0260,  0.0157, -0.0413,  ...,  0.0027, -0.0422,  0.0340]])), ('decoder.range_predictor.lstm.bias_ih_l0_reverse', tensor([ 0.0031, -0.0085,  0.0213,  ...,  0.0089, -0.0221,  0.0191])), ('decoder.range_predictor.lstm.bias_hh_l0_reverse', tensor([-0.0064,  0.0091,  0.0055,  ..., -0.0198,  0.0108, -0.0199])), ('decoder.range_predictor.lstm.weight_ih_l1', tensor([[-0.0390, -0.0312,  0.0260,  ..., -0.0139, -0.0022, -0.0146],\n",
      "        [ 0.0409, -0.0384,  0.0347,  ..., -0.0181, -0.0314,  0.0321],\n",
      "        [ 0.0120, -0.0179, -0.0379,  ...,  0.0154, -0.0060, -0.0334],\n",
      "        ...,\n",
      "        [ 0.0393,  0.0341, -0.0252,  ...,  0.0012, -0.0080, -0.0047],\n",
      "        [-0.0022, -0.0380,  0.0036,  ..., -0.0036, -0.0359,  0.0341],\n",
      "        [-0.0224, -0.0361,  0.0094,  ...,  0.0229, -0.0032, -0.0231]])), ('decoder.range_predictor.lstm.weight_hh_l1', tensor([[ 0.0206, -0.0048,  0.0362,  ..., -0.0048, -0.0277, -0.0192],\n",
      "        [ 0.0218,  0.0378,  0.0085,  ...,  0.0405, -0.0032, -0.0007],\n",
      "        [ 0.0170,  0.0385,  0.0028,  ..., -0.0126, -0.0427, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0407,  0.0133,  0.0035,  ..., -0.0244,  0.0441, -0.0306],\n",
      "        [ 0.0357,  0.0047,  0.0140,  ...,  0.0311, -0.0005, -0.0286],\n",
      "        [ 0.0186,  0.0238,  0.0237,  ...,  0.0022, -0.0323, -0.0081]])), ('decoder.range_predictor.lstm.bias_ih_l1', tensor([ 0.0394, -0.0248, -0.0055,  ..., -0.0191,  0.0050,  0.0225])), ('decoder.range_predictor.lstm.bias_hh_l1', tensor([-0.0352,  0.0120, -0.0227,  ..., -0.0088,  0.0185,  0.0296])), ('decoder.range_predictor.lstm.weight_ih_l1_reverse', tensor([[ 0.0257,  0.0306, -0.0266,  ..., -0.0150,  0.0290,  0.0168],\n",
      "        [ 0.0212, -0.0137, -0.0021,  ..., -0.0114, -0.0198, -0.0062],\n",
      "        [ 0.0090, -0.0273,  0.0083,  ...,  0.0320, -0.0087, -0.0032],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0303,  0.0191,  ..., -0.0358,  0.0238, -0.0043],\n",
      "        [-0.0296, -0.0377,  0.0381,  ...,  0.0226, -0.0088,  0.0047],\n",
      "        [ 0.0312,  0.0415, -0.0204,  ...,  0.0111, -0.0375,  0.0312]])), ('decoder.range_predictor.lstm.weight_hh_l1_reverse', tensor([[-0.0148,  0.0254,  0.0041,  ...,  0.0120, -0.0387, -0.0044],\n",
      "        [ 0.0142, -0.0074, -0.0274,  ..., -0.0432, -0.0165, -0.0161],\n",
      "        [ 0.0194,  0.0077,  0.0096,  ..., -0.0361, -0.0316, -0.0398],\n",
      "        ...,\n",
      "        [-0.0156,  0.0408,  0.0250,  ..., -0.0389, -0.0140,  0.0404],\n",
      "        [-0.0106, -0.0059, -0.0277,  ...,  0.0131,  0.0080,  0.0400],\n",
      "        [ 0.0310, -0.0438,  0.0387,  ...,  0.0353,  0.0312, -0.0420]])), ('decoder.range_predictor.lstm.bias_ih_l1_reverse', tensor([-0.0299, -0.0078,  0.0040,  ...,  0.0006, -0.0080, -0.0308])), ('decoder.range_predictor.lstm.bias_hh_l1_reverse', tensor([-0.0340, -0.0010,  0.0422,  ..., -0.0359, -0.0207,  0.0274])), ('decoder.range_predictor.proj.linear_layer.weight', tensor([[-0.0106,  0.0281,  0.0662,  ...,  0.0041,  0.0050, -0.0656]])), ('decoder.range_predictor.proj.linear_layer.bias', tensor([0.0164])), ('decoder.duration_predictor.lstm.weight_ih_l0', tensor([[ 0.0035, -0.0103,  0.0163,  ...,  0.0429,  0.0259,  0.0003],\n",
      "        [ 0.0072,  0.0216, -0.0396,  ..., -0.0265, -0.0319,  0.0030],\n",
      "        [-0.0180, -0.0430,  0.0276,  ..., -0.0234, -0.0239, -0.0353],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0399,  0.0217,  ..., -0.0393,  0.0173,  0.0221],\n",
      "        [-0.0245,  0.0267, -0.0225,  ..., -0.0243,  0.0093, -0.0348],\n",
      "        [-0.0433,  0.0213,  0.0055,  ...,  0.0351, -0.0419,  0.0037]])), ('decoder.duration_predictor.lstm.weight_hh_l0', tensor([[-0.0404, -0.0196,  0.0359,  ...,  0.0196, -0.0138,  0.0442],\n",
      "        [-0.0386, -0.0016, -0.0387,  ..., -0.0210,  0.0437,  0.0220],\n",
      "        [-0.0173,  0.0071, -0.0432,  ...,  0.0304,  0.0379, -0.0288],\n",
      "        ...,\n",
      "        [-0.0354, -0.0072,  0.0391,  ..., -0.0304,  0.0284, -0.0364],\n",
      "        [-0.0130,  0.0264, -0.0006,  ..., -0.0235,  0.0037, -0.0198],\n",
      "        [-0.0178,  0.0103, -0.0215,  ..., -0.0437, -0.0159,  0.0342]])), ('decoder.duration_predictor.lstm.bias_ih_l0', tensor([ 0.0233,  0.0060, -0.0005,  ..., -0.0053,  0.0326, -0.0285])), ('decoder.duration_predictor.lstm.bias_hh_l0', tensor([-0.0372, -0.0244, -0.0095,  ..., -0.0004, -0.0037, -0.0362])), ('decoder.duration_predictor.lstm.weight_ih_l0_reverse', tensor([[ 0.0204,  0.0031, -0.0103,  ...,  0.0439, -0.0042,  0.0050],\n",
      "        [-0.0132,  0.0384, -0.0146,  ...,  0.0321, -0.0043, -0.0317],\n",
      "        [-0.0396, -0.0083,  0.0091,  ...,  0.0146, -0.0395,  0.0316],\n",
      "        ...,\n",
      "        [-0.0067,  0.0416, -0.0181,  ...,  0.0334,  0.0011,  0.0145],\n",
      "        [-0.0159, -0.0304, -0.0334,  ..., -0.0075,  0.0006,  0.0006],\n",
      "        [ 0.0170,  0.0380, -0.0311,  ...,  0.0013, -0.0271,  0.0148]])), ('decoder.duration_predictor.lstm.weight_hh_l0_reverse', tensor([[-3.5079e-02,  3.3072e-02,  3.7007e-02,  ...,  3.1683e-02,\n",
      "         -1.3892e-02, -1.5762e-02],\n",
      "        [-1.7290e-02,  1.0084e-02,  2.4587e-02,  ...,  3.8628e-02,\n",
      "          1.3739e-02, -1.0706e-02],\n",
      "        [-3.7869e-02, -9.6798e-03,  1.8742e-02,  ...,  4.0670e-02,\n",
      "          3.0160e-02,  8.3671e-03],\n",
      "        ...,\n",
      "        [-4.2491e-02, -1.2966e-02,  1.3697e-03,  ...,  3.3928e-05,\n",
      "          2.1454e-02, -1.3413e-02],\n",
      "        [ 2.5893e-02, -2.8445e-02,  1.6768e-02,  ...,  7.1082e-03,\n",
      "         -4.2200e-02,  4.2004e-02],\n",
      "        [-2.1667e-02, -3.8959e-02,  6.9324e-03,  ...,  1.7596e-02,\n",
      "          9.4852e-03, -4.8783e-03]])), ('decoder.duration_predictor.lstm.bias_ih_l0_reverse', tensor([ 0.0301, -0.0340, -0.0244,  ..., -0.0399,  0.0028, -0.0023])), ('decoder.duration_predictor.lstm.bias_hh_l0_reverse', tensor([-0.0032, -0.0407, -0.0345,  ..., -0.0163,  0.0337,  0.0285])), ('decoder.duration_predictor.lstm.weight_ih_l1', tensor([[ 0.0106,  0.0350,  0.0061,  ...,  0.0187,  0.0388, -0.0179],\n",
      "        [-0.0215, -0.0174,  0.0132,  ..., -0.0079, -0.0311, -0.0433],\n",
      "        [-0.0415,  0.0207,  0.0314,  ..., -0.0167, -0.0096, -0.0394],\n",
      "        ...,\n",
      "        [-0.0378,  0.0352,  0.0322,  ...,  0.0245, -0.0428, -0.0322],\n",
      "        [-0.0394, -0.0186,  0.0308,  ...,  0.0266, -0.0138,  0.0360],\n",
      "        [-0.0058,  0.0220,  0.0132,  ..., -0.0187,  0.0400, -0.0253]])), ('decoder.duration_predictor.lstm.weight_hh_l1', tensor([[-0.0384,  0.0326,  0.0209,  ...,  0.0420, -0.0321, -0.0122],\n",
      "        [-0.0190,  0.0142, -0.0410,  ..., -0.0099, -0.0299, -0.0127],\n",
      "        [ 0.0249,  0.0171,  0.0375,  ..., -0.0017,  0.0301,  0.0310],\n",
      "        ...,\n",
      "        [ 0.0421,  0.0040, -0.0160,  ...,  0.0283, -0.0274, -0.0321],\n",
      "        [-0.0292,  0.0357, -0.0359,  ..., -0.0347,  0.0393, -0.0113],\n",
      "        [ 0.0126, -0.0021, -0.0102,  ..., -0.0148,  0.0323, -0.0084]])), ('decoder.duration_predictor.lstm.bias_ih_l1', tensor([ 0.0368,  0.0406,  0.0062,  ...,  0.0315,  0.0073, -0.0408])), ('decoder.duration_predictor.lstm.bias_hh_l1', tensor([-0.0155,  0.0283,  0.0411,  ...,  0.0185, -0.0126,  0.0343])), ('decoder.duration_predictor.lstm.weight_ih_l1_reverse', tensor([[-0.0163,  0.0149, -0.0424,  ...,  0.0120,  0.0344, -0.0349],\n",
      "        [-0.0180,  0.0195, -0.0264,  ..., -0.0019, -0.0376,  0.0147],\n",
      "        [ 0.0376, -0.0031, -0.0179,  ...,  0.0402,  0.0274,  0.0263],\n",
      "        ...,\n",
      "        [-0.0142,  0.0390,  0.0205,  ...,  0.0214, -0.0245,  0.0352],\n",
      "        [ 0.0233,  0.0027,  0.0394,  ...,  0.0008,  0.0390,  0.0347],\n",
      "        [ 0.0117, -0.0068, -0.0190,  ...,  0.0315,  0.0213, -0.0382]])), ('decoder.duration_predictor.lstm.weight_hh_l1_reverse', tensor([[ 0.0305, -0.0416, -0.0208,  ...,  0.0212, -0.0356,  0.0275],\n",
      "        [ 0.0322, -0.0184, -0.0269,  ...,  0.0061,  0.0265,  0.0211],\n",
      "        [ 0.0356, -0.0211, -0.0325,  ...,  0.0245, -0.0131,  0.0071],\n",
      "        ...,\n",
      "        [-0.0154, -0.0149, -0.0115,  ...,  0.0104,  0.0031, -0.0213],\n",
      "        [ 0.0008,  0.0223,  0.0018,  ..., -0.0010, -0.0144,  0.0165],\n",
      "        [-0.0067,  0.0080, -0.0417,  ...,  0.0249, -0.0224, -0.0411]])), ('decoder.duration_predictor.lstm.bias_ih_l1_reverse', tensor([ 0.0294,  0.0256,  0.0160,  ...,  0.0268,  0.0344, -0.0414])), ('decoder.duration_predictor.lstm.bias_hh_l1_reverse', tensor([ 0.0292, -0.0392,  0.0006,  ..., -0.0386,  0.0221,  0.0393])), ('decoder.duration_predictor.proj.linear_layer.weight', tensor([[ 0.0587, -0.0166,  0.0078,  ..., -0.0153,  0.0709,  0.0498]])), ('decoder.duration_predictor.proj.linear_layer.bias', tensor([-0.0230])), ('decoder.prenet.layers.0.linear_layer.weight', tensor([[ 5.7415e-02,  2.1364e-02,  7.0565e-02,  ...,  1.4960e-01,\n",
      "         -9.4665e-02, -1.3396e-02],\n",
      "        [ 7.9564e-02,  9.8666e-02,  3.4609e-02,  ..., -2.3021e-01,\n",
      "         -1.5707e-01, -8.8874e-02],\n",
      "        [-3.2529e-01, -2.1942e-02,  1.2245e-01,  ...,  3.0680e-02,\n",
      "          1.1860e-03,  1.7141e-02],\n",
      "        ...,\n",
      "        [ 7.2490e-04,  6.1919e-04,  1.2840e-04,  ...,  1.1338e-03,\n",
      "          2.4031e-03,  4.9238e-04],\n",
      "        [ 9.8120e-02, -1.5448e-02,  9.3378e-03,  ..., -9.4965e-03,\n",
      "          2.2407e-01,  1.4970e-01],\n",
      "        [ 1.5184e-02,  7.9279e-02,  2.9118e-02,  ...,  4.3022e-02,\n",
      "         -5.9975e-02,  6.9107e-02]])), ('decoder.prenet.layers.1.linear_layer.weight', tensor([[-1.3600e-02, -1.4353e-06,  2.1432e-02,  ...,  2.7196e-11,\n",
      "          1.2736e-02, -1.0836e-02],\n",
      "        [ 6.4131e-02,  1.0371e-02, -2.6150e-03,  ...,  8.3229e-07,\n",
      "          1.7379e-02,  4.2528e-02],\n",
      "        [-5.7246e-02,  2.8010e-03,  3.1302e-02,  ..., -9.0352e-06,\n",
      "         -7.5127e-02,  3.3779e-02],\n",
      "        ...,\n",
      "        [ 1.8086e-02, -6.2893e-02,  5.0963e-04,  ...,  4.8240e-13,\n",
      "          3.0745e-02,  3.5649e-02],\n",
      "        [ 8.0536e-03,  9.7390e-02,  5.4859e-03,  ...,  1.3671e-14,\n",
      "         -2.3632e-01,  7.1533e-03],\n",
      "        [-3.6514e-02,  1.9231e-02,  1.5472e-02,  ...,  1.0212e-11,\n",
      "         -9.9891e-04,  3.7558e-02]])), ('decoder.linear_projection.linear_layer.weight', tensor([[ 0.0104,  0.0128, -0.0184,  ...,  0.1184, -0.0897,  0.0050],\n",
      "        [-0.0126, -0.0082, -0.0321,  ...,  0.0971, -0.0283,  0.0022],\n",
      "        [-0.0108, -0.0161, -0.0191,  ...,  0.0698, -0.0571,  0.0127],\n",
      "        ...,\n",
      "        [-0.0042,  0.0655, -0.0275,  ...,  0.1223, -0.0242,  0.0465],\n",
      "        [ 0.0017,  0.0548, -0.0191,  ...,  0.0777, -0.0401,  0.0356],\n",
      "        [-0.0023,  0.0527, -0.0062,  ...,  0.1025, -0.0302,  0.0241]])), ('decoder.linear_projection.linear_layer.bias', tensor([-0.0502, -0.0415, -0.0307, -0.0455, -0.0335, -0.0516, -0.0251, -0.0471,\n",
      "        -0.0254, -0.0393, -0.0563, -0.0403, -0.0227, -0.0486, -0.0204, -0.0642,\n",
      "        -0.0582, -0.0221, -0.0606, -0.0649, -0.0603, -0.0389, -0.0507, -0.0385,\n",
      "        -0.0433, -0.0668, -0.0355, -0.0613, -0.0691, -0.0604, -0.0829, -0.0811,\n",
      "        -0.0624, -0.0710, -0.0705, -0.0786, -0.0797, -0.0475, -0.0821, -0.0650,\n",
      "        -0.0621, -0.0606, -0.0530, -0.0733, -0.0729, -0.0733, -0.0574, -0.0475,\n",
      "        -0.0563, -0.0656, -0.0414, -0.0820, -0.0659, -0.0809, -0.0855, -0.0595,\n",
      "        -0.0839, -0.0716, -0.0505, -0.0874, -0.0453, -0.0709, -0.0711, -0.0623,\n",
      "        -0.0503, -0.0483, -0.0827, -0.0537, -0.0696, -0.0673, -0.0698, -0.0701,\n",
      "        -0.0944, -0.0685, -0.0660, -0.0790, -0.0719, -0.0662, -0.0855, -0.0875])), ('decoder.positional_embedding.pe', tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  5.3317e-01,  ...,  1.0000e+00,\n",
      "          1.7783e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.0213e-01,  ...,  1.0000e+00,\n",
      "          3.5566e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 9.5625e-01, -2.9254e-01,  9.9089e-01,  ..., -9.3940e-03,\n",
      "          7.7619e-01,  6.3049e-01],\n",
      "        [ 2.7050e-01, -9.6272e-01,  9.1005e-01,  ..., -9.7101e-03,\n",
      "          7.7631e-01,  6.3036e-01],\n",
      "        [-6.6395e-01, -7.4778e-01,  5.4898e-01,  ..., -1.0026e-02,\n",
      "          7.7642e-01,  6.3022e-01]])), ('decoder.decoder_rnn.weight_ih_l0', tensor([[ 0.0194, -0.0250,  0.0151,  ..., -0.0284,  0.0273,  0.0119],\n",
      "        [ 0.0253,  0.0164,  0.0167,  ..., -0.0269,  0.0098, -0.0282],\n",
      "        [-0.0151, -0.0295,  0.0150,  ...,  0.0052, -0.0232,  0.0147],\n",
      "        ...,\n",
      "        [ 0.0120,  0.0080,  0.0122,  ..., -0.0056, -0.0028, -0.0141],\n",
      "        [ 0.0204,  0.0213,  0.0032,  ..., -0.0070,  0.0279,  0.0115],\n",
      "        [ 0.0110, -0.0280,  0.0189,  ...,  0.0310, -0.0074,  0.0108]])), ('decoder.decoder_rnn.weight_hh_l0', tensor([[-0.0231,  0.0077,  0.0080,  ..., -0.0296,  0.0097,  0.0203],\n",
      "        [-0.0139, -0.0247, -0.0090,  ...,  0.0092,  0.0240,  0.0208],\n",
      "        [ 0.0180, -0.0163,  0.0064,  ..., -0.0203, -0.0045, -0.0112],\n",
      "        ...,\n",
      "        [-0.0100, -0.0147,  0.0134,  ..., -0.0244,  0.0140,  0.0118],\n",
      "        [ 0.0245,  0.0220, -0.0009,  ...,  0.0022, -0.0167, -0.0273],\n",
      "        [-0.0217,  0.0097,  0.0242,  ...,  0.0161, -0.0115, -0.0050]])), ('decoder.decoder_rnn.bias_ih_l0', tensor([ 0.0187, -0.0148,  0.0270,  ...,  0.0263, -0.0262, -0.0235])), ('decoder.decoder_rnn.bias_hh_l0', tensor([ 0.0270, -0.0050,  0.0270,  ...,  0.0065, -0.0173, -0.0262])), ('decoder.decoder_rnn.weight_ih_l1', tensor([[-0.0002, -0.0066, -0.0043,  ..., -0.0099,  0.0081, -0.0246],\n",
      "        [ 0.0146, -0.0085,  0.0158,  ..., -0.0305, -0.0206,  0.0242],\n",
      "        [ 0.0061,  0.0241, -0.0020,  ...,  0.0182,  0.0068,  0.0239],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0196,  0.0275,  ...,  0.0071,  0.0080,  0.0276],\n",
      "        [ 0.0277,  0.0053, -0.0295,  ..., -0.0240, -0.0122,  0.0195],\n",
      "        [-0.0142, -0.0015,  0.0221,  ..., -0.0075, -0.0106, -0.0219]])), ('decoder.decoder_rnn.weight_hh_l1', tensor([[ 0.0162, -0.0270, -0.0193,  ...,  0.0270,  0.0026, -0.0199],\n",
      "        [ 0.0123,  0.0090, -0.0133,  ..., -0.0077,  0.0123, -0.0163],\n",
      "        [ 0.0228,  0.0158,  0.0231,  ...,  0.0041,  0.0113, -0.0151],\n",
      "        ...,\n",
      "        [ 0.0047,  0.0063, -0.0227,  ...,  0.0041, -0.0133,  0.0028],\n",
      "        [-0.0201,  0.0123, -0.0046,  ...,  0.0207, -0.0223,  0.0259],\n",
      "        [ 0.0214, -0.0167, -0.0267,  ..., -0.0076, -0.0309, -0.0037]])), ('decoder.decoder_rnn.bias_ih_l1', tensor([0.0233, 0.0142, 0.0311,  ..., 0.0244, 0.0075, 0.0254])), ('decoder.decoder_rnn.bias_hh_l1', tensor([ 0.0097, -0.0062,  0.0028,  ..., -0.0084,  0.0006,  0.0232])), ('decoder.gate_layer.linear_layer.weight', tensor([[ 0.0946,  0.2322,  0.0858,  ...,  0.1734, -0.1254, -0.0033]])), ('decoder.gate_layer.linear_layer.bias', tensor([-0.0251])), ('postnet.convolutions.0.0.conv.weight', tensor([[[ 3.4895e-03, -3.9575e-02,  2.7195e-03,  5.2804e-03, -9.0449e-03],\n",
      "         [ 2.2329e-02, -4.6564e-05, -3.6460e-02,  6.5331e-02, -1.7686e-05],\n",
      "         [-1.4333e-02, -2.2477e-02, -2.3160e-02,  7.0170e-02,  3.1559e-03],\n",
      "         ...,\n",
      "         [-1.1709e-02,  3.8970e-02, -6.7017e-02, -2.9573e-02, -5.6825e-02],\n",
      "         [-5.4851e-02,  8.7261e-02,  2.5190e-02, -1.2441e-04, -6.6429e-03],\n",
      "         [ 2.4728e-02,  6.5376e-02, -2.9345e-02, -2.1159e-02,  3.3018e-02]],\n",
      "\n",
      "        [[ 5.4563e-02, -1.8728e-02,  4.3920e-02, -5.8151e-02,  1.9288e-02],\n",
      "         [-5.9065e-02, -3.1662e-02,  1.2090e-01, -4.7048e-02, -1.1731e-01],\n",
      "         [-1.2459e-02,  2.6536e-03,  7.4434e-02,  3.8319e-02,  4.6132e-02],\n",
      "         ...,\n",
      "         [ 8.8164e-03,  1.8087e-02,  1.1455e-02, -4.4831e-02, -8.3290e-02],\n",
      "         [-3.8489e-02, -2.5214e-02, -8.0351e-03,  1.0039e-01, -2.7029e-02],\n",
      "         [-2.3967e-02,  1.7961e-02,  2.7362e-02,  4.7968e-03, -4.8303e-03]],\n",
      "\n",
      "        [[ 3.3394e-02,  4.1968e-02, -8.8713e-03,  4.8358e-02, -2.9212e-02],\n",
      "         [-4.4683e-02,  9.3435e-03, -6.1305e-02, -1.4652e-02, -1.3284e-02],\n",
      "         [ 8.9404e-03,  1.7008e-02, -3.4552e-02,  2.5441e-02, -5.9523e-03],\n",
      "         ...,\n",
      "         [ 6.7049e-02, -1.3309e-02,  4.7800e-02,  2.0403e-02,  1.9651e-03],\n",
      "         [-5.8261e-03,  3.3015e-02,  8.3635e-03, -3.8624e-02, -6.5632e-03],\n",
      "         [ 8.2094e-03, -3.7809e-02,  2.9247e-03, -1.1883e-02, -4.6921e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.6079e-04, -9.6142e-03, -1.5662e-02,  1.3709e-02,  3.9226e-02],\n",
      "         [-3.0955e-02,  2.2664e-02,  3.6997e-02, -1.1587e-03,  4.9578e-02],\n",
      "         [-7.3441e-03, -1.4725e-03,  3.8501e-02, -9.4229e-04,  8.8873e-04],\n",
      "         ...,\n",
      "         [-3.7707e-02,  3.9329e-02, -3.0933e-02, -2.2897e-03,  4.8925e-02],\n",
      "         [-1.9438e-02,  8.2005e-03,  2.8857e-02,  1.1910e-03,  1.3013e-02],\n",
      "         [ 1.6303e-02,  4.8707e-02,  4.9031e-02, -3.1546e-02, -2.9907e-02]],\n",
      "\n",
      "        [[ 6.3463e-02, -2.2255e-02,  3.9123e-02,  1.1004e-01, -4.4306e-02],\n",
      "         [-8.4156e-02, -7.5026e-02, -1.0736e-01, -2.3941e-02,  3.3161e-02],\n",
      "         [ 2.1653e-02, -1.7674e-02, -5.4294e-02,  1.1449e-01,  4.8876e-02],\n",
      "         ...,\n",
      "         [-4.2973e-02, -1.9860e-02, -2.0367e-02, -7.9166e-02,  1.0264e-01],\n",
      "         [-2.1590e-02,  1.2694e-02,  1.7785e-02, -1.7654e-02,  6.2830e-02],\n",
      "         [ 1.6494e-03,  2.1212e-02,  2.0987e-02, -1.0223e-01,  6.2228e-02]],\n",
      "\n",
      "        [[ 1.7618e-02,  2.5917e-02,  1.1956e-02,  5.9649e-02,  4.1640e-02],\n",
      "         [ 3.7023e-02, -1.1641e-01, -1.0685e-01,  4.5299e-02, -3.6026e-02],\n",
      "         [ 1.7296e-03, -3.6889e-02, -1.0034e-01,  9.1641e-03,  3.8131e-02],\n",
      "         ...,\n",
      "         [-7.2327e-02, -1.0065e-02,  4.9228e-02,  9.3314e-02, -4.4601e-02],\n",
      "         [-5.5240e-02,  3.6917e-02,  2.7497e-02,  1.1696e-01,  8.9956e-02],\n",
      "         [-4.4575e-02, -1.5207e-02, -9.1387e-02,  6.4757e-02, -8.9688e-02]]])), ('postnet.convolutions.0.0.conv.bias', tensor([-2.8496e-05,  7.6365e-06, -1.1638e-04,  6.2632e-06,  1.1243e-04,\n",
      "         8.9056e-05, -2.0502e-04, -2.0644e-04,  2.6560e-04, -1.0080e-04,\n",
      "        -6.4904e-05,  2.6029e-05, -1.9099e-04, -1.1910e-04,  2.9524e-05,\n",
      "         8.3407e-05, -3.1172e-04,  1.5395e-04,  2.5312e-04, -6.3425e-05,\n",
      "        -9.3802e-05,  4.8097e-07,  1.6835e-05,  4.8955e-06, -2.2041e-05,\n",
      "         8.4427e-05, -5.1633e-05, -1.8582e-04,  4.6634e-05, -2.5630e-04,\n",
      "        -4.6541e-05,  1.5100e-04, -3.1264e-04,  2.2797e-04, -1.8461e-05,\n",
      "         2.1041e-05,  6.8023e-05, -7.2110e-05, -2.2061e-05, -1.2848e-04,\n",
      "         3.4709e-05, -1.8030e-05,  2.8116e-05,  2.7354e-04, -1.8094e-04,\n",
      "         6.9399e-05, -5.5965e-06,  5.4944e-05,  1.9922e-05, -2.2706e-04,\n",
      "         9.0765e-05, -2.6527e-05,  4.7188e-05, -6.0385e-05,  5.8146e-05,\n",
      "        -5.0606e-05,  3.6852e-05,  7.7473e-05, -1.5572e-04, -1.7246e-04,\n",
      "         6.4988e-05,  1.0301e-04,  6.2152e-05,  7.2663e-05, -2.8667e-04,\n",
      "        -4.5050e-05,  1.0333e-04,  2.4319e-06, -5.7026e-05,  1.2770e-05,\n",
      "        -1.5180e-04, -2.3124e-04,  8.8713e-05, -2.8877e-06, -3.1482e-04,\n",
      "        -6.5616e-05,  5.5782e-05, -1.4436e-04, -1.9809e-04, -4.6240e-05,\n",
      "         1.6204e-04, -2.0316e-04, -4.0999e-05,  2.4253e-04, -5.1259e-04,\n",
      "         2.9465e-04, -1.5387e-05,  7.7128e-05,  6.6416e-05, -6.5814e-05,\n",
      "         1.3311e-04, -4.0174e-05, -7.9225e-05, -3.5525e-04,  1.6330e-04,\n",
      "         1.6997e-04, -2.1408e-04, -3.5144e-05, -7.5450e-05,  1.0235e-04,\n",
      "        -2.2338e-05, -1.8684e-04,  1.0637e-04,  2.0432e-04,  1.7348e-04,\n",
      "         7.8679e-05,  3.0589e-05, -2.9862e-04, -1.4713e-04, -2.0991e-04,\n",
      "         9.1789e-05, -1.1290e-04, -2.6172e-04,  1.0762e-04, -4.9788e-05,\n",
      "         3.1366e-04, -2.5995e-05,  5.9081e-05,  9.9777e-05, -2.9681e-05,\n",
      "        -9.3483e-07, -1.4469e-05, -3.2720e-05, -3.6265e-04, -5.5643e-05,\n",
      "        -4.6139e-05, -9.7513e-05, -4.5797e-05,  6.4191e-05,  4.5967e-05,\n",
      "        -1.0968e-04,  5.6180e-05,  1.3926e-05,  2.5016e-06,  2.2669e-05,\n",
      "         1.1254e-04,  6.7720e-05,  9.6478e-05,  2.3690e-05, -3.3275e-04,\n",
      "         6.9370e-05,  2.0872e-04, -1.9959e-05, -2.6287e-04,  1.2931e-04,\n",
      "         8.1336e-05, -7.2042e-05, -6.1095e-06, -4.0694e-05,  5.3103e-05,\n",
      "         9.5251e-05,  8.7656e-06, -1.7790e-05, -2.2771e-04,  8.5206e-05,\n",
      "        -1.4907e-04,  1.9596e-04, -1.5973e-05, -1.7885e-04,  1.3230e-04,\n",
      "         1.2513e-04,  1.5868e-04,  1.6175e-04, -7.5960e-05,  8.9839e-05,\n",
      "         8.2084e-05, -2.5999e-04,  3.9169e-05,  1.1323e-05,  3.7934e-05,\n",
      "        -1.4305e-04,  2.2540e-04,  1.8941e-04, -9.6991e-05,  9.7685e-05,\n",
      "        -2.1064e-04,  1.0256e-04,  8.5663e-05,  9.0285e-05,  1.7997e-04,\n",
      "         1.5207e-04, -3.8547e-04, -1.1475e-04,  3.2269e-04, -5.6035e-05,\n",
      "        -5.9722e-05,  1.2656e-04,  2.0202e-05, -2.5777e-04, -6.3219e-05,\n",
      "        -1.2674e-04, -5.1202e-05, -1.7505e-04,  2.8918e-05,  3.6783e-05,\n",
      "         2.3323e-04,  2.1869e-05, -1.0944e-04,  5.9067e-05,  1.0710e-04,\n",
      "         2.4630e-04, -2.5588e-04,  1.2747e-05, -1.8878e-04,  5.7451e-05,\n",
      "        -1.0045e-04, -7.8182e-06, -9.1293e-05, -3.6259e-05,  1.5281e-05,\n",
      "         1.5518e-04,  1.5005e-04, -2.7780e-04,  5.0379e-05,  2.9814e-05,\n",
      "        -1.6946e-05,  8.1729e-06, -4.0407e-05, -2.6354e-05, -2.1296e-04,\n",
      "         8.7615e-05, -1.4659e-04,  7.8686e-07,  4.0735e-05,  2.9155e-05,\n",
      "        -9.6061e-05, -1.1796e-05, -1.0992e-04,  9.7682e-05,  2.9594e-05,\n",
      "         5.0993e-05,  3.1446e-05,  1.1208e-04,  6.7736e-05,  5.4989e-05,\n",
      "        -1.9053e-05,  1.4467e-04,  4.4490e-05,  4.1244e-05,  1.0564e-04,\n",
      "         5.7634e-05, -3.0137e-05, -1.4529e-04,  1.1477e-04, -9.5515e-05,\n",
      "         1.4029e-04, -2.9073e-05,  1.5314e-04,  1.5461e-05,  6.9369e-05,\n",
      "         2.0433e-04, -1.6299e-04, -7.6145e-05,  2.8762e-04,  9.4651e-05,\n",
      "        -2.0058e-05,  5.5216e-05,  5.3754e-05,  2.1653e-04,  9.4242e-05,\n",
      "         2.0994e-04,  6.6905e-06, -4.5875e-05, -1.6781e-04,  3.3659e-05,\n",
      "         3.6446e-04, -6.6913e-05,  9.5068e-05,  2.1285e-04, -3.0703e-05,\n",
      "         2.4505e-05,  5.7393e-05,  8.1932e-05, -1.1937e-04,  5.9706e-05,\n",
      "        -1.3476e-04,  1.4408e-04, -1.4787e-04, -3.3040e-05,  6.8258e-05,\n",
      "         1.7685e-04, -1.8948e-05,  1.2927e-04, -1.9257e-05, -2.6859e-05,\n",
      "        -6.3143e-05, -5.4283e-05,  1.2337e-05, -1.5164e-05, -1.6956e-05,\n",
      "         3.2098e-05, -1.2145e-04,  5.3657e-05,  9.6768e-05,  2.5223e-04,\n",
      "        -6.6600e-05, -1.7632e-04,  9.8310e-05,  2.0597e-05,  2.7683e-04,\n",
      "         1.6929e-04, -1.2547e-04, -1.5822e-04, -2.9218e-04,  1.7234e-04,\n",
      "         4.7792e-05,  5.9486e-05,  1.0679e-04,  2.4596e-05, -1.9566e-04,\n",
      "         5.4725e-05, -8.8320e-05,  1.2516e-04, -2.9323e-05,  9.5092e-05,\n",
      "        -1.0207e-04, -1.1922e-04, -2.6633e-05, -6.0617e-05,  1.2623e-04,\n",
      "         6.7393e-04,  3.7975e-05,  1.3216e-04,  3.7141e-05,  7.8059e-05,\n",
      "         7.4604e-05,  3.3340e-05, -8.2204e-05, -1.3058e-04,  2.5457e-05,\n",
      "        -1.2707e-04, -9.3059e-05, -3.3198e-05, -9.5329e-05, -3.2983e-06,\n",
      "        -3.6466e-05, -1.7030e-04, -8.9117e-05, -3.5843e-05,  1.9976e-04,\n",
      "        -4.3678e-06,  6.3188e-05,  1.2664e-04, -1.5341e-04, -1.5882e-05,\n",
      "         1.3892e-04,  7.2459e-05,  1.4844e-04,  1.7190e-04, -1.9251e-05,\n",
      "        -4.1274e-05,  2.6533e-05,  1.8697e-04, -4.0981e-04, -2.8486e-06,\n",
      "         1.7887e-04,  7.7964e-05, -8.3104e-05, -5.3887e-05, -6.1326e-05,\n",
      "         6.0211e-05, -1.0991e-04,  3.1708e-05, -2.9123e-04,  2.0199e-04,\n",
      "         7.3086e-05,  3.0259e-05,  3.2846e-04, -1.2031e-04,  2.9608e-05,\n",
      "        -1.5553e-04, -1.6154e-04, -9.8900e-06,  4.5596e-05, -1.6808e-04,\n",
      "         6.2698e-05, -2.2712e-05, -2.0159e-04,  1.1947e-04,  8.0363e-05,\n",
      "        -2.9493e-05, -1.2832e-04,  3.7765e-05,  7.1685e-05, -2.9940e-04,\n",
      "        -2.0741e-04, -3.5231e-05,  7.0452e-05,  5.3074e-05, -1.7057e-04,\n",
      "        -1.8275e-05, -1.3498e-04, -1.5145e-04,  2.5404e-04, -1.1436e-04,\n",
      "         9.4895e-05,  1.6696e-04, -5.4213e-05, -1.0933e-04, -1.1105e-06,\n",
      "         1.1395e-04,  8.0207e-05, -6.9809e-05,  5.1622e-05,  1.4494e-04,\n",
      "         1.5077e-04, -5.8724e-05, -2.8560e-05,  1.0699e-04, -3.5301e-04,\n",
      "         3.7986e-05, -3.6629e-05,  1.8955e-04, -1.4831e-05,  1.3779e-06,\n",
      "        -1.4343e-04, -3.9586e-05, -1.2516e-04, -7.8910e-05, -9.3587e-06,\n",
      "         6.3432e-05,  3.6642e-05, -1.4113e-04, -1.1567e-04,  9.6453e-05,\n",
      "         6.9124e-05,  1.5456e-04, -2.6682e-05, -5.8936e-05, -5.5871e-06,\n",
      "        -2.4836e-05, -4.1206e-05,  2.5663e-04,  6.6160e-05,  3.2035e-05,\n",
      "         1.0095e-05, -6.4012e-05, -2.3082e-04, -3.8171e-04, -9.7713e-05,\n",
      "         1.5992e-05, -1.3708e-06,  1.5450e-04, -1.5240e-04, -2.3457e-05,\n",
      "         3.8244e-05, -1.3669e-05, -1.4657e-04, -8.6082e-05,  1.0363e-04,\n",
      "         2.7705e-04,  8.1327e-05,  7.2570e-05,  1.6023e-04,  1.8507e-05,\n",
      "         1.4069e-05, -9.1098e-07, -4.0548e-05,  1.6651e-04, -1.4639e-04,\n",
      "        -3.9984e-05, -1.5502e-04, -1.4480e-04, -3.8268e-05, -8.0670e-05,\n",
      "         1.2134e-05,  5.5350e-07, -9.4266e-05,  1.9016e-05, -1.8603e-05,\n",
      "         1.1442e-04,  1.0564e-05, -2.3684e-04, -3.7847e-05,  1.0810e-04,\n",
      "        -5.9155e-05,  1.8669e-04,  2.6893e-04, -6.9900e-06, -2.1027e-04,\n",
      "        -1.5788e-05, -2.3122e-04,  1.1709e-04, -1.5650e-04, -2.4944e-04,\n",
      "        -4.0942e-05,  4.7767e-05, -6.9016e-05,  1.1500e-04,  1.5830e-04,\n",
      "         2.6736e-05,  1.0690e-05,  1.5265e-05,  2.6385e-04, -7.0004e-05,\n",
      "        -1.0346e-04,  1.7051e-04, -2.0482e-05, -5.1378e-05, -1.2711e-04,\n",
      "         1.5430e-04, -5.3856e-05,  1.0301e-04, -1.1525e-04, -8.4654e-05,\n",
      "        -6.8984e-06, -1.3312e-04, -1.7220e-04,  3.2246e-04, -2.2336e-04,\n",
      "        -1.0582e-04,  1.9269e-05])), ('postnet.convolutions.0.1.weight', tensor([ 7.2207e-02,  8.2572e-02,  7.1399e-02,  5.5770e-02,  8.8304e-02,\n",
      "         8.6935e-02,  1.1775e-01,  1.0110e-01,  9.9853e-02,  8.7096e-02,\n",
      "         8.0389e-02,  1.0354e-01,  1.0405e-01,  2.6755e-05,  7.1956e-02,\n",
      "         7.5723e-02,  1.2048e+00,  1.1116e-01,  6.8330e-02,  8.8842e-02,\n",
      "         7.9667e-02,  8.2398e-02,  8.6509e-02,  2.3503e-01,  8.6697e-02,\n",
      "         8.1804e-02,  1.0891e-01,  1.1809e-01,  8.5274e-02,  2.2181e-01,\n",
      "         8.8134e-02,  1.0823e-01,  8.8700e-02,  8.7188e-01,  1.9721e-01,\n",
      "         6.1401e-02,  7.6369e-02,  9.0964e-02,  9.1771e-02,  7.7619e-02,\n",
      "         9.2234e-02,  9.2029e-02,  6.8979e-02,  9.2780e-02,  1.6253e-01,\n",
      "         7.8516e-02,  1.0273e-01,  1.2297e-01,  1.1258e-01,  1.0843e-01,\n",
      "         8.4692e-02,  8.5306e-02,  9.2566e-02,  2.7675e-01,  9.2329e-02,\n",
      "         9.1151e-02,  8.2513e-02,  8.5539e-01,  6.2236e-02,  1.4383e-01,\n",
      "         1.9074e-01,  6.4225e-02,  9.4916e-02,  2.5258e-01,  8.9267e-02,\n",
      "         2.1352e-01,  1.0118e-01,  6.8597e-02,  9.3538e-02,  9.1777e-02,\n",
      "         8.3621e-02,  2.4179e-01,  1.1226e-01,  9.2229e-02,  6.8679e-01,\n",
      "         9.4370e-02,  3.5768e-01,  1.2844e-01,  4.8137e-01,  9.6206e-02,\n",
      "         9.7642e-02,  1.6476e-01,  9.8226e-02,  9.7398e-02,  4.2473e-01,\n",
      "         9.6867e-02,  1.0445e-01,  1.1266e-01,  8.5205e-02,  8.6516e-02,\n",
      "         8.9442e-02,  1.0471e-01,  1.1256e-01,  1.9991e-01,  8.7913e-02,\n",
      "         7.4568e-02,  3.5742e-01,  9.7641e-02, -5.0822e-02,  2.1421e-01,\n",
      "         8.9681e-02,  8.7371e-02,  8.4826e-02,  8.7874e-02,  8.7694e-02,\n",
      "         4.2524e-02,  7.3606e-02,  8.5608e-02,  2.1418e-01,  1.0950e-01,\n",
      "         1.0416e-01,  1.2011e-01,  9.9244e-02,  9.8706e-02,  1.0709e-01,\n",
      "         5.0867e-01,  8.7416e-02,  6.4611e-02,  9.4646e-02,  9.4182e-02,\n",
      "         1.0058e-01,  1.0432e-01,  9.3194e-02,  1.0643e-01,  8.1128e-02,\n",
      "         1.0824e-01,  8.6958e-02,  1.0533e-01,  8.9538e-02,  8.9169e-02,\n",
      "         5.9656e-02,  8.1913e-02,  1.0513e-01,  1.0414e-01,  9.4614e-02,\n",
      "         9.3259e-02,  7.9728e-02,  2.0729e-01,  7.5238e-02,  8.7515e-02,\n",
      "        -5.5544e-02,  2.9754e-01,  7.4719e-02,  6.8380e-02,  8.3695e-02,\n",
      "         4.1115e-01,  8.0579e-02,  8.9047e-02,  1.0146e+00,  1.7357e-01,\n",
      "         6.8125e-02,  4.8812e-02,  8.8835e-02,  2.4087e-01,  8.0624e-02,\n",
      "         1.0074e-01,  2.9991e-01,  8.6536e-02,  7.2961e-02,  9.2139e-02,\n",
      "         1.0062e+00,  1.3467e-01,  7.8875e-02,  7.3445e-02,  6.6967e-02,\n",
      "         9.6264e-02,  1.1846e-01,  7.8505e-02,  8.5035e-02,  8.9382e-02,\n",
      "         8.6633e-02,  7.7743e-02,  4.2267e-01,  9.1658e-02,  9.7206e-02,\n",
      "         1.5442e-01,  8.8029e-02,  9.3122e-02,  9.9012e-02,  1.0057e-01,\n",
      "         1.1616e-01,  8.4928e-02,  9.8565e-02,  9.3380e-02,  7.5387e-02,\n",
      "         9.5747e-02,  1.0919e-01,  9.0552e-02,  5.0781e-01,  1.1106e-01,\n",
      "         8.2697e-02,  8.1892e-02,  1.8484e-01,  1.2140e-01,  1.0468e-01,\n",
      "         1.2043e-01,  1.3563e-01,  9.3069e-02,  8.1660e-02,  7.7617e-02,\n",
      "         8.7824e-02,  5.8851e-01,  9.7713e-02,  1.3267e-01,  7.7897e-02,\n",
      "         7.7473e-01,  1.9469e-01,  9.7020e-01,  8.6452e-02,  9.1530e-02,\n",
      "         1.8744e-01,  6.1892e-02,  1.0718e-01,  8.3071e-02,  8.3203e-02,\n",
      "         1.6884e-01,  1.1945e-01,  5.7992e-02,  7.5296e-02,  2.3857e-01,\n",
      "         8.5800e-02,  8.6843e-01,  8.6199e-02,  9.3006e-02,  8.6650e-02,\n",
      "         1.9666e-01,  9.1351e-02,  1.2310e-01,  1.5905e-01,  9.2949e-02,\n",
      "         9.0872e-02,  1.0107e-01,  6.9896e-02,  9.7608e-02,  8.5266e-02,\n",
      "         8.5309e-02,  9.4800e-01,  8.4490e-02,  9.5730e-02,  8.7373e-02,\n",
      "         8.3514e-02,  6.2616e-01,  6.9171e-02,  8.5973e-02,  9.9019e-02,\n",
      "         5.7789e-01,  1.0109e-01,  8.5217e-02,  9.8824e-02,  7.6580e-02,\n",
      "         9.9116e-02,  9.2941e-02,  5.4270e-02,  2.2826e-01,  8.1598e-02,\n",
      "         6.9201e-02,  9.6303e-02,  2.6226e-01,  1.4010e-01,  7.8112e-02,\n",
      "         1.1814e-01,  1.0208e-01,  7.6136e-02,  9.6798e-02,  7.1112e-02,\n",
      "         1.1103e-01,  2.0357e-01,  9.5533e-02,  8.3308e-01,  8.2314e-01,\n",
      "         9.7701e-02,  2.1079e-01,  9.0810e-02,  1.3965e-01,  1.6412e-01,\n",
      "         5.1325e-02,  9.3848e-02,  8.9276e-02,  9.4081e-02,  2.2144e-01,\n",
      "         1.3206e-01,  9.2572e-02,  8.6471e-02,  9.0071e-02,  9.1110e-02,\n",
      "         3.1936e-01,  8.3223e-02,  6.4922e-02,  3.0287e-01,  6.7592e-02,\n",
      "         8.7582e-02,  8.6073e-01,  6.4001e-02,  9.9171e-02,  8.8584e-02,\n",
      "         1.1365e-01,  1.0839e-01,  8.2029e-02,  8.3364e-02,  5.1312e-02,\n",
      "         8.0905e-02,  8.2910e-02,  2.4771e-01,  1.0554e-01,  3.2786e-01,\n",
      "         9.7563e-02,  1.6512e-01,  8.9698e-02,  6.9714e-02,  9.1129e-02,\n",
      "         8.5978e-02,  9.9038e-02,  8.9463e-02,  9.9648e-02,  8.7670e-02,\n",
      "         8.5803e-02,  5.7735e-02,  8.4320e-01,  9.5962e-02,  8.9412e-02,\n",
      "         3.8666e-01,  6.6124e-02,  8.6322e-02,  9.7601e-02,  9.9443e-02,\n",
      "         2.8101e-01,  9.3037e-02,  8.8569e-02,  9.2647e-02,  7.1456e-02,\n",
      "         8.7168e-02,  9.3636e-02,  9.7215e-02,  9.0414e-02,  7.8073e-02,\n",
      "         9.4772e-02,  2.2294e-01,  9.8196e-02,  1.0028e-01,  1.8481e-01,\n",
      "         6.4115e-02,  8.1527e-02,  7.9530e-02,  9.0249e-02,  8.4535e-02,\n",
      "         7.8381e-02,  9.2602e-02,  1.1950e-01,  8.1949e-02,  8.2606e-02,\n",
      "         2.5593e-01,  9.4813e-02,  9.5022e-02,  8.6884e-02,  1.0277e-01,\n",
      "         5.4287e-02,  9.0763e-02,  6.1100e-02,  8.2439e-02,  1.1063e-01,\n",
      "         1.4640e-01,  8.5021e-02,  9.4943e-02,  9.1130e-02,  9.3007e-02,\n",
      "         1.0965e-01,  1.3431e-01,  2.4036e-01,  9.6418e-02,  1.4553e-01,\n",
      "         2.4658e-01,  8.4502e-02,  2.7710e-01,  9.2313e-02,  9.6081e-02,\n",
      "         6.5867e-02,  9.1818e-02,  9.7201e-02,  1.9771e-01,  9.8137e-02,\n",
      "         8.5667e-02,  9.9096e-02,  9.7942e-02,  9.4469e-02,  9.6502e-02,\n",
      "         8.0073e-02,  7.3861e-02,  7.8396e-02,  9.2040e-02,  6.8091e-02,\n",
      "         7.6413e-02,  8.0758e-02,  2.3497e-01,  9.8554e-02,  1.0446e-01,\n",
      "         2.5915e-01,  9.1362e-02,  2.6479e-01,  9.4575e-02,  7.2788e-02,\n",
      "         8.4549e-02,  9.3460e-02,  9.3364e-02,  2.3547e-01,  8.7238e-02,\n",
      "         6.7652e-01,  8.4642e-02,  5.8136e-02,  9.0801e-02,  9.4244e-02,\n",
      "         8.6815e-02,  7.3977e-02,  8.9238e-02,  7.9015e-02,  7.9925e-02,\n",
      "         9.2779e-02,  1.2554e-01,  1.0091e-01,  1.0646e-01,  9.5911e-02,\n",
      "         6.5995e-01,  9.5036e-02,  1.0467e-01,  4.4042e-01,  7.7561e-02,\n",
      "         6.4739e-02,  8.2113e-02,  9.6569e-02,  9.7945e-02,  8.3126e-02,\n",
      "         1.0821e-01,  9.5327e-02,  2.9370e-01,  9.1483e-02,  8.7059e-02,\n",
      "         8.9372e-02,  1.1907e-01,  1.0789e-01,  1.4680e-01,  6.0212e-02,\n",
      "         7.7562e-02,  8.8580e-02,  1.2653e-01,  9.7470e-02,  2.7987e-01,\n",
      "         9.8448e-02,  8.4385e-02,  1.1783e-01, -2.2481e-05,  9.7528e-02,\n",
      "         8.7714e-02,  8.8779e-02,  3.1226e-01,  1.5509e-01,  8.0655e-02,\n",
      "         8.6425e-02,  8.3499e-02,  8.1281e-02,  8.3919e-02,  2.6491e-01,\n",
      "         9.3550e-02,  7.4678e-02,  9.0627e-02,  6.1447e-02,  7.7549e-02,\n",
      "         6.1896e-02,  8.9766e-02,  8.2362e-02,  1.6608e-01,  6.4846e-02,\n",
      "         9.4479e-02,  7.5983e-02,  1.4906e-01,  1.3748e-01,  1.3773e-01,\n",
      "         9.0254e-02,  7.4796e-02,  7.2513e-02,  9.4791e-02,  8.9204e-02,\n",
      "        -2.1712e-01,  1.9370e-01,  1.6066e-01,  1.0479e-01,  2.1192e-01,\n",
      "         7.6801e-02,  8.0052e-02,  7.2841e-02,  8.9206e-02,  5.3194e-02,\n",
      "         9.0633e-02,  9.0890e-02,  9.7391e-02,  1.2354e-01,  8.2028e-02,\n",
      "         7.5477e-02,  8.0730e-02,  8.3545e-02,  8.5752e-02,  9.1657e-02,\n",
      "         1.0311e-01,  7.3436e-02,  8.8903e-02,  9.8253e-02,  1.0466e-01,\n",
      "         9.5485e-02,  8.1838e-02,  2.5518e-01,  7.2860e-02,  5.7163e-02,\n",
      "         9.4202e-02,  1.5803e-01])), ('postnet.convolutions.0.1.bias', tensor([ 5.6830e-05,  4.0063e-04, -4.1822e-04, -8.8908e-04,  8.1068e-04,\n",
      "         3.6007e-05, -3.7462e-03, -9.8556e-04, -4.0932e-03, -2.3636e-05,\n",
      "         4.3943e-04,  1.4096e-03, -1.0725e-03, -1.1999e-03, -6.0746e-04,\n",
      "        -3.2380e-04, -3.3650e-01,  1.3060e-04,  3.0355e-03,  2.9180e-04,\n",
      "        -3.8360e-04, -1.9784e-05,  5.2011e-04, -5.6482e-03, -2.3833e-05,\n",
      "         5.4693e-04, -5.3526e-04, -2.5042e-03,  1.5350e-05, -1.3199e-03,\n",
      "        -7.5801e-04,  2.7780e-05,  4.5663e-05,  3.0952e-01, -1.5163e-03,\n",
      "         2.9323e-04, -7.7287e-04, -5.5229e-04, -5.0407e-04, -3.6799e-04,\n",
      "         1.1579e-04,  3.0783e-04,  3.2248e-04, -8.0497e-04, -2.5897e-03,\n",
      "         2.5500e-04,  6.0349e-04, -6.5329e-04, -3.9175e-04,  1.9016e-04,\n",
      "         3.6638e-05, -1.7282e-04, -4.3247e-04,  7.9522e-03, -2.9183e-04,\n",
      "         6.5380e-05,  3.0972e-04, -2.1299e-01,  2.7371e-04,  1.0223e-02,\n",
      "         1.5932e-02,  2.0023e-04, -5.4522e-04, -1.1301e-03, -3.4484e-04,\n",
      "         2.8077e-03,  2.3032e-03, -5.6027e-04, -3.3803e-04, -1.3466e-04,\n",
      "         4.5382e-04,  1.0964e-03,  2.4523e-04, -1.6896e-04, -4.9485e-02,\n",
      "        -4.2285e-04,  1.2717e-02, -1.2433e-03, -4.3843e-02,  3.5243e-04,\n",
      "         3.9025e-04, -1.1716e-03,  7.8339e-04, -9.2513e-04, -2.7014e-02,\n",
      "         2.3846e-04,  4.7381e-04,  8.6716e-07, -5.1360e-04,  1.5951e-04,\n",
      "        -5.7503e-05,  3.9090e-04,  3.9929e-03,  2.2456e-03, -7.9474e-05,\n",
      "         8.8115e-05,  2.0180e-02,  3.5322e-04, -1.1710e-05, -3.0069e-03,\n",
      "         8.9782e-04,  7.2554e-05, -4.2232e-04, -5.6318e-04, -2.5277e-05,\n",
      "        -1.4326e-03, -3.2330e-04, -1.5577e-03,  5.4360e-04, -4.7065e-04,\n",
      "        -4.0723e-04, -3.6940e-03, -7.1214e-03, -9.7910e-04,  8.5046e-04,\n",
      "         1.3871e-01,  8.3762e-04,  3.8691e-04,  2.2718e-06,  3.0372e-03,\n",
      "        -1.3397e-04,  1.5690e-03,  6.3650e-04,  6.8510e-04,  3.0167e-04,\n",
      "        -1.5910e-03, -2.1729e-04,  6.3688e-05,  5.2634e-04,  3.8519e-04,\n",
      "        -2.3449e-04,  5.6889e-04, -1.8829e-04, -7.6873e-04, -3.9764e-04,\n",
      "        -5.9968e-04,  5.7016e-04,  4.5765e-03, -4.7589e-04,  1.1454e-03,\n",
      "        -2.0526e-04,  5.0249e-03, -7.8647e-04, -5.7487e-04, -1.1480e-04,\n",
      "         1.5917e-02,  1.0173e-04, -4.2870e-06, -1.2277e-01, -8.9490e-04,\n",
      "         2.2073e-04, -7.5777e-05,  3.6403e-04,  8.2971e-03,  9.7567e-04,\n",
      "        -7.7144e-05, -2.5050e-02,  1.2111e-03, -1.1557e-03,  4.2663e-04,\n",
      "         2.3943e-01,  2.2374e-03, -4.5465e-04, -9.7130e-06, -7.5819e-04,\n",
      "         1.9552e-04,  8.3713e-03, -3.8847e-04, -2.9799e-04,  6.6967e-05,\n",
      "        -5.9139e-04, -2.9280e-06, -4.9494e-02, -4.7042e-04,  1.7084e-03,\n",
      "        -7.3311e-03,  3.3088e-04,  7.9742e-06,  3.5790e-05, -6.4667e-04,\n",
      "         2.2516e-03, -1.0845e-04, -1.1285e-04, -5.2712e-04, -3.3690e-04,\n",
      "        -6.8273e-05,  3.6473e-04, -8.3546e-04,  1.2429e-01, -1.7929e-03,\n",
      "        -6.3876e-05,  5.9582e-04, -6.4706e-03,  8.6313e-03,  2.9794e-04,\n",
      "        -4.4167e-03, -2.8861e-04, -8.7963e-05,  7.2102e-05,  2.9674e-05,\n",
      "         7.9961e-04,  1.7601e-01,  5.4936e-04,  1.2724e-03, -2.9927e-04,\n",
      "        -9.2117e-02, -2.2764e-03,  1.2793e-01, -1.1140e-03, -1.8252e-04,\n",
      "         1.4505e-02, -9.0456e-06, -2.3025e-03, -5.9428e-05,  8.2742e-05,\n",
      "        -3.1993e-03,  1.8942e-04,  3.4210e-05, -3.0695e-04, -2.5448e-02,\n",
      "        -5.9756e-04,  1.7052e-01,  1.0076e-03, -3.7892e-05, -3.8020e-05,\n",
      "         2.8925e-03,  5.4406e-04, -4.0726e-04,  4.4690e-03, -1.1224e-03,\n",
      "         1.7280e-04,  5.5267e-04,  2.0409e-04, -1.2541e-04,  1.2519e-04,\n",
      "        -7.0598e-04, -3.2993e-01, -1.4522e-04, -1.2342e-03, -4.3395e-04,\n",
      "        -1.2470e-07, -1.0404e-01, -5.4672e-06,  4.9028e-04,  6.0942e-04,\n",
      "        -9.7653e-02,  4.0331e-04, -1.9108e-05, -1.0896e-05,  2.3587e-04,\n",
      "         1.2237e-03,  2.2895e-04, -6.3228e-04, -8.1646e-04, -5.0661e-04,\n",
      "         1.1593e-04, -1.4546e-04, -1.2250e-03,  2.4118e-03, -1.7122e-04,\n",
      "         3.7428e-03,  7.1775e-04,  5.9369e-04,  8.2628e-04, -3.1008e-04,\n",
      "         7.5221e-03, -2.4187e-03, -3.5560e-04, -3.2629e-01,  1.3500e-01,\n",
      "         5.9360e-05, -4.0643e-03, -8.8737e-05,  1.8662e-03, -2.6618e-03,\n",
      "        -7.0247e-04, -4.8908e-04,  6.7230e-04,  7.1240e-04,  2.9789e-03,\n",
      "         2.1699e-03, -8.5079e-04, -2.5081e-04,  2.9372e-04,  5.9639e-04,\n",
      "        -3.0199e-02, -6.9077e-06, -4.0033e-04, -2.9574e-03, -7.8072e-05,\n",
      "        -2.9038e-05,  9.9050e-02, -4.1176e-04, -2.1587e-04, -7.5574e-05,\n",
      "         1.8755e-03, -1.6297e-02, -8.3808e-04, -3.3392e-04, -9.0216e-03,\n",
      "        -8.4550e-04, -2.9120e-04, -1.1671e-02,  2.9639e-03,  2.9846e-03,\n",
      "         5.0209e-04, -4.1152e-04, -2.3882e-04, -3.3856e-04, -2.5457e-04,\n",
      "        -4.7311e-04, -3.4549e-04, -5.3882e-04, -3.4841e-04, -5.1562e-04,\n",
      "        -5.5424e-03, -2.7693e-04, -1.9983e-01, -7.8196e-04, -3.4719e-05,\n",
      "        -2.4842e-02,  1.6410e-04, -1.7948e-04,  7.8946e-05,  2.5667e-04,\n",
      "         2.2166e-03,  2.7685e-04,  4.0261e-04,  6.0264e-05, -1.5313e-04,\n",
      "         2.5634e-03, -1.0785e-04, -3.3425e-04, -2.0644e-04,  6.1695e-04,\n",
      "        -2.7661e-04,  2.9188e-03,  8.6713e-06,  6.4376e-04, -3.8597e-03,\n",
      "         2.6654e-04,  2.6299e-04, -1.8707e-04,  3.0895e-04, -6.8754e-04,\n",
      "        -1.5126e-05, -1.7305e-03, -7.9429e-04, -8.2659e-04, -1.5589e-04,\n",
      "         7.1846e-03, -2.7588e-04, -2.9551e-04, -7.1665e-04, -7.5752e-03,\n",
      "         4.4916e-04, -1.0375e-03,  2.1320e-04, -4.1151e-04, -2.5286e-03,\n",
      "        -9.5468e-03,  4.6140e-04,  5.9833e-04, -6.5138e-04, -7.3068e-04,\n",
      "        -4.2861e-05,  4.8246e-03, -6.9387e-03, -6.0038e-04,  1.8052e-03,\n",
      "        -3.4576e-03, -3.0465e-04,  3.7206e-03, -9.3291e-03,  8.2624e-04,\n",
      "        -4.2603e-05, -1.5629e-04,  4.1045e-04,  3.1342e-03,  4.3188e-04,\n",
      "        -2.8050e-04,  3.0133e-04,  5.2651e-03,  6.7759e-04,  3.5280e-04,\n",
      "         2.2888e-04, -1.4028e-04, -6.7118e-04,  1.0018e-04,  2.3878e-04,\n",
      "        -3.7744e-04,  1.0653e-04, -6.3717e-03, -1.2489e-05,  2.4809e-03,\n",
      "        -5.7999e-03,  1.0806e-04,  1.9638e-03,  6.4207e-04, -2.2568e-04,\n",
      "        -3.8519e-05,  4.0265e-04,  1.1611e-03, -2.1536e-03, -3.8886e-04,\n",
      "        -1.8707e-01,  4.0734e-04,  1.1857e-04,  1.0450e-03,  5.5239e-03,\n",
      "         1.9661e-04, -1.4959e-04,  1.6959e-04,  6.5991e-04,  8.1100e-04,\n",
      "         4.8535e-04, -6.4323e-04, -1.1377e-03, -8.0790e-04,  3.6664e-05,\n",
      "         1.5067e-01, -2.7968e-04,  2.2422e-03,  9.8374e-02, -1.5746e-04,\n",
      "         1.2140e-04, -2.2457e-04, -4.2766e-05,  1.7746e-04,  8.6722e-04,\n",
      "         5.1941e-04,  2.7785e-05,  5.3665e-03, -8.7993e-04, -2.2839e-04,\n",
      "         5.0384e-04, -1.1188e-02, -1.8693e-03,  2.2690e-03, -1.2687e-04,\n",
      "         2.4185e-04,  1.0226e-04, -3.1414e-03, -9.2551e-04,  7.3742e-04,\n",
      "        -1.8534e-04, -8.8776e-05,  1.3328e-03,  9.2546e-04,  2.2510e-04,\n",
      "         1.4625e-04,  1.6700e-04,  1.7159e-02,  1.1206e-03, -1.7317e-04,\n",
      "         2.3522e-04,  3.8721e-05, -4.9282e-04,  1.6012e-04, -8.5101e-05,\n",
      "         5.3368e-04,  2.1856e-04, -2.6773e-04,  4.1622e-04,  4.9428e-05,\n",
      "        -7.5098e-04,  1.3672e-04,  6.3753e-05,  1.1071e-04,  4.6351e-04,\n",
      "        -3.6601e-04, -2.2193e-04, -9.2398e-03,  1.5651e-03, -1.0396e-02,\n",
      "        -3.0484e-05,  1.2186e-03,  9.9163e-03,  1.1239e-04, -3.5738e-04,\n",
      "         4.3288e-03,  5.1891e-03, -1.9743e-03,  6.6826e-04,  9.3183e-03,\n",
      "        -7.4461e-04, -2.9652e-03,  1.3121e-04, -2.8929e-04, -1.9127e-04,\n",
      "        -3.5774e-04, -1.6906e-04,  2.7435e-04, -1.4791e-03, -5.4510e-04,\n",
      "        -1.3590e-04,  3.7777e-04, -8.9640e-04, -3.0988e-04, -8.9489e-04,\n",
      "         1.3773e-03,  1.5955e-04,  9.0859e-05,  2.0670e-04,  2.8812e-04,\n",
      "         6.1845e-04,  1.6274e-04,  3.6924e-03,  2.9705e-03, -5.9161e-03,\n",
      "         2.5747e-04,  2.0725e-03])), ('postnet.convolutions.0.1.running_mean', tensor([ 1.0383e-02,  1.7139e-02, -5.5706e-03, -5.7740e-02,  1.7653e-02,\n",
      "        -5.7833e-03, -1.1791e-02, -1.3518e-02, -3.8253e-02, -7.8344e-03,\n",
      "         1.7343e-02, -1.2324e-02, -1.5654e-02,  3.6112e-02, -3.7961e-03,\n",
      "        -5.5536e-03, -2.8258e-01,  5.5862e-03,  3.9758e-02,  2.9974e-03,\n",
      "         9.4649e-03,  4.4533e-02,  7.9896e-03, -1.5523e-02, -1.9097e-02,\n",
      "         1.1596e-02,  2.3480e-03, -1.3598e-02,  1.8159e-01, -9.7614e-03,\n",
      "         3.4725e-03,  4.9776e-03, -1.4431e-04,  4.3405e-01, -5.4107e-03,\n",
      "        -5.2019e-03, -5.4915e-03, -6.0438e-03, -2.1272e-02,  2.4906e-03,\n",
      "        -1.3564e-02,  2.6341e-03, -1.6054e-02, -3.2715e-03, -1.0188e-02,\n",
      "         5.2226e-03,  6.1100e-03, -9.7610e-03, -2.3921e-03, -8.5973e-03,\n",
      "        -2.5675e-02, -1.5204e-03,  5.6404e-03,  7.0177e-03, -3.9564e-03,\n",
      "        -5.2905e-03, -4.8010e-04, -2.3223e-01, -1.3095e-02,  1.4704e+00,\n",
      "         1.3868e-01,  3.8607e-02, -1.5425e-02,  9.8807e-04,  3.4134e-02,\n",
      "         1.9056e-02,  7.1109e-02,  3.2976e-02, -1.4518e-02,  4.7482e-03,\n",
      "        -6.8593e-03, -2.0702e-02, -1.8772e-03,  6.0843e-03, -9.6895e-02,\n",
      "        -2.3845e-02,  3.3403e-02, -2.0252e-02, -8.0566e-02, -3.9248e-03,\n",
      "         1.6998e-02,  3.0622e-03,  7.2114e-04, -4.1361e-02, -4.9018e-02,\n",
      "        -7.6347e-03, -9.7520e-05,  3.7422e-03, -1.5354e-02, -5.0598e-03,\n",
      "         2.9790e-03,  2.9636e-03,  4.6507e-02,  1.6207e-02,  1.1210e-02,\n",
      "         4.4877e-03,  4.3614e-02,  1.2097e-03, -6.9434e-03, -2.1659e-02,\n",
      "         1.6038e-03, -1.0543e-02, -8.9383e-03, -2.8953e-03, -4.4727e-03,\n",
      "        -3.9327e-01, -1.2698e-02, -3.3598e-01, -8.1018e-03,  1.1304e-02,\n",
      "         8.3856e-03, -5.8016e-02, -2.0277e-01,  8.4326e-03,  7.7239e-03,\n",
      "         4.8043e-01, -1.4506e-03,  2.0819e-02,  8.4659e-03,  1.7496e-01,\n",
      "         7.9631e-03,  6.2305e-03, -9.2503e-03,  1.2810e-02,  1.0690e-02,\n",
      "         1.0785e-03, -4.1381e-03, -1.0541e-02, -3.3490e-03,  3.4019e-03,\n",
      "         3.6185e-03,  9.0521e-03, -5.8715e-03,  5.1724e-03,  1.0520e-02,\n",
      "         1.4850e-03,  3.5305e-03,  1.0649e-02, -2.2285e-02,  1.4358e-02,\n",
      "         1.1767e-02,  4.3687e-03, -1.0285e-02, -3.1945e-03, -6.8945e-03,\n",
      "         4.0102e-02, -5.4811e-03, -3.2690e-03, -1.3896e-01,  1.2038e-02,\n",
      "         4.9835e-03,  1.6323e-03, -2.9511e-02,  1.9599e-02, -1.5158e-03,\n",
      "         1.7296e-02, -5.2875e-02,  3.3595e-03, -1.5839e-02,  1.1947e-02,\n",
      "         2.6937e-01,  4.4554e-02,  9.8211e-03,  1.2064e-02,  4.0345e-02,\n",
      "         3.7570e-03,  8.2554e-02,  3.3551e-03, -1.1159e-02, -1.5510e-02,\n",
      "         9.1733e-03,  1.9540e-03, -1.1909e-01, -1.5269e-02,  5.8469e-04,\n",
      "        -5.0591e-03, -1.2719e-03, -4.3084e-03,  1.2591e-04, -9.5229e-03,\n",
      "        -2.8336e-03,  1.0979e-02, -1.3065e-02,  1.3237e-02,  1.2978e-02,\n",
      "        -5.6959e-03,  1.0462e-02,  1.4555e-02,  3.0791e-01,  2.7938e-02,\n",
      "        -2.1441e-03,  1.4625e-02, -1.2452e-02,  6.8922e-02, -7.5115e-03,\n",
      "        -2.6655e-02,  7.5996e-03, -2.1728e-03, -2.9828e-03, -9.0612e-03,\n",
      "        -2.4252e-03,  4.8853e-01,  8.1152e-03,  1.1490e-02,  8.2796e-03,\n",
      "        -9.0700e-02, -4.1125e-03,  1.6932e-01, -7.3166e-04,  1.2206e-02,\n",
      "         7.3681e-02,  2.5943e-02,  2.8818e-02, -5.4266e-03, -9.5249e-03,\n",
      "        -1.3852e-02, -9.0343e-03,  1.0434e-02,  1.6262e-03, -5.0341e-02,\n",
      "         1.9432e-02,  1.7569e-01,  4.1880e-03,  7.8199e-03,  6.4684e-03,\n",
      "         2.5014e-03, -3.3451e-03, -1.2344e-02,  2.2307e-02, -3.1206e-04,\n",
      "         2.6371e-04,  9.1169e-03, -2.2505e-05, -1.1872e-04,  5.7563e-03,\n",
      "        -3.9981e-02, -5.4912e-01,  1.1442e-02,  5.8457e-03,  2.6120e-03,\n",
      "         1.5369e-02, -1.6655e-01,  7.4260e-03, -1.0982e-02, -4.1832e-03,\n",
      "        -1.3316e-01,  7.5657e-03,  3.3701e-03,  6.8132e-03,  7.8498e-03,\n",
      "         2.4111e-03, -2.0423e-02, -7.6297e-02, -1.3044e-02,  3.1085e-03,\n",
      "        -6.0006e-03,  5.4591e-03, -9.1702e-03,  3.8263e-03, -3.1121e-03,\n",
      "         7.1965e-03,  5.9001e-03,  4.7055e-03,  2.8723e-03,  1.4764e-03,\n",
      "         1.2199e-01,  8.3750e-03,  4.8974e-03, -3.7263e-01,  1.7723e-01,\n",
      "         1.6585e-02, -1.5400e-02, -2.7981e-03,  1.3757e-02,  4.2633e-03,\n",
      "        -1.4876e-01, -1.3236e-02,  2.0651e-02,  2.1552e-03,  2.5942e-03,\n",
      "         1.4143e-02, -4.3847e-03,  1.5370e-02,  3.4666e-03,  1.1005e-02,\n",
      "        -1.1756e-01,  3.1818e-02,  1.5700e-02, -8.4148e-03, -1.1664e-02,\n",
      "        -5.3454e-03,  1.2399e-01, -2.1599e-03, -1.0317e-02, -8.1870e-04,\n",
      "         3.3338e-01, -8.3945e-01, -2.8259e-02,  5.6171e-04, -3.8119e-01,\n",
      "         6.0577e-03,  5.5402e-03, -4.8787e-02,  2.9245e-02,  6.4039e-03,\n",
      "         9.2835e-03,  1.4673e-02,  2.4188e-03, -1.0735e-02, -2.4301e-02,\n",
      "        -6.1693e-03,  4.7026e-03, -1.0955e-02,  4.8842e-03,  4.1661e-03,\n",
      "        -1.8963e-01, -1.1496e-02, -2.0846e-01, -7.2210e-03, -9.8992e-03,\n",
      "        -6.1639e-02,  3.3698e-02, -7.8935e-03, -2.7964e-03, -5.7624e-03,\n",
      "         7.5695e-03, -2.5561e-05, -4.4593e-03,  1.2040e-02,  4.9678e-03,\n",
      "         4.2746e-03, -9.0873e-03, -7.5585e-03, -8.6731e-03,  1.1457e-02,\n",
      "         8.9705e-04,  1.2497e-02,  2.4349e-03,  1.0899e-03, -1.8194e-02,\n",
      "        -1.7555e-02, -3.9901e-03, -4.1648e-03, -3.0642e-02,  4.1601e-03,\n",
      "        -3.5023e-03, -2.2996e-02, -1.1684e-02,  8.5313e-03, -1.2170e-02,\n",
      "         1.6559e-02, -1.2558e-02, -1.6233e-02, -2.4911e-03, -2.1255e-01,\n",
      "        -9.4570e-03, -3.2496e-03,  5.5218e-03,  1.4812e-04, -6.0239e-02,\n",
      "        -1.8701e-01,  9.1125e-03, -7.1197e-03,  7.6679e-03, -8.6534e-03,\n",
      "        -1.0666e-03,  5.6196e-02, -8.9096e-03,  1.1493e-03, -2.2215e-02,\n",
      "         8.6221e-03,  5.7679e-03,  1.5623e-02, -4.3787e-01,  4.1044e-03,\n",
      "         3.0515e-03,  5.1845e-03, -5.0091e-03,  1.5847e-02, -6.8514e-04,\n",
      "        -3.3971e-03,  8.3255e-04,  9.2251e-02,  9.4347e-03,  8.6571e-03,\n",
      "         3.6220e-03, -1.0677e-02,  1.4156e-02,  2.8168e-03, -4.8104e-02,\n",
      "         2.7197e-03,  1.4111e-03, -9.3152e-03, -8.5303e-03,  2.1619e-02,\n",
      "        -2.2380e-02, -5.3448e-04, -4.1514e-03, -6.8188e-03, -5.7615e-03,\n",
      "        -8.2849e-03,  6.4687e-03,  9.8198e-03,  1.3563e-02,  3.3258e-02,\n",
      "        -4.9162e-01, -5.0880e-04, -6.1041e-03, -1.0078e-02,  3.3197e-01,\n",
      "        -1.8112e-02,  1.4854e-02, -3.6156e-03, -2.8648e-03,  3.6795e-03,\n",
      "         4.9393e-03,  3.6345e-03, -2.4452e-02,  6.3509e-03,  2.4539e-02,\n",
      "         1.2868e-01, -1.8018e-02, -6.4409e-03,  2.2319e-01,  1.4346e-03,\n",
      "         1.2620e-02, -1.6664e-03,  8.7946e-03, -4.6402e-02, -8.0054e-03,\n",
      "         3.9451e-03,  1.2499e-02, -2.1599e-02, -1.2845e-02, -1.2022e-02,\n",
      "         1.4195e-02, -1.3914e-01, -2.3205e-02,  2.0155e-02, -9.4457e-03,\n",
      "         2.2038e-02, -1.1691e-02, -5.0081e-02,  2.5670e-03,  2.7658e-02,\n",
      "         1.2281e-02, -3.7291e-04,  1.2019e-02,  2.0170e-01, -9.4157e-03,\n",
      "        -6.7006e-03, -2.9334e-03,  7.5511e-02,  2.1340e-03, -1.8737e-02,\n",
      "        -4.1841e-03, -9.8388e-03, -1.1863e-02,  2.6090e-03,  1.6955e-02,\n",
      "        -1.8866e-02,  1.4112e-02, -6.8186e-03, -3.7577e-04,  9.5704e-03,\n",
      "        -5.0553e-03,  1.2453e-02, -1.0260e-02,  2.0909e-02, -4.8003e-03,\n",
      "        -1.2330e-02,  7.3787e-03, -5.0008e-02,  1.6891e-02, -6.6304e-02,\n",
      "         1.4769e-03,  2.8987e-02,  9.3544e-01, -2.8432e-03, -2.3545e-02,\n",
      "        -2.4233e-03,  7.0086e-03, -4.1541e-03,  5.7087e-03,  3.4397e-02,\n",
      "        -1.0636e-02, -1.0463e-01, -5.8011e-03, -9.3672e-03,  6.3229e-03,\n",
      "         4.3872e-03, -1.2330e-03, -1.0396e-02, -2.0891e-02,  1.0105e-02,\n",
      "        -3.2547e-03,  3.0569e-05, -1.1198e-02,  8.6257e-03, -4.0526e-03,\n",
      "        -3.2794e-03, -2.5443e-02, -1.5140e-02,  1.1577e-03,  1.1483e-02,\n",
      "        -6.3153e-03,  5.1778e-03, -1.1830e-03, -2.3217e-02, -4.5168e-01,\n",
      "         1.4849e-02,  9.4037e-04])), ('postnet.convolutions.0.1.running_var', tensor([0.0573, 0.0341, 0.0435, 0.0229, 0.0863, 0.0465, 0.4820, 0.0633, 1.1844,\n",
      "        0.0421, 0.0451, 0.0504, 0.2041, 0.0141, 0.0377, 0.0381, 1.2576, 0.9074,\n",
      "        0.1558, 0.0393, 0.0694, 2.1597, 0.0765, 0.4566, 0.0747, 0.0431, 0.1915,\n",
      "        0.2274, 2.1110, 0.1720, 0.0513, 0.0572, 0.0779, 1.3812, 0.5332, 0.0195,\n",
      "        0.0349, 0.0368, 0.0750, 0.0153, 0.0492, 0.0797, 0.0248, 0.0457, 0.1224,\n",
      "        0.0356, 0.0990, 0.0304, 0.2164, 0.0483, 0.0468, 0.0515, 0.0881, 0.3069,\n",
      "        0.0278, 0.0458, 0.0727, 0.7738, 0.0434, 1.6830, 0.9749, 0.0369, 0.0511,\n",
      "        0.1049, 0.0788, 0.0996, 1.0257, 0.0552, 0.0685, 0.0824, 0.0369, 0.2001,\n",
      "        0.0474, 0.0964, 1.7058, 0.0713, 0.2629, 0.0624, 0.3883, 0.0328, 0.1180,\n",
      "        0.2668, 0.0824, 0.0796, 0.9871, 0.0884, 0.0364, 0.4082, 0.0378, 0.0739,\n",
      "        0.0484, 0.0373, 0.9331, 0.0742, 0.1236, 0.0356, 0.8185, 0.0489, 0.0082,\n",
      "        0.1258, 0.0218, 0.0386, 0.0356, 0.0485, 0.0564, 0.1217, 0.0378, 4.5035,\n",
      "        0.1027, 0.1949, 0.0563, 0.5933, 1.1724, 0.0738, 0.1169, 2.8278, 0.0978,\n",
      "        0.0351, 0.0801, 2.1320, 0.0322, 0.0323, 0.0662, 0.1202, 0.0330, 0.0960,\n",
      "        0.0744, 0.0921, 0.0948, 0.0642, 0.0233, 0.0519, 0.0748, 0.0548, 0.0380,\n",
      "        0.0567, 0.0305, 0.0722, 0.0477, 0.0747, 0.0194, 0.2342, 0.0255, 0.0404,\n",
      "        0.0482, 1.8740, 0.0893, 0.1123, 1.7859, 0.2640, 0.0376, 0.0143, 0.0418,\n",
      "        0.1824, 0.0625, 0.0745, 1.1332, 0.1799, 0.0596, 0.0712, 1.4308, 0.4182,\n",
      "        0.0392, 0.0228, 0.0431, 0.0708, 1.0092, 0.0391, 0.0414, 0.1295, 0.0975,\n",
      "        0.0353, 0.5972, 0.0844, 0.2442, 0.3887, 0.0398, 0.0265, 0.0507, 0.0779,\n",
      "        0.1323, 0.0411, 0.0618, 0.0712, 0.0480, 0.0855, 0.3500, 0.0656, 1.8929,\n",
      "        0.0870, 0.0363, 0.0637, 0.4605, 0.2426, 0.3386, 0.2897, 0.0783, 0.0437,\n",
      "        0.0382, 0.0268, 0.0605, 3.2944, 0.1287, 0.1015, 0.0392, 0.9310, 0.0932,\n",
      "        2.5286, 0.0442, 0.0480, 0.3982, 0.0242, 0.3523, 0.0643, 0.0431, 0.0823,\n",
      "        0.3504, 0.0158, 0.0280, 2.3999, 0.0706, 1.4662, 0.0386, 0.0625, 0.0515,\n",
      "        0.1041, 0.0588, 0.0796, 0.2851, 0.0660, 0.0546, 0.0696, 0.0340, 0.0511,\n",
      "        0.1334, 0.0656, 2.5424, 0.0694, 0.0895, 0.0264, 0.0365, 1.1694, 0.0317,\n",
      "        0.0641, 0.0865, 0.8285, 0.0534, 0.0818, 0.0489, 0.0395, 0.0861, 0.0396,\n",
      "        0.0330, 0.2599, 0.0544, 0.0225, 0.0605, 0.3403, 0.2682, 0.0393, 0.2170,\n",
      "        0.0484, 0.0380, 0.0345, 0.0169, 1.5685, 0.3013, 0.0368, 1.9831, 1.6744,\n",
      "        0.0482, 0.0781, 0.0523, 0.2014, 0.2416, 0.0359, 0.0653, 0.1036, 0.0381,\n",
      "        0.0982, 1.3506, 0.0585, 0.0502, 0.0494, 0.0576, 1.0945, 0.0846, 0.0587,\n",
      "        0.1577, 0.0301, 0.0359, 2.5556, 0.0157, 0.0396, 0.0518, 3.0757, 3.4085,\n",
      "        0.0413, 0.0264, 0.1759, 0.0869, 0.1333, 0.5038, 1.5178, 0.4756, 0.0372,\n",
      "        0.1361, 0.0657, 0.0334, 0.1054, 0.0418, 0.0660, 0.0699, 0.0290, 0.0450,\n",
      "        1.3637, 0.0157, 0.9203, 0.1000, 0.0664, 1.2621, 0.0158, 0.0619, 0.0446,\n",
      "        0.0392, 0.6352, 0.0528, 0.0541, 0.0679, 0.0294, 1.1349, 0.0870, 0.1476,\n",
      "        0.0447, 0.0341, 0.0568, 0.0881, 0.0502, 0.0518, 0.5817, 0.0277, 0.0438,\n",
      "        0.0610, 0.0729, 0.0459, 0.0350, 0.1669, 0.6298, 0.0459, 0.0550, 0.5714,\n",
      "        0.0466, 0.0284, 0.0670, 2.1574, 0.0187, 0.0475, 0.0244, 0.0514, 0.8125,\n",
      "        0.9015, 0.0639, 0.0583, 0.1067, 0.0858, 0.0439, 1.0836, 0.3815, 0.0556,\n",
      "        0.1070, 0.7069, 0.0525, 0.1578, 1.6628, 0.0576, 0.0221, 0.0845, 0.0711,\n",
      "        0.4293, 0.0422, 0.0308, 0.0571, 1.4600, 0.0774, 0.3146, 0.0396, 0.0354,\n",
      "        0.0414, 0.0520, 0.0428, 0.0307, 0.0430, 0.3592, 0.0512, 0.5655, 0.6805,\n",
      "        0.0848, 0.0860, 0.0505, 0.0286, 0.0738, 0.0709, 0.0344, 0.9302, 0.1253,\n",
      "        2.2573, 0.0534, 0.0160, 0.0422, 2.8715, 0.0597, 0.0294, 0.0896, 0.0564,\n",
      "        0.0477, 0.0408, 0.1368, 0.6581, 0.1316, 0.0721, 0.3670, 0.1055, 0.9075,\n",
      "        1.2484, 0.0237, 0.0288, 0.0411, 0.0608, 0.0339, 0.0384, 0.0762, 0.0923,\n",
      "        0.2867, 0.0895, 0.0378, 0.0431, 0.8743, 0.1127, 0.2984, 0.0182, 0.0350,\n",
      "        0.0725, 0.9620, 0.1407, 0.2468, 0.0559, 0.0642, 0.3658, 0.0257, 0.0616,\n",
      "        0.0842, 0.0495, 1.0124, 1.3047, 0.0624, 0.0557, 0.0889, 0.0334, 0.0780,\n",
      "        1.1011, 0.0515, 0.1559, 0.0434, 0.0229, 0.0614, 0.0172, 0.0608, 0.0706,\n",
      "        0.0554, 0.0301, 0.0561, 0.0179, 0.4987, 0.0890, 0.6989, 0.0552, 0.0692,\n",
      "        0.6871, 0.0610, 0.0849, 0.0682, 0.5043, 0.0389, 0.4681, 0.9387, 0.0278,\n",
      "        1.6335, 0.0311, 0.0546, 0.0184, 0.0667, 0.0366, 0.0753, 0.2353, 0.0174,\n",
      "        0.0291, 0.0568, 0.0372, 0.0419, 0.0696, 0.3325, 0.0258, 0.0717, 0.0532,\n",
      "        0.0431, 0.0346, 0.1153, 0.1170, 0.0474, 0.1853, 0.0710, 0.0719])), ('postnet.convolutions.0.1.num_batches_tracked', tensor(18012)), ('postnet.convolutions.1.0.conv.weight', tensor([[[ 3.1659e-03,  8.3502e-03,  2.0475e-03,  2.4139e-03, -7.9575e-03],\n",
      "         [-1.0875e-02,  9.9697e-03, -9.2177e-03,  6.0486e-04,  3.0229e-03],\n",
      "         [-4.4612e-03, -5.8161e-03,  8.5854e-03, -4.5299e-03, -2.7861e-03],\n",
      "         ...,\n",
      "         [ 2.0968e-03, -2.8800e-03,  2.0420e-03,  3.1035e-03, -2.2815e-03],\n",
      "         [-2.9877e-03, -4.3683e-04, -6.5705e-04,  5.6399e-03, -4.4476e-04],\n",
      "         [-1.5931e-03,  6.7300e-03, -3.1757e-03,  4.2750e-04, -4.6052e-03]],\n",
      "\n",
      "        [[ 6.9712e-03,  5.4321e-03,  4.2283e-03,  3.0357e-03,  5.6345e-03],\n",
      "         [ 1.4282e-02,  1.5141e-02,  1.8459e-02,  2.4701e-02,  1.4036e-02],\n",
      "         [-4.6014e-03, -4.5358e-04,  2.5331e-03, -1.6557e-03, -1.3326e-03],\n",
      "         ...,\n",
      "         [-4.4053e-03, -5.4396e-03, -4.7601e-03, -5.6572e-03, -6.3697e-03],\n",
      "         [-4.4067e-04,  2.9214e-04, -7.6884e-03, -1.8826e-03, -7.9275e-03],\n",
      "         [-8.4830e-03, -1.6619e-03,  6.2136e-04,  1.0922e-02,  7.6223e-03]],\n",
      "\n",
      "        [[-8.1973e-03, -7.1500e-03, -2.5840e-03, -1.6384e-03, -2.3795e-03],\n",
      "         [-8.2325e-03, -6.7895e-03,  1.0572e-02,  9.3047e-03,  6.1801e-03],\n",
      "         [-1.0492e-02, -1.0720e-02, -1.0795e-02, -5.3606e-03, -2.4340e-03],\n",
      "         ...,\n",
      "         [-2.8581e-03, -1.8158e-03, -2.7643e-03, -9.2054e-04, -2.7879e-03],\n",
      "         [-7.2944e-03, -6.0319e-03, -7.5917e-04, -4.7167e-03, -2.4294e-03],\n",
      "         [ 8.6340e-03,  2.3676e-03, -3.9346e-03, -3.2516e-03, -8.0211e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.1663e-03, -1.1932e-03, -1.5303e-03,  6.1461e-03, -8.8342e-03],\n",
      "         [-8.2147e-03,  2.6447e-03,  1.0457e-02,  1.1970e-02, -1.5038e-02],\n",
      "         [-6.0434e-03,  2.9449e-03, -1.7901e-03, -2.8583e-03, -3.1579e-03],\n",
      "         ...,\n",
      "         [ 1.0998e-03, -4.1110e-03,  3.9282e-03, -2.2002e-03, -3.5480e-03],\n",
      "         [ 5.5719e-04,  6.7596e-03, -2.7686e-03, -5.6372e-03, -2.0818e-03],\n",
      "         [ 1.2690e-03,  2.7133e-03, -2.5314e-03, -2.8153e-03,  2.4628e-04]],\n",
      "\n",
      "        [[-1.1507e-02, -9.6451e-03,  5.8575e-03, -3.9221e-03,  3.3711e-03],\n",
      "         [ 8.3633e-03,  6.3728e-04,  1.0125e-03,  1.4346e-03, -1.6256e-02],\n",
      "         [-8.0364e-03, -3.0432e-03,  5.1430e-03, -2.7154e-03,  4.3110e-03],\n",
      "         ...,\n",
      "         [-5.8317e-03, -6.4991e-03, -1.0341e-02, -5.0726e-03,  3.6843e-04],\n",
      "         [ 7.6095e-03, -3.9173e-03,  5.6848e-03, -6.5138e-03, -5.1554e-03],\n",
      "         [ 9.4056e-05, -1.3981e-03,  1.8967e-02, -2.2698e-03, -1.8418e-03]],\n",
      "\n",
      "        [[ 2.9669e-03,  5.6828e-03,  3.9733e-03,  4.9469e-03,  7.6445e-03],\n",
      "         [-1.4893e-02, -1.3917e-02,  3.6310e-04, -6.6015e-03, -3.0702e-03],\n",
      "         [ 4.9992e-05,  6.0251e-03, -3.7297e-03, -2.0340e-03, -7.8902e-03],\n",
      "         ...,\n",
      "         [ 2.2908e-03, -3.4678e-04, -4.4091e-05,  4.0236e-04,  2.7389e-03],\n",
      "         [-7.1906e-03, -5.1410e-03, -9.1993e-03, -1.0681e-02, -3.7401e-03],\n",
      "         [-2.8608e-03, -5.1623e-03,  4.7139e-05, -4.6818e-03, -5.1490e-03]]])), ('postnet.convolutions.1.0.conv.bias', tensor([ 4.7038e-06,  1.0222e-04,  7.3534e-05, -1.1391e-06,  2.1128e-05,\n",
      "        -6.6229e-05, -7.9273e-05,  1.1649e-04,  7.7302e-05, -6.2265e-05,\n",
      "        -7.8448e-05, -1.3387e-04,  3.8547e-05, -7.7046e-05, -2.7153e-05,\n",
      "        -1.7362e-05,  7.1354e-05, -8.0623e-05,  1.0363e-05,  2.2215e-06,\n",
      "         7.6636e-05,  3.5748e-05, -6.4909e-05,  1.1707e-04, -5.1862e-05,\n",
      "        -1.4021e-05,  5.1907e-06, -3.0256e-05,  3.2122e-05,  4.0293e-05,\n",
      "        -2.8580e-05, -1.6230e-05,  4.4217e-05, -1.2348e-05,  3.8611e-05,\n",
      "        -8.5835e-06, -3.8975e-05,  1.6964e-05, -1.4225e-05,  7.1589e-05,\n",
      "         8.8491e-05,  1.4744e-05,  1.2833e-05, -1.7447e-05, -8.0188e-06,\n",
      "        -1.0677e-04, -7.9132e-05,  3.2753e-05,  6.2736e-05, -1.2983e-05,\n",
      "        -3.2978e-06, -9.3026e-05,  7.0927e-05, -1.1790e-05,  1.4988e-04,\n",
      "         1.5771e-04,  3.8687e-05,  1.1336e-04, -4.0570e-05, -1.0781e-04,\n",
      "         9.3421e-05,  1.2541e-05, -1.2576e-04,  5.8250e-05, -2.6824e-05,\n",
      "        -1.2111e-05, -8.7751e-06, -8.6616e-05,  1.6148e-05, -1.7597e-05,\n",
      "        -3.7331e-05, -3.0061e-05, -1.5703e-05, -3.5304e-05, -1.7309e-05,\n",
      "        -4.5431e-05,  6.2080e-06, -9.7928e-05,  8.2730e-05, -1.0679e-05,\n",
      "        -5.0104e-06, -3.2010e-05,  1.6443e-04,  7.3387e-06, -3.0966e-05,\n",
      "         8.2052e-05,  4.3976e-05,  1.0858e-04,  2.4115e-05,  2.5516e-05,\n",
      "        -5.2547e-05,  8.0893e-05, -1.0704e-05, -1.3367e-05,  5.8521e-05,\n",
      "         1.2652e-04, -3.8239e-05, -3.4515e-05, -1.1620e-05,  1.0240e-04,\n",
      "        -2.1534e-05,  4.4089e-06,  2.1682e-05, -2.6192e-05,  2.5615e-05,\n",
      "        -6.1157e-05,  4.5612e-05,  7.5531e-05,  3.7567e-05, -1.0882e-04,\n",
      "         7.9409e-05,  2.4412e-05,  7.8569e-05,  8.6364e-05, -8.1070e-05,\n",
      "         1.1027e-04, -4.9509e-05,  6.1672e-05,  2.8704e-05,  3.0420e-05,\n",
      "        -5.2518e-05,  1.2592e-04, -7.6727e-05,  4.6680e-05, -3.1248e-06,\n",
      "         4.9960e-05,  1.1600e-04, -2.0900e-05,  1.4719e-05, -4.6918e-05,\n",
      "        -2.5119e-05,  3.9265e-05,  5.3986e-06, -5.2172e-05,  8.0075e-05,\n",
      "         3.8686e-06,  2.1625e-05,  7.3728e-05, -1.0190e-05, -5.6967e-05,\n",
      "         1.7769e-05, -1.2482e-04, -1.7666e-04, -5.5366e-05,  6.3031e-06,\n",
      "        -1.9895e-05,  1.8842e-05, -5.0139e-07, -5.3329e-05, -2.1568e-05,\n",
      "        -3.1111e-05,  1.4993e-04,  7.9301e-06,  9.0567e-05, -1.7294e-04,\n",
      "         3.6568e-05,  5.6165e-05, -2.8313e-05, -1.4679e-05,  1.2920e-05,\n",
      "         3.8831e-05,  4.2876e-05,  6.6557e-05, -7.3857e-05,  2.2535e-07,\n",
      "        -4.7927e-05,  3.2824e-06, -5.9028e-05,  5.5667e-05,  1.9269e-05,\n",
      "         3.1969e-05, -2.2426e-05, -9.6827e-05,  4.8804e-05,  2.3489e-05,\n",
      "        -2.8407e-05,  1.1500e-04, -1.1999e-04, -1.0312e-04,  4.1491e-05,\n",
      "        -7.4253e-06, -1.0729e-04, -1.0572e-04, -6.7833e-05,  9.9334e-05,\n",
      "         9.0391e-05, -6.3076e-05,  3.6840e-05,  1.3433e-04,  2.5898e-05,\n",
      "        -3.4765e-05,  2.4645e-05, -8.2049e-05, -4.2808e-06,  1.6341e-05,\n",
      "         4.8460e-05,  6.5791e-05,  2.9296e-05, -1.3233e-04, -5.8976e-05,\n",
      "        -2.5278e-05,  3.7513e-05,  5.7141e-05,  3.4488e-05, -7.0976e-05,\n",
      "         1.0422e-05,  5.9991e-05, -1.5753e-04, -3.9263e-05,  5.2879e-05,\n",
      "        -1.9486e-05,  5.1850e-05,  1.9365e-05, -5.7269e-05, -1.2659e-06,\n",
      "        -7.0774e-06,  7.1343e-05,  4.1366e-05, -1.8138e-05,  1.5092e-05,\n",
      "        -2.8867e-05,  3.9613e-07,  5.3027e-05, -5.4583e-05, -6.8016e-05,\n",
      "        -8.6325e-05, -2.4946e-05, -2.8247e-06, -3.2511e-05, -1.2772e-04,\n",
      "         5.5383e-06, -8.5750e-05, -9.1754e-05,  2.6138e-05,  9.5099e-06,\n",
      "         2.3832e-05,  2.4683e-05,  4.3604e-06,  4.9708e-05,  2.8396e-05,\n",
      "        -1.7795e-05, -5.4805e-05,  1.7300e-05,  3.2345e-05,  1.0736e-04,\n",
      "         2.6671e-06,  2.2169e-05, -7.1947e-05,  5.3544e-05,  2.8581e-05,\n",
      "         4.0821e-05,  8.6285e-05, -6.5111e-05, -1.3908e-05, -5.3154e-05,\n",
      "         6.0488e-05, -6.2741e-06,  1.0951e-04,  3.2722e-05, -3.2411e-05,\n",
      "         3.7356e-05, -5.2504e-06, -6.2534e-05,  6.8623e-05,  1.2485e-04,\n",
      "        -9.2708e-05,  2.0250e-05,  7.8340e-06,  2.2999e-06, -5.3376e-05,\n",
      "        -2.5613e-05,  2.7614e-05, -9.5441e-05,  1.4491e-05,  2.0822e-05,\n",
      "        -2.4664e-05,  8.9194e-05,  4.5249e-05,  3.3838e-06,  1.1106e-04,\n",
      "         4.1534e-05, -5.0984e-05, -5.9699e-05,  2.5857e-05,  5.8750e-05,\n",
      "        -1.0804e-04, -6.0979e-05,  3.7391e-05, -3.3297e-05, -5.3137e-05,\n",
      "        -4.6234e-05, -5.2498e-05,  3.0614e-05, -4.9303e-05,  1.1466e-04,\n",
      "         4.7775e-06, -7.8877e-06,  1.0937e-05, -8.0923e-05,  5.1456e-05,\n",
      "        -1.6304e-05, -5.3051e-05,  8.8228e-05,  4.4954e-05,  1.4865e-05,\n",
      "         6.3881e-06,  1.0626e-04, -4.5294e-05,  7.1699e-05, -1.4531e-05,\n",
      "        -3.3178e-05, -1.2114e-04, -4.7488e-05,  4.2537e-05, -2.5444e-05,\n",
      "         8.0136e-06, -7.9567e-05, -3.1379e-05,  7.0056e-06, -2.7704e-05,\n",
      "         5.5078e-05, -2.3344e-05,  5.6947e-06, -2.0947e-05,  4.3801e-05,\n",
      "        -6.2693e-05, -4.1901e-05, -6.1618e-05, -8.6656e-05, -3.8585e-05,\n",
      "         1.4255e-05,  7.3834e-05,  2.6526e-05,  3.9708e-05, -3.5614e-05,\n",
      "        -5.6165e-05,  2.7919e-05,  5.4292e-05,  2.8851e-05, -3.5232e-05,\n",
      "         5.5757e-05, -9.8370e-05, -1.6329e-05, -3.2742e-05, -5.2433e-05,\n",
      "        -1.3148e-05, -7.9762e-05, -2.6487e-05, -9.0117e-05,  3.1880e-05,\n",
      "        -4.0888e-05,  5.7384e-05,  1.2644e-04, -5.4749e-05,  1.2286e-04,\n",
      "        -7.6131e-05, -5.8858e-05,  4.9492e-05,  2.6239e-05,  5.6959e-05,\n",
      "        -9.4981e-05,  3.3575e-05,  1.0717e-04,  1.1327e-04, -4.0167e-05,\n",
      "         9.5349e-05, -4.3667e-05, -2.5150e-05, -1.3794e-05, -5.3155e-06,\n",
      "        -1.7356e-05, -1.0270e-04,  3.9242e-06,  6.0269e-05,  1.0353e-04,\n",
      "         3.6200e-05, -2.2829e-05, -9.5238e-05,  7.2477e-05, -1.1880e-04,\n",
      "         9.1047e-05,  3.4180e-05,  2.8732e-05, -6.8052e-05,  1.7348e-05,\n",
      "         1.0679e-04,  6.0470e-05,  1.9490e-05, -9.7473e-06,  2.9724e-05,\n",
      "         5.0205e-05, -7.3761e-05, -3.1903e-05, -1.6121e-05, -2.5066e-05,\n",
      "        -1.1543e-04,  4.9842e-05,  5.8156e-05,  4.0146e-05,  3.3301e-05,\n",
      "         7.2453e-05,  9.9573e-06, -8.4012e-05,  4.1851e-05, -1.4674e-05,\n",
      "         2.9681e-05,  4.2920e-05, -1.4535e-04, -1.0358e-04, -3.0492e-05,\n",
      "         5.5016e-06, -6.7451e-05, -5.0854e-06, -1.0812e-04, -1.9155e-06,\n",
      "         1.6092e-05, -1.1539e-05, -8.8947e-05, -3.2812e-05,  2.8239e-05,\n",
      "         4.4825e-05, -5.1931e-05, -1.1243e-05, -3.3034e-05, -1.2430e-06,\n",
      "         1.1327e-05,  1.3868e-05, -1.8655e-05,  1.3022e-05,  1.1236e-04,\n",
      "        -2.3926e-05, -3.4555e-05, -1.8977e-05, -1.8936e-05, -1.0780e-04,\n",
      "        -2.2446e-06,  1.7954e-05,  3.4112e-05,  6.1520e-05,  1.1954e-04,\n",
      "        -6.8123e-05,  5.4916e-05, -6.6797e-06,  1.1167e-04, -2.7665e-05,\n",
      "        -6.6835e-05,  1.4736e-05, -6.0530e-05, -6.0829e-05, -9.5412e-05,\n",
      "        -4.0167e-05,  8.0394e-06, -6.3665e-05,  4.9314e-05, -2.0562e-04,\n",
      "         8.9250e-06,  4.2978e-05,  9.4470e-05,  4.2621e-05, -3.9496e-05,\n",
      "        -3.8488e-05, -1.6993e-05, -3.5700e-05,  5.6794e-05, -7.1125e-05,\n",
      "         1.9500e-05,  3.4619e-05, -9.9137e-05, -7.0126e-05, -3.2069e-05,\n",
      "        -1.9388e-05,  9.7385e-05,  1.0644e-04, -7.6534e-05, -1.0095e-04,\n",
      "        -8.2910e-06, -1.5708e-05, -3.1371e-05,  4.0267e-05, -1.1377e-05,\n",
      "        -6.5738e-05,  1.6807e-05, -9.5503e-05,  1.1400e-04, -4.6913e-05,\n",
      "         7.0635e-05,  1.3442e-04, -1.0945e-04, -7.5753e-05,  5.0990e-05,\n",
      "         8.5037e-05,  1.7379e-05,  4.9214e-05,  3.2013e-05, -4.0973e-05,\n",
      "         1.2431e-04,  2.5941e-05,  5.1649e-05, -2.2439e-05, -1.0584e-04,\n",
      "         7.2853e-05, -2.3258e-05,  7.2230e-06,  6.5830e-06,  5.9687e-05,\n",
      "        -3.4656e-05, -8.2925e-05, -9.3137e-05,  2.8348e-05, -8.0462e-05,\n",
      "         2.4957e-06,  8.6734e-05])), ('postnet.convolutions.1.1.weight', tensor([ 0.1003,  0.0636,  0.1787,  0.1237,  0.2172,  0.3439,  0.1922,  0.1053,\n",
      "         0.2163,  0.1179,  1.3738,  0.0846,  0.8602,  0.1381,  0.0693,  0.6851,\n",
      "         0.1149,  0.0929,  0.0662,  0.1076,  1.0571,  0.2662,  0.1108,  0.1424,\n",
      "         0.6271,  0.0717,  0.0755,  0.1155,  0.7829,  0.0932,  0.1220,  0.1185,\n",
      "         0.2273,  0.1871,  0.4635,  0.0831,  0.1205,  0.1080,  0.0688,  0.0907,\n",
      "         0.7205,  1.0449,  0.1513,  0.0890,  0.1210,  0.0980,  0.1138,  0.8183,\n",
      "         0.5832,  0.0658,  0.1169,  0.1185,  0.0555,  0.0752,  0.1399,  0.0864,\n",
      "         0.1164,  0.1127,  1.1489,  0.3378,  0.3505,  0.0900,  0.0895,  0.3095,\n",
      "         0.1176,  0.2975,  1.5824,  0.0652,  0.1236,  0.0696,  0.1069,  1.1637,\n",
      "         0.1179,  0.4329,  0.1263,  0.1033,  0.1317,  0.1100,  0.1177,  0.0551,\n",
      "         0.0999,  0.1017,  0.3069,  0.0829,  0.1207,  0.1010,  0.1961,  0.1075,\n",
      "         0.0937,  0.1025,  0.3117,  0.1130,  0.0653,  0.7469,  0.0850,  0.0912,\n",
      "         0.2016,  0.1073,  0.0751,  0.0940,  0.1736,  0.4304,  1.4215,  0.3666,\n",
      "        -0.0625,  0.4107,  0.4863,  0.5765,  0.1185,  0.1157,  0.0820,  0.1094,\n",
      "         1.0879,  0.1002,  0.0824,  0.1350,  1.3676,  0.0935,  0.0674,  0.1138,\n",
      "         0.1016,  0.0562,  0.0616,  0.1178,  0.1213,  0.1886,  0.1049,  0.0743,\n",
      "         0.2685,  0.0940,  0.1160,  0.0899,  0.3679,  0.1004,  0.1411,  0.1270,\n",
      "         0.1102,  0.1331,  0.1179,  0.0554,  0.2363,  0.1919,  0.2808,  0.0777,\n",
      "         0.1096,  0.1052,  0.0851,  0.2165,  0.2624,  1.3084,  0.0735,  0.0952,\n",
      "         0.4346,  0.2961,  0.0741,  0.0690,  0.1113,  0.1403,  0.5664,  0.0926,\n",
      "         0.5650,  0.0996,  0.1316,  1.1126,  0.1232,  0.5381,  0.1018,  0.1243,\n",
      "         0.1778,  0.1404,  0.1124,  0.1023,  0.1044,  0.9412,  0.1014,  0.1252,\n",
      "         0.5540,  1.0349,  0.2096,  0.0580,  0.1316,  0.1006,  0.0955,  0.1270,\n",
      "         0.3861,  0.1046,  0.0802,  0.0779,  0.1351,  0.1131,  0.0643,  0.1199,\n",
      "         1.0552,  0.6143,  0.1214,  0.0741,  0.3467,  0.0992,  0.1491,  0.0698,\n",
      "         1.4000,  0.3200,  0.1197,  0.0963,  0.1986,  0.0949,  0.0743,  0.0961,\n",
      "         0.0759,  0.1157,  0.0620,  0.0716,  0.0610,  0.1008,  0.4540,  0.1429,\n",
      "         0.1223,  0.1060,  0.1258,  0.1170,  0.1020,  0.1037,  1.0397,  0.0897,\n",
      "         0.1033,  0.0974,  0.0696,  0.1136,  0.1013,  0.1252,  0.1124,  1.0889,\n",
      "         0.0638,  0.3082,  0.1168,  0.1138,  0.1222,  1.2375,  1.1674,  0.1055,\n",
      "         0.8156,  0.0778,  0.1229,  0.3467,  0.2139,  0.0746,  0.1310,  0.2039,\n",
      "         0.1191,  0.1161,  0.1929,  0.1925,  0.1037,  0.5409,  0.0872,  0.1331,\n",
      "         0.0670,  1.0112,  0.1113,  0.0807,  0.0921,  1.0851,  0.1237,  0.1075,\n",
      "         0.1592,  0.1279,  1.3163,  0.9683,  0.7194,  0.1224,  0.6210,  0.0924,\n",
      "         0.0955,  0.1020,  0.1864,  0.1000,  0.2181,  0.1320,  0.4849,  0.0881,\n",
      "         0.1188,  0.1031,  0.2108,  0.3554,  1.0566,  0.0979,  0.1275,  0.0954,\n",
      "         1.3288,  0.8700,  0.7668,  1.3103,  0.1061,  0.9820,  0.1127,  1.0342,\n",
      "         0.0577,  0.1000,  0.1947,  0.1026,  0.1131,  0.1794,  0.5775,  0.1140,\n",
      "         0.0733,  0.1381,  0.3058,  0.1971,  0.1318,  0.1837,  0.0857,  0.2803,\n",
      "         0.1599,  0.1076,  0.1109,  0.1724,  0.2991,  0.1409,  0.1017,  0.1273,\n",
      "         0.3588,  0.1505,  0.1137,  0.1291,  0.1622,  0.0558,  0.1676,  0.7685,\n",
      "         0.3921,  0.3521,  0.0628,  1.3353,  0.1657,  0.1608,  0.1151,  0.1186,\n",
      "         0.1188,  0.1199,  0.1110,  0.0998,  0.4113,  0.8862,  0.1533,  0.1232,\n",
      "         0.0742,  0.1064,  0.6095,  0.0642,  0.1040,  0.0797,  0.1656,  0.5717,\n",
      "         0.0638,  0.0698,  0.0972,  0.3277,  0.1103,  0.0687,  0.0997,  0.0648,\n",
      "         0.2882,  0.0789,  0.0673,  0.1239,  0.1129,  0.0897,  0.8681,  0.8503,\n",
      "         0.1132,  0.1087,  0.0759,  0.1728,  0.1201,  0.1223,  1.1399,  0.1057,\n",
      "         0.1026,  0.1309,  0.1025,  0.1674,  0.0951,  0.1115,  0.1301,  0.0946,\n",
      "         0.1046,  0.0563,  0.1108,  0.3490,  1.0815,  0.0776,  0.0679,  0.3816,\n",
      "         0.0648,  0.1182,  0.1085,  0.1192,  0.1409,  0.0798,  0.3953,  0.0722,\n",
      "         0.3609,  0.1054,  0.1317,  1.1586,  0.0647,  0.1044,  0.9401,  0.2280,\n",
      "         0.1198,  0.0930,  0.0961,  0.0719,  0.1364,  0.2015,  0.1562,  0.1232,\n",
      "         0.1141,  0.6774,  0.0682,  0.0648,  0.1331,  0.0901,  0.0908,  0.3786,\n",
      "         0.1174,  0.0987,  0.1812,  0.0792,  0.1033,  0.5854,  0.0800,  0.1111,\n",
      "         0.0989,  0.1042,  0.0988,  0.2097,  0.1089,  1.5468,  1.1695,  0.1142,\n",
      "         0.0923,  0.0984,  0.1193,  1.1790,  1.3036,  0.1038,  1.2357,  0.1060,\n",
      "         0.0692,  0.0933,  0.1044,  1.2171,  0.1217,  0.2166,  0.0590,  0.1081,\n",
      "         0.1152,  0.0996,  0.4113,  0.0788,  0.0545,  0.0966,  1.0319,  0.3118,\n",
      "         1.1937,  0.0590,  0.3202,  0.0965,  0.1102,  0.0844,  0.0886,  0.0956,\n",
      "         0.1298,  0.1266,  0.3691,  0.0960,  0.3467,  0.0653,  0.1260,  0.1229,\n",
      "         0.3746,  0.1474,  0.2612,  0.2241,  0.7173,  0.0663,  0.2512,  0.6870,\n",
      "         0.5502,  0.1274,  0.3968,  0.0964,  0.1297,  0.1136,  0.0560,  0.0852,\n",
      "         0.2372,  0.0816,  0.1281,  0.0749,  0.6792,  0.1088,  0.1975,  0.3318,\n",
      "         0.1147,  0.9193,  0.0702,  0.0579,  1.1144,  0.1118,  0.3001,  0.0887])), ('postnet.convolutions.1.1.bias', tensor([ 6.1594e-04,  8.5527e-04,  2.3022e-03, -2.2698e-04,  1.0118e-02,\n",
      "         1.4168e-03,  9.1962e-03, -9.0586e-04,  1.5604e-03,  4.7263e-04,\n",
      "         3.2406e-01,  1.3837e-03,  1.1794e-01,  3.1437e-05,  9.0713e-04,\n",
      "        -2.0011e-01, -5.4530e-04, -3.4728e-04, -2.5767e-05, -1.2639e-03,\n",
      "        -3.3865e-01, -5.3552e-03,  2.6925e-04,  1.5894e-03,  3.8721e-02,\n",
      "        -5.4523e-04,  4.4824e-04,  4.1649e-04, -1.2115e-02,  2.9714e-04,\n",
      "        -7.6806e-06, -3.6346e-05, -3.0116e-03, -2.7651e-03,  8.9048e-03,\n",
      "         1.7192e-04, -2.4731e-04, -2.4253e-04,  9.3918e-04, -1.1326e-03,\n",
      "        -2.2155e-02,  3.2113e-01, -1.6745e-03, -3.0974e-04, -2.0282e-04,\n",
      "        -5.1819e-04, -2.6195e-04, -2.6333e-01, -5.1734e-02, -4.0276e-04,\n",
      "         1.3476e-03,  1.5661e-04, -4.9764e-04,  4.7530e-05,  5.7751e-04,\n",
      "         3.8553e-04, -1.2289e-04,  1.5989e-04,  2.8797e-01, -1.6079e-02,\n",
      "         4.1979e-02,  1.9991e-04, -1.4733e-03, -3.2642e-04, -2.2976e-04,\n",
      "        -4.6502e-03,  1.2688e-01,  2.8611e-04,  1.1076e-04, -6.1081e-04,\n",
      "        -1.0720e-04,  2.4052e-01, -2.8654e-04, -4.0502e-02,  3.3086e-04,\n",
      "         2.1143e-05, -2.4541e-04, -7.3154e-04, -1.5169e-04,  1.5590e-04,\n",
      "         8.4314e-04,  1.2779e-04, -2.6076e-02, -6.1142e-04,  4.3239e-04,\n",
      "         1.7353e-04,  8.7993e-03, -2.9362e-04,  1.0043e-03,  2.1607e-04,\n",
      "         6.7918e-03, -9.8603e-04, -4.6432e-05, -1.0518e-02,  1.0120e-03,\n",
      "        -1.0226e-04, -1.6978e-04, -6.1999e-04,  1.4387e-05,  7.5322e-04,\n",
      "        -1.9017e-04, -3.5561e-02, -4.3651e-01, -5.3529e-03, -1.3264e-04,\n",
      "        -1.2896e-02,  1.5361e-02,  4.1896e-03,  1.0386e-04,  9.0318e-04,\n",
      "         7.7591e-04, -1.6778e-04, -1.2436e-01, -5.4412e-04, -6.1331e-04,\n",
      "        -1.1104e-04,  3.1186e-01,  3.4254e-04,  2.6388e-04, -6.8802e-04,\n",
      "         1.6057e-04, -3.8762e-04, -1.0537e-03, -5.0323e-04, -2.4162e-04,\n",
      "        -2.0758e-03,  5.9640e-04, -8.6168e-05,  1.0655e-03,  2.9992e-04,\n",
      "        -5.9507e-04, -4.3748e-04, -1.1810e-03,  1.3537e-04,  1.0199e-03,\n",
      "         5.4583e-04, -7.4675e-04, -2.2157e-04, -9.9688e-04,  4.2056e-04,\n",
      "        -3.5534e-03, -7.9805e-03,  1.4608e-03,  1.1340e-03,  1.6621e-04,\n",
      "         1.0347e-03,  2.0194e-04, -1.0810e-03, -3.2103e-02, -3.2303e-01,\n",
      "        -4.2740e-04,  4.1270e-04, -1.8778e-03,  8.3712e-03, -1.3486e-03,\n",
      "        -6.6656e-04,  1.3445e-04, -1.5981e-03, -2.8698e-02, -5.1076e-04,\n",
      "         3.9028e-02, -1.2336e-04, -8.5881e-03,  2.7981e-01, -3.9098e-04,\n",
      "        -4.1942e-02,  4.8941e-04,  4.2454e-04,  8.3213e-03, -1.4327e-03,\n",
      "         3.1162e-04, -1.7490e-04,  6.7866e-04,  2.6491e-01, -2.1156e-04,\n",
      "         2.3435e-04, -8.8164e-04, -3.3925e-01,  5.1150e-03,  2.2349e-03,\n",
      "         6.9924e-04, -3.2661e-05, -4.2569e-04,  9.0301e-04, -4.8557e-02,\n",
      "        -5.9915e-05, -6.7179e-04,  2.3613e-04,  4.6120e-04,  1.4115e-03,\n",
      "        -5.8631e-04,  1.4982e-04, -1.5164e-01,  4.6338e-02,  7.1743e-04,\n",
      "         2.3460e-05, -1.2605e-02,  7.2129e-04, -1.8465e-03, -6.6919e-05,\n",
      "        -4.4037e-03, -2.8737e-03,  6.8205e-04,  2.6506e-05, -7.1687e-03,\n",
      "        -2.4541e-04,  7.7856e-04,  4.5852e-05, -1.6883e-04, -2.1937e-04,\n",
      "         6.4459e-05, -5.0959e-04,  2.0752e-04, -7.3613e-04,  1.2234e-02,\n",
      "         1.7106e-03, -1.7805e-04,  3.3597e-04,  5.6109e-04, -7.9740e-05,\n",
      "        -3.3934e-04,  2.3045e-04, -3.2792e-01,  6.2368e-04, -4.5001e-04,\n",
      "        -3.3321e-04,  4.8866e-04, -4.9064e-04,  1.0056e-03, -1.8826e-04,\n",
      "         1.9774e-04, -2.2535e-01, -8.2065e-04, -2.4047e-02, -4.6193e-05,\n",
      "        -1.2176e-04, -1.5212e-04,  1.5502e-02,  3.0881e-01,  1.8043e-05,\n",
      "        -1.6039e-01, -2.1500e-05,  2.5729e-04, -1.0036e-02,  6.4291e-03,\n",
      "         2.2198e-04, -8.2773e-04, -1.4704e-03,  2.6053e-04,  2.8490e-04,\n",
      "        -3.7387e-03, -6.4965e-03, -9.7773e-05,  6.4124e-02,  4.3839e-04,\n",
      "        -8.2488e-05,  4.3656e-04, -2.2613e-01,  5.6729e-04, -5.4752e-04,\n",
      "         1.8670e-04, -5.6153e-01, -2.1069e-04, -5.0019e-04, -2.4033e-04,\n",
      "        -2.5395e-04, -2.2775e-01,  1.9305e-01,  7.6914e-03, -2.3587e-04,\n",
      "         1.3483e-01, -5.4559e-04,  3.2838e-04,  6.1258e-04,  3.3855e-03,\n",
      "         6.0682e-04,  7.8976e-03,  5.0312e-04, -5.3309e-02, -5.4068e-05,\n",
      "         1.8285e-04,  3.1534e-04,  6.3075e-03, -7.1948e-03, -2.2199e-01,\n",
      "        -8.0712e-05,  5.6899e-04,  1.4803e-04,  1.6815e-01, -1.4365e-01,\n",
      "        -5.0073e-02,  3.4485e-01, -4.5328e-04,  8.8089e-02, -9.5869e-05,\n",
      "         1.8017e-01, -1.7693e-04, -6.4581e-04, -4.8829e-03, -1.2201e-04,\n",
      "        -2.9915e-04, -1.7854e-03, -8.6707e-03, -1.3842e-03, -3.9488e-04,\n",
      "         1.2721e-03, -1.0802e-02, -4.3247e-03,  1.0939e-03, -7.2085e-03,\n",
      "         4.1877e-04, -1.1327e-02, -1.2376e-03,  5.5189e-05,  5.1561e-04,\n",
      "        -1.0284e-02,  7.0752e-03,  1.6442e-03,  1.1816e-03, -5.0676e-06,\n",
      "         4.9689e-04, -4.1233e-04, -1.4344e-04,  1.1332e-03,  3.6904e-03,\n",
      "        -1.3181e-03,  9.1738e-03,  3.2193e-02, -4.4527e-02,  3.5062e-03,\n",
      "        -5.2942e-04,  3.7294e-01,  1.2384e-03,  1.1607e-03,  8.1522e-04,\n",
      "        -6.6767e-04,  1.7498e-03, -2.6146e-04,  5.6915e-05,  4.8786e-04,\n",
      "         1.9966e-02, -2.8967e-01, -4.6540e-04, -1.5773e-04,  4.4954e-04,\n",
      "         1.2306e-03,  1.5961e-01,  2.5361e-04, -2.8247e-05, -2.4936e-03,\n",
      "         2.0892e-03,  9.5000e-02,  5.9910e-04, -1.0484e-04,  2.2309e-04,\n",
      "        -1.0796e-02, -4.8606e-04, -3.2287e-05,  1.4682e-04, -5.7447e-04,\n",
      "        -1.1014e-02,  1.9613e-04,  4.0856e-05,  5.0765e-04,  7.4225e-04,\n",
      "         1.2445e-04,  1.3135e-01, -4.9005e-02, -7.1741e-04,  1.9420e-04,\n",
      "        -3.0434e-05, -4.1698e-03, -7.0841e-04,  2.5852e-04, -2.3724e-01,\n",
      "         7.7094e-04,  2.2902e-04,  1.4119e-03, -3.5573e-04,  3.0448e-03,\n",
      "        -6.8950e-04, -7.6190e-04,  7.7454e-04, -5.9706e-04, -5.4913e-04,\n",
      "        -4.6214e-04,  6.2050e-04,  4.8471e-03,  1.8985e-01, -3.4329e-04,\n",
      "         2.8912e-04, -2.1325e-03, -6.5149e-04,  6.3843e-04,  8.4145e-05,\n",
      "        -5.1209e-04,  2.9568e-04,  5.4454e-04, -1.4799e-02, -4.6108e-04,\n",
      "         1.3750e-03, -1.8867e-04, -7.6430e-04,  5.6972e-02,  4.2814e-04,\n",
      "        -2.7024e-04,  3.7361e-02,  8.2102e-03, -2.5809e-04,  5.3268e-04,\n",
      "         7.8853e-05, -2.7014e-04, -1.7313e-03, -7.9559e-03, -1.8131e-03,\n",
      "        -4.0925e-04,  1.6276e-05, -6.6792e-02, -7.3483e-04, -1.0221e-04,\n",
      "         3.4683e-04,  6.8216e-04, -8.3823e-05,  2.8766e-02, -2.4525e-04,\n",
      "        -6.6017e-04,  3.1922e-03, -6.5232e-04, -6.4061e-04,  9.2529e-02,\n",
      "         3.1700e-05,  7.5925e-04,  9.7761e-04, -6.0675e-04,  1.1419e-03,\n",
      "         8.0560e-03,  6.4458e-06, -2.7674e-01, -2.1363e-01, -3.8426e-04,\n",
      "        -3.6856e-05,  1.7525e-04,  6.1881e-04, -3.2920e-01, -1.1931e-01,\n",
      "        -2.5247e-04,  1.1312e-01, -2.4934e-04,  5.1748e-04, -1.6546e-04,\n",
      "         6.6520e-05,  1.2227e-02, -9.9536e-04,  2.7371e-03,  8.6506e-04,\n",
      "        -1.0311e-03, -6.5110e-04, -2.3654e-04,  4.4353e-02, -4.3545e-04,\n",
      "        -1.1298e-04, -1.7026e-04,  1.7307e-01, -5.8557e-03,  2.8450e-01,\n",
      "         6.3157e-04, -7.4428e-03, -9.9519e-04,  1.1601e-03,  1.1913e-04,\n",
      "        -6.4229e-04, -1.3368e-04,  1.6098e-04, -4.3807e-04, -3.9136e-03,\n",
      "        -9.2294e-05,  2.7424e-02,  3.9439e-05,  1.8409e-04,  5.0802e-04,\n",
      "        -1.7880e-03,  6.4591e-03, -7.6486e-03, -3.6655e-03,  1.2212e-01,\n",
      "        -3.0384e-04, -1.1449e-02,  7.8101e-02,  7.6388e-02, -2.6564e-04,\n",
      "        -3.8158e-02, -2.9091e-04,  3.3479e-04, -4.0884e-04, -3.8622e-04,\n",
      "        -8.1973e-04,  5.8311e-03, -1.8033e-03, -1.3162e-04,  1.4863e-04,\n",
      "        -1.5178e-01,  4.8696e-04, -3.7809e-04,  3.3300e-03,  6.3054e-03,\n",
      "         1.4394e-02, -8.5476e-05,  7.7396e-04, -2.8690e-01, -7.0874e-05,\n",
      "         2.9384e-03,  2.9551e-04])), ('postnet.convolutions.1.1.running_mean', tensor([ 4.2782e-04,  8.6757e-03, -2.7128e-03, -2.7487e-03,  7.3377e-03,\n",
      "         3.2091e-03,  1.2242e-02, -1.0250e-03,  6.8131e-03,  3.0981e-03,\n",
      "         8.1725e-03, -7.3079e-04,  3.4567e-03,  1.1107e-03, -2.5113e-02,\n",
      "        -2.6688e-02,  4.9520e-04,  1.6088e-03,  2.3323e-03, -4.4822e-04,\n",
      "        -1.2287e-02, -1.2390e-04, -8.6728e-06,  1.2723e-04, -8.3474e-04,\n",
      "        -5.0034e-03, -1.0337e-03, -5.3206e-04,  9.4317e-04,  8.5989e-04,\n",
      "         5.9521e-05, -4.0524e-04, -2.3959e-03,  2.9031e-03, -9.1861e-04,\n",
      "         1.4504e-04, -1.1191e-04, -7.9622e-04,  6.5303e-03, -3.5597e-03,\n",
      "        -4.9449e-03,  1.3412e-02,  3.2850e-04,  7.4544e-04,  1.1610e-04,\n",
      "         2.0316e-03,  1.4744e-03, -3.3964e-02,  2.9438e-04,  1.2963e-03,\n",
      "        -1.3101e-03,  8.9446e-05,  2.4047e-03,  6.8304e-03,  1.2332e-03,\n",
      "         2.8192e-03,  1.9941e-03, -1.1111e-03,  4.8180e-03, -1.1860e-03,\n",
      "         9.1766e-03, -9.6035e-04, -4.9844e-03, -1.9039e-03, -4.0139e-04,\n",
      "        -3.6091e-03,  1.0802e-02, -3.3146e-03,  1.3329e-03, -3.0541e-03,\n",
      "         1.1291e-04,  3.4351e-03, -1.3315e-04,  1.2461e-03, -2.4306e-04,\n",
      "         2.3379e-04, -1.4495e-03, -1.7463e-03,  2.0289e-04, -7.1372e-04,\n",
      "         8.6944e-06, -2.5003e-03, -5.3032e-03, -4.6791e-04,  7.2784e-04,\n",
      "         1.3993e-03,  3.7974e-03, -4.7541e-04, -2.6121e-03,  1.1137e-03,\n",
      "         6.0852e-03,  2.6706e-04,  1.0220e-03,  7.2801e-04,  2.6261e-03,\n",
      "         1.2557e-03, -3.9341e-04, -9.5198e-04, -3.8819e-03,  2.1488e-03,\n",
      "        -2.4568e-03, -6.6157e-03, -1.2940e-02, -1.0888e-03,  1.6194e-03,\n",
      "        -4.1783e-03,  1.2872e-03,  1.5674e-03, -2.1619e-04, -1.0081e-03,\n",
      "         2.0546e-04, -2.2487e-03, -7.9141e-03, -7.4573e-04,  6.1460e-03,\n",
      "        -3.1239e-03,  1.6260e-02,  2.2500e-03,  7.7354e-03, -1.3545e-04,\n",
      "        -8.7026e-04, -4.2279e-04, -1.8423e-03, -1.7339e-03, -1.1269e-04,\n",
      "        -5.4444e-04, -6.2133e-04,  7.5143e-03, -1.2017e-02, -1.4784e-04,\n",
      "         1.4509e-04, -1.6006e-03,  2.9639e-03,  2.5052e-04,  2.3601e-04,\n",
      "        -6.1985e-04,  1.9184e-04, -3.3398e-04, -3.7705e-04,  1.4554e-03,\n",
      "        -2.0428e-04, -4.0529e-03,  3.8158e-03,  3.8372e-03, -1.8131e-03,\n",
      "         3.4216e-04,  3.4516e-03, -4.0773e-03, -9.8503e-03, -2.7630e-03,\n",
      "        -7.1164e-05, -1.3777e-04, -2.1209e-03,  4.0481e-03, -1.9072e-03,\n",
      "        -2.5454e-04,  4.5811e-04, -3.1402e-04, -6.9760e-03,  7.8401e-05,\n",
      "        -3.9417e-03,  6.3951e-04,  6.0586e-04,  1.0292e-02, -1.0615e-03,\n",
      "        -4.8167e-03,  1.7234e-03, -1.4029e-03,  4.3040e-03, -8.2211e-03,\n",
      "        -5.7595e-04, -6.7567e-04,  1.3554e-03,  1.9197e-02,  7.6501e-04,\n",
      "         2.5242e-03, -2.9535e-03, -1.4410e-02, -1.4066e-03, -9.0445e-03,\n",
      "         6.0979e-04, -1.0415e-05,  1.5180e-04,  1.6982e-03, -1.1777e-02,\n",
      "         2.6675e-04,  1.0234e-03,  5.2131e-03,  4.8424e-03,  7.4380e-03,\n",
      "         1.7353e-03,  8.5515e-04, -1.3690e-02,  5.2413e-03,  1.5614e-03,\n",
      "         2.5208e-04, -3.2984e-03,  1.9727e-03, -7.5755e-03, -1.0925e-03,\n",
      "         5.4785e-03, -1.0314e-03, -1.1194e-03,  1.4417e-03, -5.1347e-03,\n",
      "        -6.6431e-04,  1.1605e-03,  3.9161e-04,  2.4307e-03, -8.9064e-04,\n",
      "        -4.2560e-04, -3.1573e-05, -3.9463e-03, -1.7511e-04,  1.7567e-03,\n",
      "         6.7892e-03, -1.0195e-03,  8.9133e-04,  2.6712e-04,  4.9025e-04,\n",
      "        -1.1439e-04,  3.7654e-04, -1.9377e-02,  4.9859e-04,  3.4051e-04,\n",
      "        -5.2070e-04, -1.0576e-02,  5.6351e-03, -1.0848e-04,  5.8591e-04,\n",
      "         5.7860e-04, -3.5375e-03,  1.6519e-03,  5.0176e-03,  3.0658e-04,\n",
      "        -1.3065e-03,  2.0054e-03,  1.7454e-03,  1.3330e-02, -3.2641e-05,\n",
      "        -1.0172e-02,  2.8474e-03,  1.5141e-03, -3.9010e-03,  2.6822e-03,\n",
      "        -1.5420e-04,  8.5670e-04,  9.7209e-04,  1.6720e-04,  9.7217e-04,\n",
      "        -1.6910e-03, -1.7462e-03, -1.5206e-03,  5.2227e-03,  4.8132e-04,\n",
      "         1.1298e-03, -9.0623e-04, -8.3120e-03, -1.6370e-04,  6.3754e-03,\n",
      "        -8.1159e-04, -1.1349e-02, -3.2365e-04, -8.0972e-04,  4.6501e-04,\n",
      "         1.3442e-04, -6.7774e-03, -3.7029e-04,  1.4906e-03, -9.9722e-04,\n",
      "         8.3831e-03,  2.8593e-04,  1.3617e-03,  3.6200e-04,  5.9895e-03,\n",
      "        -1.3571e-04,  1.5352e-03, -2.1591e-03,  2.9947e-03,  6.2468e-04,\n",
      "         3.8159e-03,  5.1955e-04, -2.5394e-03, -1.5034e-03, -3.7626e-03,\n",
      "         1.2153e-03, -1.5666e-03, -7.4558e-04,  6.1628e-03, -4.7549e-03,\n",
      "        -3.2237e-03,  2.3405e-02,  1.2908e-03,  7.2318e-03,  5.4483e-04,\n",
      "         4.4788e-03, -8.6041e-05,  8.5860e-03, -6.8895e-03, -2.8018e-03,\n",
      "        -1.1028e-04, -8.6867e-03, -7.2802e-03, -8.3632e-03,  3.2741e-03,\n",
      "         1.9502e-03,  1.7352e-03,  1.8669e-03, -1.1670e-03, -1.7972e-03,\n",
      "        -4.1299e-04, -3.0944e-03, -2.3477e-03,  4.8272e-04,  1.1902e-04,\n",
      "        -2.5778e-03, -3.2819e-03,  1.1302e-03,  6.8154e-04, -1.6058e-03,\n",
      "        -3.0020e-03,  4.3782e-03, -8.5309e-04,  4.2791e-04,  1.3287e-03,\n",
      "         5.4484e-04,  1.7826e-04,  1.5433e-03, -8.0843e-04, -2.5179e-03,\n",
      "        -1.6727e-02,  5.9510e-03, -3.8108e-03,  1.5893e-03,  1.0507e-04,\n",
      "        -5.4104e-04,  4.6817e-03,  1.4541e-03,  7.7036e-04, -6.9228e-04,\n",
      "         3.8288e-03, -4.0052e-02, -2.7789e-03, -2.4649e-03,  2.2025e-05,\n",
      "         2.3785e-04,  3.1230e-02, -8.8648e-04, -2.5038e-05,  9.2570e-04,\n",
      "        -4.5878e-04,  3.3592e-02,  3.1267e-03, -2.9407e-02, -2.1650e-04,\n",
      "        -8.1818e-04,  8.5698e-04, -4.0708e-04, -5.6262e-04, -8.0653e-04,\n",
      "        -4.1835e-04,  6.6881e-04, -8.8440e-04, -1.4719e-03,  9.2020e-04,\n",
      "        -5.3440e-05,  5.1157e-03,  6.1903e-03,  8.0993e-04,  3.8942e-04,\n",
      "        -6.0224e-03, -3.7578e-03,  8.4566e-04,  1.7654e-03, -2.8739e-03,\n",
      "         2.1452e-03, -4.0706e-04, -5.9573e-04, -6.2215e-04,  6.7892e-04,\n",
      "        -3.0636e-04, -7.4461e-04, -2.0610e-03, -1.1068e-03,  9.1120e-04,\n",
      "         3.3958e-03, -7.3980e-04,  2.0651e-03,  6.7790e-03, -1.8722e-04,\n",
      "         2.1036e-03, -1.1263e-03, -1.5631e-02, -7.8997e-04,  9.3273e-04,\n",
      "         8.4823e-04,  2.1682e-03, -1.3566e-03, -1.3427e-03,  8.4570e-04,\n",
      "        -6.9848e-04,  1.2672e-03, -1.2108e-04, -1.1718e-03,  6.8093e-03,\n",
      "        -4.0582e-04,  6.4769e-04,  4.4506e-03, -6.0037e-05,  1.0614e-03,\n",
      "        -4.9308e-04, -8.9874e-04, -2.0102e-03, -6.3555e-03, -1.9769e-03,\n",
      "        -9.4668e-05, -3.2569e-04,  1.2414e-03,  3.6442e-03,  7.4625e-04,\n",
      "         1.2487e-03, -1.2711e-03, -7.4014e-04,  6.7300e-03, -3.7018e-03,\n",
      "        -1.2006e-03,  3.0483e-03,  2.0009e-03, -1.4413e-03,  1.0163e-02,\n",
      "        -2.7214e-03,  9.5810e-04,  5.7762e-04, -8.4316e-04,  1.9316e-03,\n",
      "         1.5846e-03, -5.0677e-04, -1.0157e-02, -6.6960e-03,  2.3619e-04,\n",
      "        -2.7764e-04,  7.5447e-04, -1.2400e-05, -6.5707e-03, -3.3878e-03,\n",
      "        -1.6028e-03, -1.1881e-03, -1.0472e-04, -7.4820e-04,  3.2611e-04,\n",
      "        -3.1699e-04,  8.2508e-04, -1.0808e-03,  1.9085e-03, -2.4344e-03,\n",
      "        -1.1148e-03,  5.8597e-04, -2.3536e-03,  3.3584e-03, -7.7253e-04,\n",
      "         9.6823e-04,  5.4301e-04,  2.2437e-04, -1.1653e-03,  7.0618e-03,\n",
      "         4.1671e-03,  1.1875e-03,  1.7566e-03,  2.0213e-03,  4.5367e-05,\n",
      "        -1.0336e-03,  1.8457e-03,  1.9610e-04, -8.4546e-04,  3.9836e-03,\n",
      "        -2.3921e-04,  1.3714e-02, -3.4710e-03, -8.7232e-04, -2.0676e-03,\n",
      "        -5.1951e-03, -3.1842e-04, -5.3043e-03,  3.3619e-03,  9.5765e-03,\n",
      "         2.0314e-03, -8.3496e-03,  4.2646e-03,  1.9045e-03,  1.1568e-04,\n",
      "        -3.7814e-03, -5.6107e-04, -1.5620e-03,  5.9976e-04,  9.7206e-04,\n",
      "         2.3480e-03,  8.1677e-04,  8.5894e-03,  8.4484e-04,  3.5237e-04,\n",
      "        -2.1210e-02, -7.4828e-04, -2.2193e-03, -2.1636e-04,  1.9207e-03,\n",
      "         5.4495e-04,  8.5833e-04, -7.9322e-03, -1.2381e-02, -2.1049e-03,\n",
      "        -1.0621e-03,  4.8965e-04])), ('postnet.convolutions.1.1.running_var', tensor([0.0057, 0.0534, 0.0206, 0.0106, 0.0181, 0.0123, 0.0209, 0.0058, 0.0145,\n",
      "        0.0125, 0.0365, 0.0121, 0.0180, 0.0120, 0.0343, 0.0292, 0.0049, 0.0079,\n",
      "        0.0175, 0.0067, 0.0296, 0.0214, 0.0052, 0.0138, 0.0224, 0.0196, 0.0102,\n",
      "        0.0078, 0.0169, 0.0084, 0.0043, 0.0052, 0.0192, 0.0131, 0.0139, 0.0069,\n",
      "        0.0059, 0.0050, 0.0392, 0.0110, 0.0172, 0.0213, 0.0138, 0.0081, 0.0048,\n",
      "        0.0102, 0.0048, 0.0254, 0.0138, 0.0182, 0.0070, 0.0048, 0.0162, 0.0347,\n",
      "        0.0076, 0.0124, 0.0059, 0.0072, 0.0207, 0.0194, 0.0153, 0.0079, 0.0119,\n",
      "        0.0179, 0.0049, 0.0184, 0.0424, 0.0160, 0.0044, 0.0456, 0.0056, 0.0256,\n",
      "        0.0048, 0.0123, 0.0044, 0.0092, 0.0042, 0.0054, 0.0077, 0.0158, 0.0070,\n",
      "        0.0081, 0.0124, 0.0175, 0.0076, 0.0064, 0.0278, 0.0057, 0.0309, 0.0060,\n",
      "        0.0228, 0.0050, 0.0184, 0.0219, 0.0109, 0.0090, 0.0202, 0.0070, 0.0293,\n",
      "        0.0080, 0.0186, 0.0208, 0.0382, 0.0114, 0.0180, 0.0245, 0.0256, 0.0198,\n",
      "        0.0042, 0.0070, 0.0095, 0.0079, 0.0463, 0.0079, 0.0413, 0.0137, 0.0422,\n",
      "        0.0086, 0.0389, 0.0066, 0.0082, 0.0147, 0.0558, 0.0076, 0.0187, 0.0097,\n",
      "        0.0064, 0.0444, 0.0233, 0.0311, 0.0053, 0.0068, 0.0149, 0.0067, 0.0075,\n",
      "        0.0056, 0.0097, 0.0034, 0.0053, 0.0149, 0.0220, 0.0274, 0.0251, 0.0112,\n",
      "        0.0075, 0.0064, 0.0086, 0.0169, 0.0182, 0.0339, 0.0126, 0.0075, 0.0202,\n",
      "        0.0262, 0.0126, 0.0130, 0.0046, 0.0066, 0.0171, 0.0083, 0.0156, 0.0081,\n",
      "        0.0211, 0.0277, 0.0049, 0.0236, 0.0088, 0.0068, 0.0253, 0.0127, 0.0050,\n",
      "        0.0088, 0.0068, 0.0250, 0.0075, 0.0090, 0.0233, 0.0222, 0.0097, 0.0422,\n",
      "        0.0034, 0.0062, 0.0069, 0.0069, 0.0161, 0.0060, 0.0082, 0.0120, 0.0119,\n",
      "        0.0287, 0.0174, 0.0047, 0.0216, 0.0175, 0.0043, 0.0120, 0.0116, 0.0093,\n",
      "        0.0166, 0.0143, 0.0282, 0.0124, 0.0050, 0.0072, 0.0192, 0.0073, 0.0127,\n",
      "        0.0084, 0.0142, 0.0052, 0.0116, 0.0128, 0.0190, 0.0073, 0.0141, 0.0141,\n",
      "        0.0056, 0.0054, 0.0086, 0.0065, 0.0090, 0.0065, 0.0252, 0.0116, 0.0059,\n",
      "        0.0076, 0.0404, 0.0116, 0.0076, 0.0044, 0.0076, 0.0238, 0.0175, 0.0135,\n",
      "        0.0048, 0.0075, 0.0042, 0.0204, 0.0277, 0.0083, 0.0182, 0.0102, 0.0067,\n",
      "        0.0254, 0.0196, 0.0106, 0.0102, 0.0142, 0.0141, 0.0064, 0.0211, 0.0092,\n",
      "        0.0061, 0.0158, 0.0085, 0.0046, 0.0148, 0.0262, 0.0047, 0.0402, 0.0432,\n",
      "        0.0273, 0.0146, 0.0079, 0.0116, 0.0043, 0.0279, 0.0193, 0.0238, 0.0044,\n",
      "        0.0249, 0.0077, 0.0098, 0.0063, 0.0182, 0.0072, 0.0090, 0.0069, 0.0156,\n",
      "        0.0078, 0.0076, 0.0051, 0.0116, 0.0132, 0.0262, 0.0065, 0.0069, 0.0082,\n",
      "        0.0297, 0.0244, 0.0196, 0.0333, 0.0067, 0.0234, 0.0064, 0.0204, 0.0134,\n",
      "        0.0175, 0.0192, 0.0079, 0.0056, 0.0156, 0.0161, 0.0156, 0.0172, 0.0089,\n",
      "        0.0144, 0.0190, 0.0096, 0.0197, 0.0068, 0.0194, 0.0117, 0.0054, 0.0049,\n",
      "        0.0159, 0.0119, 0.0069, 0.0069, 0.0146, 0.0111, 0.0128, 0.0052, 0.0048,\n",
      "        0.0077, 0.0141, 0.0133, 0.0184, 0.0159, 0.0120, 0.0474, 0.0275, 0.0145,\n",
      "        0.0128, 0.0052, 0.0073, 0.0081, 0.0052, 0.0059, 0.0146, 0.0155, 0.0298,\n",
      "        0.0079, 0.0081, 0.0093, 0.0052, 0.0385, 0.0180, 0.0065, 0.0157, 0.0100,\n",
      "        0.0307, 0.0175, 0.0602, 0.0097, 0.0119, 0.0055, 0.0092, 0.0084, 0.0103,\n",
      "        0.0228, 0.0081, 0.0138, 0.0060, 0.0053, 0.0124, 0.0214, 0.0238, 0.0077,\n",
      "        0.0055, 0.0377, 0.0114, 0.0082, 0.0072, 0.0247, 0.0095, 0.0071, 0.0085,\n",
      "        0.0060, 0.0077, 0.0105, 0.0051, 0.0119, 0.0084, 0.0067, 0.0205, 0.0076,\n",
      "        0.0121, 0.0230, 0.0103, 0.0133, 0.0142, 0.0499, 0.0049, 0.0072, 0.0080,\n",
      "        0.0059, 0.0085, 0.0245, 0.0355, 0.0127, 0.0084, 0.0041, 0.0588, 0.0412,\n",
      "        0.0062, 0.0163, 0.0279, 0.0070, 0.0075, 0.0070, 0.0103, 0.0077, 0.0109,\n",
      "        0.0148, 0.0037, 0.0051, 0.0191, 0.0150, 0.0123, 0.0046, 0.0077, 0.0082,\n",
      "        0.0199, 0.0098, 0.0067, 0.0142, 0.0168, 0.0060, 0.0229, 0.0343, 0.0053,\n",
      "        0.0069, 0.0061, 0.0109, 0.0187, 0.0057, 0.0439, 0.0249, 0.0069, 0.0076,\n",
      "        0.0062, 0.0045, 0.0216, 0.0250, 0.0067, 0.0446, 0.0056, 0.0154, 0.0120,\n",
      "        0.0061, 0.0246, 0.0062, 0.0214, 0.0195, 0.0075, 0.0048, 0.0070, 0.0217,\n",
      "        0.0152, 0.0159, 0.0079, 0.0205, 0.0114, 0.0238, 0.0235, 0.0116, 0.0081,\n",
      "        0.0076, 0.0082, 0.0072, 0.0102, 0.0042, 0.0041, 0.0121, 0.0073, 0.0219,\n",
      "        0.0152, 0.0051, 0.0057, 0.0142, 0.0125, 0.0235, 0.0179, 0.0189, 0.0167,\n",
      "        0.0159, 0.0186, 0.0138, 0.0042, 0.0122, 0.0073, 0.0043, 0.0054, 0.0149,\n",
      "        0.0428, 0.0140, 0.0410, 0.0036, 0.0108, 0.0332, 0.0084, 0.0164, 0.0117,\n",
      "        0.0144, 0.0248, 0.0104, 0.0486, 0.0223, 0.0057, 0.0184, 0.0085])), ('postnet.convolutions.1.1.num_batches_tracked', tensor(18012)), ('postnet.convolutions.2.0.conv.weight', tensor([[[-2.7868e-03,  1.3195e-02, -1.3553e-02,  4.0685e-03,  1.1098e-03],\n",
      "         [ 1.0932e-02,  1.7867e-02,  1.9158e-02,  2.3086e-02,  2.1426e-02],\n",
      "         [ 1.3274e-03, -4.9062e-03, -4.7679e-05,  1.0307e-02,  1.1606e-02],\n",
      "         ...,\n",
      "         [-1.2876e-03, -7.9897e-03,  7.8396e-03,  1.4805e-02, -3.6328e-03],\n",
      "         [-6.2984e-04,  5.9711e-04,  3.6970e-03, -8.2797e-04,  3.8792e-03],\n",
      "         [ 1.1416e-03,  1.1083e-02, -7.6846e-03, -2.4243e-02, -1.9588e-02]],\n",
      "\n",
      "        [[-1.6519e-03, -2.0419e-03, -4.8613e-03, -7.1406e-03, -1.3168e-02],\n",
      "         [-1.9713e-03,  1.3963e-04,  2.0025e-03,  4.7628e-03,  9.2867e-04],\n",
      "         [ 3.1334e-03, -4.9761e-03, -1.4038e-02, -6.1525e-03,  2.1217e-03],\n",
      "         ...,\n",
      "         [ 3.7494e-03,  1.0827e-03,  6.2206e-03, -9.4230e-03, -9.5837e-03],\n",
      "         [ 2.8470e-03,  2.9629e-03,  5.2302e-03,  2.2983e-03,  6.9112e-03],\n",
      "         [ 3.3925e-03,  3.1898e-03, -3.5566e-03,  3.1226e-03,  1.8025e-03]],\n",
      "\n",
      "        [[ 1.5877e-02, -1.1472e-02, -3.4115e-03,  9.6928e-03,  2.4550e-03],\n",
      "         [-1.8202e-03,  7.7270e-03, -1.5072e-03, -1.2141e-03, -2.2664e-03],\n",
      "         [-1.9917e-04, -1.1028e-03,  3.2251e-03,  4.0523e-04,  6.2007e-05],\n",
      "         ...,\n",
      "         [-6.2419e-03,  7.7197e-03, -1.5653e-03, -1.2103e-02,  1.1369e-02],\n",
      "         [ 6.0450e-04,  3.6313e-03,  1.0276e-03, -5.4243e-03,  2.3864e-03],\n",
      "         [-5.8030e-03,  3.6444e-03, -5.9235e-03,  5.1401e-03, -5.2434e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.8232e-03, -6.8968e-03,  7.6286e-03, -5.6549e-03,  8.6004e-03],\n",
      "         [ 2.8894e-03,  4.1619e-03,  3.3624e-03,  3.7245e-03,  2.6343e-03],\n",
      "         [-3.7190e-03, -3.9660e-03,  5.1322e-04,  2.6134e-03, -9.8934e-04],\n",
      "         ...,\n",
      "         [-9.5169e-03,  1.3535e-02,  7.2490e-03, -8.4226e-03,  3.6012e-03],\n",
      "         [-5.2414e-04,  1.6118e-03,  4.3537e-03, -4.0556e-03,  1.2314e-03],\n",
      "         [-5.8041e-04, -1.3025e-03,  9.6045e-03, -4.5360e-03, -2.5052e-03]],\n",
      "\n",
      "        [[ 9.6547e-03, -3.4490e-03, -9.7869e-03, -7.7782e-03, -4.3047e-03],\n",
      "         [-6.8735e-04,  6.5831e-04,  2.4593e-03,  3.8437e-05, -2.1867e-03],\n",
      "         [-4.6156e-03, -1.7008e-03,  1.0041e-02,  7.3236e-03, -2.3862e-03],\n",
      "         ...,\n",
      "         [ 2.3420e-03,  3.6555e-03,  6.0372e-03,  3.1634e-03, -4.0748e-03],\n",
      "         [ 7.6516e-03,  7.7647e-03,  1.0284e-02,  5.8920e-03, -5.8784e-03],\n",
      "         [-3.6745e-03, -1.2226e-03, -7.3016e-04,  3.9434e-04,  3.4515e-03]],\n",
      "\n",
      "        [[-1.0802e-03,  4.3735e-03, -1.2328e-03,  1.7086e-03, -1.5409e-02],\n",
      "         [ 2.3851e-04, -1.0376e-03,  2.9273e-03,  3.1619e-03,  3.3460e-03],\n",
      "         [ 8.9201e-03,  7.6367e-03,  9.3282e-03,  6.6553e-03,  2.9598e-03],\n",
      "         ...,\n",
      "         [ 3.5318e-04, -5.9044e-03,  1.3320e-03, -4.2997e-04, -1.3875e-02],\n",
      "         [-4.0422e-03, -5.4900e-03, -2.7031e-03, -5.5661e-05,  8.9273e-03],\n",
      "         [ 5.2996e-03,  7.1049e-03, -7.5768e-03, -1.1476e-02, -8.6829e-03]]])), ('postnet.convolutions.2.0.conv.bias', tensor([ 1.6321e-05,  8.5603e-05, -1.8802e-05,  1.7697e-05,  5.5143e-05,\n",
      "         1.3283e-05,  1.2208e-06,  4.9053e-05, -5.7541e-05,  6.2253e-05,\n",
      "         6.0419e-05, -3.4835e-05, -3.1677e-05, -8.2259e-05, -1.9296e-05,\n",
      "        -4.5981e-05,  4.4588e-05,  2.1502e-05,  2.1392e-05, -6.6803e-07,\n",
      "        -2.9274e-05,  4.7277e-05,  4.1652e-06, -3.1690e-05, -4.8268e-05,\n",
      "        -3.9208e-05,  1.3527e-04, -4.9341e-05,  6.0299e-05, -6.4095e-05,\n",
      "         1.8946e-05, -4.9201e-05, -9.2304e-05, -1.1298e-04,  3.4957e-05,\n",
      "        -1.0584e-04, -1.1363e-05,  6.5362e-05, -6.4254e-05, -1.1969e-05,\n",
      "         5.6887e-05, -4.0349e-05,  4.2465e-05, -8.8618e-06, -7.9526e-05,\n",
      "         4.1593e-05,  3.3112e-05,  9.7287e-05,  9.1727e-05, -5.5725e-05,\n",
      "         7.2935e-05, -3.1063e-05,  7.0062e-05, -1.1110e-04, -2.3101e-05,\n",
      "        -3.4948e-05,  1.7397e-05,  3.8373e-05, -3.6069e-06, -7.1529e-05,\n",
      "        -5.2904e-05, -5.8323e-05, -7.3800e-06,  7.4932e-05, -3.4671e-05,\n",
      "        -5.9186e-05,  7.7763e-05,  8.1848e-05,  2.2904e-05, -2.7624e-05,\n",
      "         5.7398e-05,  2.4031e-05,  3.7688e-05,  1.4691e-04,  7.0112e-05,\n",
      "        -1.0768e-05,  8.0028e-05, -1.1667e-04, -2.5138e-06, -5.4853e-05,\n",
      "        -2.1025e-05,  7.7125e-06, -3.8729e-05, -2.1738e-05, -5.1804e-05,\n",
      "        -1.7714e-05,  1.7966e-05,  1.0126e-05, -5.8664e-05,  2.6779e-05,\n",
      "        -1.0706e-04,  5.6078e-05,  4.0028e-05, -2.5864e-05, -8.4887e-05,\n",
      "        -4.6581e-05,  1.5841e-05, -3.4651e-05,  1.3219e-04, -2.4232e-06,\n",
      "         5.4137e-05, -4.5677e-05,  8.9276e-05,  7.8964e-05, -8.2031e-05,\n",
      "        -5.3247e-05,  7.8319e-06,  2.0190e-05, -2.8989e-05,  3.9551e-05,\n",
      "        -2.5752e-06, -2.5203e-05,  2.1435e-05, -3.7427e-05, -3.6282e-05,\n",
      "         8.2490e-06,  2.2851e-05, -1.9006e-04,  3.6142e-06, -3.6326e-05,\n",
      "         1.0979e-06,  2.7649e-05, -2.8156e-06,  8.0327e-05,  1.3909e-05,\n",
      "        -2.4957e-05, -3.9818e-06, -3.2313e-06, -2.5383e-05, -1.0724e-04,\n",
      "         1.6224e-05,  1.0136e-04,  7.2708e-07, -2.7315e-05, -2.8564e-05,\n",
      "         1.3741e-05, -1.6783e-05, -1.6166e-04,  1.1671e-05,  8.9966e-05,\n",
      "        -2.6808e-05,  9.4334e-06,  2.4956e-05, -4.4072e-05,  3.9086e-05,\n",
      "        -4.0348e-05,  3.7530e-05,  5.9994e-05,  8.5184e-06,  6.0036e-05,\n",
      "         9.1704e-06,  5.3859e-05, -2.9380e-05, -9.7073e-05,  7.8060e-05,\n",
      "         6.8308e-05,  3.1414e-05, -4.3263e-05,  5.9152e-05, -5.3578e-05,\n",
      "         3.9495e-05, -7.7854e-05,  3.9891e-05, -4.3832e-05,  1.0154e-05,\n",
      "        -2.1408e-05,  7.8041e-05,  8.0383e-05,  3.0118e-05,  7.0561e-05,\n",
      "         4.2177e-05,  1.3259e-05,  3.8218e-05,  8.5043e-05, -4.6111e-05,\n",
      "        -3.6998e-06, -5.8677e-05,  6.5677e-05, -6.7025e-05, -7.3297e-05,\n",
      "        -8.5957e-05,  9.1266e-05,  4.5585e-05, -7.7271e-05,  2.9951e-05,\n",
      "        -6.0348e-05, -4.3451e-06,  5.0641e-05,  7.9887e-05,  4.6725e-05,\n",
      "        -1.0219e-05, -1.9146e-05,  5.0182e-05, -6.9869e-05,  2.5255e-05,\n",
      "         1.4963e-04, -1.9425e-04,  6.7366e-05, -8.9821e-05,  1.2067e-04,\n",
      "         4.8700e-05, -5.0185e-05, -6.7644e-05,  9.5247e-06, -3.2613e-05,\n",
      "        -3.2880e-05, -4.4964e-05, -2.7350e-05,  3.9012e-05, -7.1646e-05,\n",
      "        -6.4667e-05,  2.3355e-05, -3.8495e-05, -1.6544e-05, -3.2258e-05,\n",
      "        -1.3099e-05,  1.1476e-05, -2.3709e-05,  5.0979e-05, -1.9140e-06,\n",
      "        -5.9261e-06, -9.1444e-05,  3.8131e-05, -6.6565e-05, -7.8576e-05,\n",
      "        -4.5631e-06,  5.7997e-05, -6.6289e-05,  5.2985e-05, -4.0958e-05,\n",
      "         5.2592e-05,  4.0080e-05, -4.9437e-05,  3.9996e-06,  1.0415e-05,\n",
      "        -2.5656e-05, -2.9213e-05, -8.9469e-06, -1.0492e-05,  9.6993e-05,\n",
      "        -9.2062e-05, -5.8494e-05,  1.6958e-05,  4.0981e-06,  8.2347e-05,\n",
      "         7.2175e-05,  1.0085e-05,  3.3413e-05, -2.2046e-05, -3.8369e-05,\n",
      "         4.8870e-06, -2.8557e-05, -2.0337e-05, -8.1757e-05,  7.5748e-05,\n",
      "        -4.9653e-06,  1.4047e-05, -1.0912e-04, -6.3604e-07,  1.8659e-05,\n",
      "        -3.7837e-05, -1.0051e-05, -9.7192e-05,  3.9848e-05,  4.2419e-05,\n",
      "         2.8122e-08, -1.1769e-05, -9.0421e-05,  1.0941e-04, -1.1223e-04,\n",
      "         6.5568e-05,  6.4158e-06,  3.3029e-05,  5.3809e-05,  1.0787e-04,\n",
      "        -2.9621e-05,  6.9019e-05, -1.6917e-05, -1.4176e-05, -2.1194e-05,\n",
      "         2.7163e-05,  3.1394e-05, -3.6554e-05, -4.5021e-05,  8.1406e-05,\n",
      "         1.0332e-05, -4.0796e-05, -3.1869e-06,  2.3393e-05, -2.5751e-05,\n",
      "        -5.5411e-06,  4.7985e-06, -7.0050e-06,  4.0669e-05,  1.2989e-05,\n",
      "        -4.8717e-05, -1.2528e-04,  2.9783e-05,  3.0239e-05, -2.5378e-05,\n",
      "         4.8882e-05,  4.6777e-05, -2.1792e-05, -1.0582e-05, -6.3486e-05,\n",
      "         6.1555e-05, -2.5360e-05,  8.5100e-05,  2.1377e-05,  5.4720e-05,\n",
      "         9.0521e-05,  5.6957e-05,  1.1805e-04, -3.8550e-05, -9.6069e-05,\n",
      "        -5.1921e-05, -2.6432e-05, -3.3731e-05, -6.2396e-05, -7.5431e-05,\n",
      "        -5.8828e-05,  6.9898e-06, -1.2084e-04,  1.2299e-05,  9.7913e-05,\n",
      "         3.5824e-05,  4.4194e-05, -1.5316e-04, -1.3174e-05, -2.6995e-05,\n",
      "        -8.9250e-05,  2.4063e-05, -3.7147e-05,  1.9854e-05,  3.0116e-05,\n",
      "         4.7850e-05,  5.0878e-05, -1.2751e-05,  5.7151e-05, -3.5910e-05,\n",
      "         4.6666e-05, -7.6396e-05,  7.4663e-05,  4.9654e-05, -3.3680e-05,\n",
      "        -5.2199e-05, -4.5882e-05, -1.4323e-04, -4.5263e-05, -4.3951e-06,\n",
      "        -5.5950e-05, -6.9457e-05,  7.4741e-05, -6.2444e-05,  1.5829e-04,\n",
      "        -1.8188e-06,  1.3738e-05, -4.3843e-05, -9.3210e-05,  2.1642e-05,\n",
      "        -1.1140e-05, -1.3805e-04, -5.4042e-06,  2.4055e-05,  9.0305e-06,\n",
      "        -4.2300e-05,  3.7984e-05, -5.7793e-05,  3.0959e-05, -6.9557e-05,\n",
      "        -6.4360e-05, -9.0878e-05,  2.6302e-05,  5.1502e-06, -4.3938e-05,\n",
      "         3.4458e-06,  2.6646e-05, -1.0212e-05,  6.3692e-05, -7.1761e-05,\n",
      "        -1.6549e-05,  3.9415e-05, -1.3493e-05,  8.9883e-05, -9.0031e-06,\n",
      "         7.2367e-05, -5.5906e-06,  9.8134e-05,  7.7220e-05,  1.1673e-05,\n",
      "         5.6336e-05, -7.3314e-05,  4.9734e-05, -2.5503e-05,  5.4836e-05,\n",
      "         5.0325e-05,  2.9982e-05, -7.8960e-06,  5.4576e-07,  1.6749e-05,\n",
      "        -2.1326e-06,  1.5394e-05, -5.4661e-05, -3.1666e-05,  8.2694e-05,\n",
      "         1.6310e-05,  4.5023e-05, -2.1146e-05,  2.5974e-05,  1.2571e-04,\n",
      "         7.9251e-05,  3.2403e-05, -7.8631e-06,  3.4726e-05,  5.2049e-05,\n",
      "        -8.2033e-06, -1.2677e-05,  4.2434e-05, -4.9433e-05, -2.8428e-06,\n",
      "        -9.8566e-07,  1.8863e-05, -3.1498e-05, -9.9785e-05, -1.3511e-05,\n",
      "         1.0765e-04,  2.1730e-05, -2.8463e-05,  9.0892e-05,  2.7331e-05,\n",
      "         8.5269e-05,  2.3050e-05,  5.3098e-05, -7.0980e-05, -2.3510e-05,\n",
      "        -1.2857e-05,  1.0863e-05, -5.3063e-06, -7.8367e-06, -1.0878e-04,\n",
      "         3.5928e-05, -6.3754e-06,  4.9698e-05,  3.5297e-06, -8.1989e-05,\n",
      "        -5.9621e-06, -2.9067e-05,  4.5026e-05, -3.8699e-05, -2.0760e-05,\n",
      "        -8.0666e-05,  4.5955e-05,  8.1346e-05, -6.7199e-05,  8.4903e-05,\n",
      "        -1.8859e-05,  3.0821e-05, -3.0473e-05,  4.6394e-05,  4.4254e-05,\n",
      "         8.4315e-05,  3.8547e-05, -3.5908e-05,  5.3642e-05, -1.7187e-06,\n",
      "        -4.4876e-05,  6.4301e-05,  6.1340e-05, -3.0191e-05,  1.2350e-06,\n",
      "        -2.3907e-05,  4.7213e-05,  1.2651e-05,  1.9002e-06,  2.5537e-05,\n",
      "        -3.0227e-05,  2.6115e-05,  1.9169e-05,  3.9899e-06, -9.7097e-05,\n",
      "        -3.5458e-05, -1.0150e-04,  6.2017e-05, -3.9154e-05,  4.9629e-05,\n",
      "        -7.1876e-05, -5.4580e-05,  3.5605e-06, -7.9518e-05,  3.2925e-06,\n",
      "         4.4193e-06,  4.6970e-05, -2.3055e-05, -2.5078e-05,  6.2992e-06,\n",
      "         1.3400e-06, -8.1135e-05, -8.5773e-05, -1.3781e-06, -1.5244e-04,\n",
      "        -4.3297e-05, -4.1073e-05, -2.1206e-05, -7.0002e-05,  3.1881e-06,\n",
      "         1.5699e-05,  5.0433e-05,  3.1496e-05,  9.1400e-06,  4.0417e-06,\n",
      "        -3.1991e-05, -3.3388e-05])), ('postnet.convolutions.2.1.weight', tensor([ 1.0567,  0.3397,  0.1014,  0.1072,  0.1313,  0.0654,  1.0826,  0.1124,\n",
      "         0.1027,  0.0686,  0.1052,  0.0831,  0.1109,  0.1262,  0.3464,  0.1078,\n",
      "         0.0810,  0.0901,  0.1186,  0.0465,  0.4287,  0.4671,  0.0429,  0.0686,\n",
      "         0.0849,  0.1012,  0.1139,  0.9797,  0.0832,  1.0874,  0.2026,  0.1140,\n",
      "         0.8786,  0.0827,  0.0430,  0.1079,  0.1171,  0.0955,  0.1033,  0.1016,\n",
      "         0.5569,  0.0866,  0.0405,  0.0845,  0.2050,  0.0593,  0.0562,  0.7812,\n",
      "         0.1368,  0.5149,  0.0981,  0.0725,  0.0897,  0.0962,  0.0867,  0.1387,\n",
      "         0.1047,  0.1081,  1.0267,  0.0493,  0.0920,  0.0398,  0.0947,  0.0892,\n",
      "         0.0923,  0.0925,  0.1090,  0.0895,  0.1085,  0.0395,  0.0733,  0.0453,\n",
      "         0.1895,  0.1563,  0.1030,  0.0404,  0.0964,  0.1254,  0.1428,  0.3823,\n",
      "         0.1071,  0.9713,  0.1115,  0.0779,  0.0834,  1.0063,  0.1011,  0.0819,\n",
      "         0.0916,  0.6147,  0.0916,  0.1187,  0.0961,  0.1015,  0.0675,  0.2008,\n",
      "         0.1941,  0.1361,  0.1128,  0.0888,  0.1302,  0.1004,  0.1020,  0.0806,\n",
      "         0.0655,  0.0894,  0.1511,  0.0559,  0.1308,  0.0919,  0.3327,  0.3175,\n",
      "         0.0797,  0.0669,  0.2135,  0.0996,  0.0977,  1.1812,  0.4595,  0.1106,\n",
      "         0.0941,  0.1233,  0.0808,  0.0567,  0.0584,  0.1121,  0.0644,  0.0833,\n",
      "         0.0388,  0.0748,  0.0943,  0.1970,  0.1102,  0.0887,  0.0394,  0.0822,\n",
      "         0.2170,  0.8850,  0.1084,  0.5523,  0.0967,  0.1311,  0.0976,  0.0461,\n",
      "         0.0846,  0.0985,  0.1210,  0.0968,  0.0568,  0.1540,  0.0959,  0.0911,\n",
      "         0.2000,  0.0988,  0.4889,  0.0522,  0.1077,  0.1081,  0.1203,  0.0738,\n",
      "         0.0419,  0.5429,  0.1057,  0.0410,  0.1196,  0.1054,  0.1018,  0.0828,\n",
      "         0.0872,  0.0716,  0.1163,  0.1023,  0.0673,  0.0776,  0.0943,  0.3942,\n",
      "         0.1007,  0.1172,  0.1569,  0.1232,  0.1025,  0.0902,  0.0752,  0.2832,\n",
      "         0.0598,  0.1233,  0.2304,  0.3268,  0.1029,  0.0793,  0.4877,  0.0813,\n",
      "         0.1072,  0.0807,  0.1051,  0.5401,  0.1016,  0.1050,  0.0706,  0.0986,\n",
      "         0.1400,  0.1019,  0.0667,  0.0856,  0.0788,  0.0535,  0.0570,  0.1094,\n",
      "         0.0977,  0.0395,  0.0788,  0.2614,  0.0883,  0.0831,  0.0738,  0.0813,\n",
      "         0.0732,  0.1112,  0.0452,  0.2861,  1.0255,  0.0574,  0.1078,  0.1051,\n",
      "         0.1221,  0.0880,  0.2813,  0.1165,  0.0962,  0.1111,  0.0837,  0.0635,\n",
      "         0.0967,  0.0625,  0.0859,  0.0989,  0.0864,  0.0601,  0.0932,  0.1011,\n",
      "         0.0925,  0.0555,  0.3156,  1.4814,  0.0923,  0.0544,  0.1044,  0.0475,\n",
      "         0.1107,  0.0854,  0.0909,  0.0615,  1.0936,  0.1070,  0.0881,  0.0667,\n",
      "         0.0916,  0.0441,  0.1008,  0.1488,  1.0919,  0.0911,  1.2119,  0.0818,\n",
      "         0.0967,  0.1267,  0.0437,  0.1300,  0.5249,  0.2044,  0.0708,  0.1392,\n",
      "         0.0792,  0.0403,  0.1391,  0.0873,  0.0868,  0.1109,  0.0866,  0.0766,\n",
      "         0.0764,  0.1031,  0.1002,  0.0933,  0.2314,  0.0810,  0.0997,  0.6534,\n",
      "         0.1036,  0.0419,  0.0582,  0.4065,  0.0682,  0.1029,  0.0765,  0.0702,\n",
      "         0.1027,  0.0729,  0.1157,  1.0942,  0.1072,  0.0640,  0.0544,  1.0214,\n",
      "         0.2083,  0.0396,  0.0774,  0.0896,  0.1636,  0.0386,  0.0929,  0.1000,\n",
      "         0.2247,  0.2704,  0.1242,  0.1029,  0.1264,  0.0974,  0.0497,  0.1229,\n",
      "         0.3330,  0.2317,  0.0722,  0.1020,  0.2163,  0.1108,  0.0950,  0.1213,\n",
      "         0.0775,  0.0833,  0.1833,  0.0626,  0.1437,  0.0855,  1.0208,  0.1042,\n",
      "         0.0452,  0.0984,  0.0832,  0.0776,  0.1018,  0.0788, -0.0755,  0.0966,\n",
      "         0.0894,  0.3995,  0.1069,  0.0554,  0.1169,  0.1191,  0.0907,  0.1031,\n",
      "         0.1130,  0.0889,  0.0870,  0.9856,  0.0854,  0.1034,  0.5059,  0.1153,\n",
      "         0.3370,  0.1025,  0.0945,  0.0555,  0.2095,  0.2316,  0.2633,  0.0391,\n",
      "         0.1143,  0.0424,  0.0880,  0.0846,  0.1963,  0.0628,  0.0848,  0.0735,\n",
      "         0.0747,  0.4884,  0.0934,  0.1004,  1.0462,  0.0631,  0.2502,  0.1684,\n",
      "         0.0825,  0.1815,  0.1014,  0.1060,  0.0897,  0.0869,  0.0620,  0.0602,\n",
      "         0.0930,  0.1059,  0.0951,  0.1083,  0.1032,  0.1687,  0.0988,  0.0944,\n",
      "         0.5892,  0.1032,  0.1031,  0.0898,  0.0888,  0.0897,  0.1023,  0.1025,\n",
      "         0.1025,  0.0969,  0.0959,  0.1216,  0.3698,  0.8319,  0.6332,  0.0399,\n",
      "         0.0889,  0.4824,  0.9856,  0.1130,  0.9352,  0.5631,  0.1828,  0.4842,\n",
      "         0.0387,  0.0809,  0.0937,  0.0925,  0.0991,  0.0577,  0.0884,  1.1552,\n",
      "         0.3037,  0.0404,  0.0874,  0.0986,  0.0978,  0.0562,  0.0413,  0.0883,\n",
      "         1.0748,  0.1058,  0.0938,  0.1081,  0.0818,  0.0836,  0.0395,  0.1392,\n",
      "         0.1084,  0.0401,  0.0883,  0.5620,  0.6334,  1.0168,  0.1895,  1.0030,\n",
      "         0.0989,  0.0825,  0.0927,  0.6867,  0.0921,  0.2037,  0.0842,  0.1072,\n",
      "         1.1086,  0.1098,  0.0532,  0.1132,  0.0843,  0.6600,  0.0704,  0.0953,\n",
      "         0.1885,  0.0870,  0.1033,  0.4427,  0.0918,  0.0631,  0.0953,  0.0938,\n",
      "         0.0575,  0.0399,  0.1740,  0.0671,  0.0749,  1.0180,  0.1128,  0.1051,\n",
      "         0.0750,  0.1005,  0.2561,  0.0993,  0.1121,  0.0957,  0.0750,  0.0815,\n",
      "         0.3411,  0.1085,  0.1752,  0.1846,  0.0780,  0.1235,  0.1348,  0.0954,\n",
      "         0.1015,  0.0941,  0.2057,  0.0937,  0.1041,  0.1026,  0.1944,  0.1500])), ('postnet.convolutions.2.1.bias', tensor([-1.9320e-01,  7.0870e-03, -1.4821e-04,  1.1877e-03, -1.0949e-04,\n",
      "         1.6540e-04,  2.5961e-01,  1.3483e-04,  2.8643e-04,  1.1662e-04,\n",
      "        -1.0455e-04, -3.0076e-04,  1.3247e-04,  4.1816e-04,  2.7667e-02,\n",
      "         7.4218e-04, -3.1759e-04,  3.8756e-04,  2.8697e-04, -8.0913e-04,\n",
      "        -4.9207e-03,  9.8333e-04,  2.5983e-04, -2.8113e-04, -2.8938e-04,\n",
      "         1.2508e-04,  1.0231e-04,  2.0131e-01,  2.4120e-04, -6.3332e-02,\n",
      "         4.1386e-03,  1.2456e-04, -1.5987e-01,  3.4512e-04,  8.6080e-05,\n",
      "         3.9762e-04, -9.0270e-04,  4.9332e-04, -9.2249e-05,  3.2068e-04,\n",
      "        -1.8099e-02, -2.4068e-05, -1.5178e-04, -2.9286e-04,  3.7780e-03,\n",
      "        -3.9907e-04, -2.1016e-04,  1.8917e-01, -1.6066e-03, -5.8213e-03,\n",
      "        -1.7350e-04, -1.4353e-04, -1.9586e-04,  4.8240e-04,  6.2367e-04,\n",
      "        -1.5231e-03,  3.9661e-04, -3.9488e-04,  2.4391e-01, -7.2536e-05,\n",
      "         1.1844e-03,  2.9616e-04, -5.2482e-04, -3.0937e-04,  5.5688e-04,\n",
      "        -4.1684e-04, -3.1436e-04, -2.4727e-04,  1.3874e-04, -2.0769e-04,\n",
      "         7.8771e-05, -7.7958e-04,  6.9165e-03,  6.3436e-03,  4.7887e-04,\n",
      "        -6.2573e-04, -2.2388e-04, -2.8898e-04,  1.0854e-03, -2.5337e-02,\n",
      "         3.0052e-04,  2.1784e-01, -2.9899e-04, -1.3896e-04, -3.2218e-04,\n",
      "         2.3094e-01, -8.9439e-03,  3.5257e-04, -5.2671e-04,  1.1579e-01,\n",
      "        -5.5067e-05,  1.1346e-04, -4.5238e-04,  7.9656e-05, -7.4736e-04,\n",
      "        -3.2556e-03,  7.4552e-04,  1.0489e-03, -2.4711e-04,  3.3471e-04,\n",
      "        -8.4585e-04, -1.3873e-04,  3.6254e-04,  6.4725e-04,  2.7741e-04,\n",
      "        -6.4625e-04, -1.0722e-03, -9.7335e-05,  9.5177e-04,  3.9446e-04,\n",
      "         3.3985e-03, -1.0557e-02,  3.3120e-04,  4.0923e-04,  1.1068e-02,\n",
      "        -1.8123e-03, -1.2788e-04, -2.5870e-01, -8.8988e-03, -3.6305e-04,\n",
      "        -2.6951e-04, -1.0155e-03, -1.9785e-04,  4.0085e-04, -5.6869e-05,\n",
      "         1.2927e-03, -4.7068e-04,  1.6694e-05,  2.0851e-04,  5.5814e-04,\n",
      "         1.1046e-04, -2.6733e-03, -2.7357e-04, -5.8544e-04,  2.2635e-04,\n",
      "        -2.7095e-04, -6.2818e-03, -1.9570e-01, -7.7886e-05, -1.1833e-02,\n",
      "         5.2620e-04, -5.1026e-04, -2.4755e-04,  2.2882e-05, -1.2874e-04,\n",
      "        -5.5680e-04,  9.2593e-04, -4.8329e-04,  4.4271e-04, -3.0506e-04,\n",
      "        -1.3998e-05, -1.2564e-04,  4.2021e-03,  5.3092e-04, -1.0689e-02,\n",
      "         3.1793e-05,  2.6751e-04, -1.0607e-03, -2.0280e-04, -1.0049e-04,\n",
      "        -7.7718e-04, -6.0600e-02,  3.9256e-04, -4.2738e-04, -2.1502e-04,\n",
      "         7.1468e-05, -2.4677e-05,  3.9160e-05, -2.5490e-04, -4.2326e-04,\n",
      "        -4.0450e-04,  4.8443e-04, -2.3327e-04,  8.4812e-05, -6.0869e-04,\n",
      "         1.5274e-04, -5.1308e-04, -1.9352e-04,  1.0003e-04, -4.5953e-04,\n",
      "        -3.4705e-05,  6.9317e-05, -2.7816e-04, -3.3390e-03, -3.0952e-04,\n",
      "         3.9322e-04,  1.6600e-02,  1.1439e-02,  1.0174e-05, -1.2177e-04,\n",
      "        -3.1384e-02, -2.5419e-04,  1.5260e-03, -4.1030e-04, -9.5519e-05,\n",
      "         6.2087e-02, -2.3209e-04,  3.0110e-04,  6.4293e-04,  5.9157e-05,\n",
      "         1.4012e-03,  7.5676e-04, -6.7551e-05, -9.4415e-05, -4.4809e-04,\n",
      "         6.3412e-04,  2.1446e-04, -8.9299e-04, -7.3310e-04,  1.5831e-04,\n",
      "        -5.5929e-05, -3.0283e-04,  4.9961e-04, -2.8240e-04,  7.6780e-04,\n",
      "        -9.2885e-04,  6.6145e-05,  1.5310e-04,  3.1201e-04,  3.1170e-03,\n",
      "         8.0844e-03, -2.6464e-04, -1.7317e-04, -4.8332e-05,  1.2945e-05,\n",
      "         5.2763e-04, -5.4160e-03, -9.7031e-06, -7.1496e-04, -1.9000e-04,\n",
      "        -4.1437e-05,  2.4953e-04, -1.9004e-04, -3.7099e-04, -5.3016e-04,\n",
      "         5.4038e-04, -1.2418e-03, -3.1490e-04,  7.5425e-04, -5.4442e-05,\n",
      "         1.3068e-03, -9.9129e-06, -5.6211e-03,  1.4012e-01,  9.8208e-05,\n",
      "         2.6080e-04, -6.2631e-04, -2.8577e-04,  5.6933e-04, -6.9665e-04,\n",
      "         3.4109e-04,  1.9132e-04, -2.5108e-02, -1.4477e-04,  3.1372e-04,\n",
      "         4.4040e-04, -6.3084e-04, -1.3351e-04, -2.6862e-04,  1.0480e-03,\n",
      "        -1.4101e-01, -3.6848e-04, -4.0106e-03,  2.0509e-04, -8.8843e-05,\n",
      "         1.3775e-03, -2.8359e-04, -8.1976e-04, -1.2531e-02,  1.8963e-03,\n",
      "        -7.9005e-05, -5.6000e-05,  1.2808e-04,  2.4081e-05, -7.0079e-04,\n",
      "        -1.5473e-04, -6.5760e-04, -8.7823e-05,  4.4040e-04, -9.2597e-04,\n",
      "         1.7850e-04, -7.9202e-04, -2.3871e-03, -6.5584e-04,  3.1413e-03,\n",
      "         6.5810e-04,  4.6213e-04, -7.3288e-03,  2.8647e-05, -3.0887e-05,\n",
      "        -3.0882e-04,  1.3907e-03,  4.5197e-05, -1.5789e-04,  4.3688e-04,\n",
      "        -3.4081e-04,  7.4383e-05, -6.6694e-05,  4.4455e-04, -2.7712e-01,\n",
      "        -7.7382e-04, -1.3396e-04, -1.9333e-04,  1.5465e-01,  3.1557e-03,\n",
      "         1.5786e-04,  1.1094e-04,  7.4481e-04,  1.9092e-03,  5.6742e-05,\n",
      "         2.8120e-04,  6.2416e-04, -1.6115e-02, -3.8884e-02, -1.0209e-05,\n",
      "        -1.6791e-04,  6.6669e-03,  1.5037e-04,  2.9128e-04,  3.9741e-04,\n",
      "        -9.0384e-03, -1.1534e-02, -5.8685e-05,  8.5000e-04, -3.9322e-03,\n",
      "        -1.7243e-04,  1.5463e-04,  7.9441e-04,  2.1558e-04,  3.1243e-04,\n",
      "        -3.8937e-03, -8.5554e-05,  2.3926e-03,  3.4517e-04, -1.9088e-01,\n",
      "         3.2697e-04,  3.7073e-04, -6.4697e-04,  1.7441e-04, -3.7449e-04,\n",
      "         2.5225e-05, -5.4420e-04,  8.3822e-04, -3.7671e-04,  8.7826e-04,\n",
      "        -6.1633e-03,  1.6741e-03, -1.2325e-04, -5.5107e-04, -2.4529e-04,\n",
      "        -2.4514e-05, -3.4996e-04,  4.6293e-04, -1.7684e-04, -5.5383e-04,\n",
      "        -2.2192e-01,  5.7787e-05, -8.2611e-05,  9.6627e-02,  4.1764e-04,\n",
      "         3.7854e-02, -1.3727e-04,  1.3687e-04, -5.7140e-04, -4.8990e-03,\n",
      "        -8.4707e-03, -6.6969e-03,  3.2354e-04,  6.7660e-04, -5.4170e-04,\n",
      "         1.3802e-03, -5.0017e-04,  8.3019e-03,  3.9922e-04,  4.4785e-04,\n",
      "        -1.6162e-04, -2.4955e-04, -1.0179e-01,  8.6541e-04,  3.0174e-04,\n",
      "        -2.4819e-01,  3.2540e-04, -2.5376e-03,  9.6462e-03,  3.2524e-04,\n",
      "         3.6585e-04, -1.8808e-04, -3.7846e-04,  3.6041e-04,  6.5177e-04,\n",
      "        -3.6270e-04,  1.1727e-04, -4.6525e-04,  2.9620e-03, -3.1413e-04,\n",
      "         2.4115e-04, -2.9328e-04,  7.3002e-03, -3.6351e-04,  3.6474e-04,\n",
      "         1.3856e-01,  6.8378e-05, -4.9307e-04, -1.8175e-04, -5.1455e-04,\n",
      "        -2.7514e-04, -2.5624e-04, -4.4852e-04,  3.7283e-05,  3.4223e-04,\n",
      "        -7.1420e-04,  1.0068e-03,  1.7411e-03,  5.1752e-01, -2.0389e-02,\n",
      "         9.4806e-05, -1.5712e-07, -3.5873e-04,  2.3169e-01, -3.6081e-05,\n",
      "         2.1841e-01,  2.4733e-02,  5.2865e-03, -4.9406e-02,  3.1066e-04,\n",
      "        -2.2808e-04, -1.5718e-04, -5.1094e-04, -2.2252e-04,  3.1951e-05,\n",
      "        -2.9734e-05, -1.0221e-01,  7.2612e-03,  4.6982e-04,  4.0686e-05,\n",
      "        -1.1843e-03,  3.9217e-04, -4.8663e-04, -6.4933e-04,  1.2258e-04,\n",
      "        -2.4430e-01,  7.4183e-04, -3.4565e-04,  2.7810e-04, -5.9857e-04,\n",
      "        -5.2124e-04,  4.2852e-05,  7.4882e-04, -5.2661e-04, -5.5842e-04,\n",
      "        -1.1548e-04,  2.2494e-02,  1.0412e-01, -2.2023e-01,  5.5926e-03,\n",
      "         1.8522e-01,  5.6963e-04,  7.1057e-04,  5.7724e-04, -3.0486e-02,\n",
      "         3.4600e-04,  2.8959e-03, -2.0994e-04, -2.2170e-05, -2.3656e-01,\n",
      "         8.5345e-04,  7.1364e-05, -7.8785e-04, -4.7037e-04, -1.8835e-01,\n",
      "        -6.4939e-04, -1.7116e-04, -4.3211e-03, -6.5647e-05,  4.8817e-04,\n",
      "        -5.5830e-02,  1.4878e-04,  3.0371e-04,  4.4180e-05, -6.7318e-04,\n",
      "        -2.7034e-06, -1.6441e-04, -8.4762e-04,  1.2630e-03,  2.3630e-03,\n",
      "        -2.5524e-01, -5.9614e-04, -1.4948e-04, -4.9914e-04, -3.7765e-04,\n",
      "        -1.5439e-02, -7.2397e-04,  1.4649e-04, -2.9128e-05, -6.3217e-04,\n",
      "         7.3291e-04,  9.8689e-04, -2.0519e-04,  5.2825e-03, -5.4588e-03,\n",
      "         3.7978e-05,  1.5509e-03, -9.9910e-05, -1.8260e-04, -5.7455e-07,\n",
      "        -4.6386e-05, -8.3725e-05,  9.4561e-04,  1.6282e-04, -1.2748e-04,\n",
      "        -1.0890e-02,  2.4333e-03])), ('postnet.convolutions.2.1.running_mean', tensor([ 3.4021e-02,  1.9620e-03,  3.5776e-03, -7.9227e-05, -5.5632e-03,\n",
      "        -4.9595e-04, -9.1427e-03,  9.6796e-04,  1.3807e-03,  9.8536e-03,\n",
      "        -1.0942e-02, -5.8469e-03, -3.6932e-03, -1.0312e-02, -1.0669e-02,\n",
      "        -3.7659e-03,  1.7015e-03, -1.1543e-03,  2.8988e-03, -1.5125e-02,\n",
      "        -2.9583e-03, -2.4868e-03,  1.5084e-04, -5.8864e-03,  1.9137e-03,\n",
      "        -5.7260e-03,  3.8820e-03, -1.5240e-02,  3.2029e-03,  1.2957e-02,\n",
      "        -8.0894e-05,  9.3947e-03,  9.4700e-03, -2.5103e-03,  9.6981e-05,\n",
      "        -3.8353e-04, -2.7871e-03, -8.2289e-04, -1.5585e-03, -2.3524e-03,\n",
      "        -1.6293e-03,  2.1830e-03,  1.1341e-03,  1.1069e-02,  5.7723e-02,\n",
      "         1.3747e-04,  5.5201e-03, -2.7980e-03, -1.0284e-03,  1.7245e-03,\n",
      "        -4.0139e-03, -9.1753e-04,  1.8382e-03, -2.0920e-03, -6.0559e-03,\n",
      "        -4.5766e-04,  1.0986e-03, -3.0564e-03, -1.9058e-02,  2.5776e-03,\n",
      "         3.1721e-03,  4.4439e-03, -1.8608e-03,  1.1240e-03, -1.1407e-03,\n",
      "        -4.6437e-03,  3.5167e-03,  2.6865e-03, -1.9589e-03,  1.9088e-03,\n",
      "         9.8948e-04, -1.0981e-02,  1.8148e-02,  9.2751e-04,  4.4138e-03,\n",
      "         1.3367e-03,  5.5589e-03, -1.9093e-03,  1.7708e-03,  8.4478e-03,\n",
      "        -2.9706e-03, -2.6413e-02,  3.9688e-03,  4.0599e-03,  2.1959e-03,\n",
      "        -2.1439e-02,  2.1889e-02,  1.4496e-03, -4.1492e-04, -1.5998e-02,\n",
      "         1.9561e-03,  3.3627e-03, -4.7377e-04, -2.1583e-03, -4.5062e-04,\n",
      "        -1.1962e-02,  9.4918e-03, -2.2440e-03, -1.8654e-03, -2.7732e-04,\n",
      "         2.5406e-02, -1.4263e-03,  6.0618e-03,  2.4920e-03,  4.4112e-04,\n",
      "         1.8516e-03,  3.6998e-03,  1.1370e-02, -1.9599e-03, -1.1385e-03,\n",
      "         8.0384e-03, -6.1161e-03, -1.7569e-05,  6.1238e-03, -2.3833e-02,\n",
      "         1.1659e-02, -1.6457e-03,  4.1572e-02, -7.8803e-03,  1.7409e-02,\n",
      "         4.6177e-03, -9.0474e-03, -3.9437e-03, -3.7682e-03,  7.3355e-04,\n",
      "         1.4648e-04, -4.6844e-03, -3.9899e-03,  1.0789e-03,  7.0327e-03,\n",
      "        -7.0456e-04, -9.7604e-03,  4.4767e-04, -1.3526e-03, -7.2435e-04,\n",
      "         1.0767e-03,  4.8242e-03,  2.7769e-02, -4.1985e-02, -3.0804e-03,\n",
      "         8.8189e-05,  4.7044e-02, -4.5432e-04, -9.6317e-03, -3.8371e-03,\n",
      "         6.5155e-03,  5.2527e-03,  7.7114e-04,  1.9874e-03, -9.9532e-03,\n",
      "        -1.9393e-04, -4.3540e-03,  9.0963e-04,  3.3823e-03, -6.7677e-03,\n",
      "         1.1244e-03, -4.0590e-04,  7.7284e-03,  4.2039e-03,  1.2398e-03,\n",
      "        -3.2223e-03,  1.4683e-02,  4.9039e-04,  1.1292e-04,  9.6686e-04,\n",
      "         4.2715e-03, -3.8489e-03,  5.1567e-03, -7.1211e-04, -6.2434e-03,\n",
      "         3.5678e-03, -1.8564e-02, -1.8363e-03,  4.2467e-03,  5.2238e-04,\n",
      "         1.7872e-03,  1.1456e-02,  5.6051e-03,  5.1889e-03, -2.2663e-03,\n",
      "        -6.3662e-03, -1.0292e-03,  6.1637e-05, -2.1358e-02,  1.9439e-03,\n",
      "        -3.8222e-04,  3.9586e-02,  9.7398e-02,  1.7222e-03,  2.1337e-03,\n",
      "        -3.7650e-04, -4.4936e-03,  3.5708e-04, -4.7081e-03,  2.8747e-03,\n",
      "         2.9371e-02, -2.5862e-03,  2.4323e-03, -2.3606e-03, -4.5962e-04,\n",
      "        -7.2914e-03,  7.7465e-04,  7.1626e-03,  1.9156e-03, -5.5794e-03,\n",
      "         8.0173e-03,  1.6520e-03,  3.4341e-03, -1.3378e-02, -3.6105e-03,\n",
      "         5.0221e-03,  3.9074e-03, -7.3110e-04, -1.3799e-02, -5.5907e-05,\n",
      "        -1.3425e-04, -6.5090e-03, -1.1964e-03,  2.9320e-03, -6.6281e-03,\n",
      "         9.3757e-03, -7.3734e-04,  2.3282e-03,  6.7541e-04, -2.5560e-04,\n",
      "         1.1283e-04,  4.0021e-02, -1.4125e-03, -4.1884e-03,  2.2509e-03,\n",
      "        -1.5630e-03,  2.7795e-03,  1.2436e-03,  4.7068e-03,  2.5725e-03,\n",
      "         1.4442e-03, -9.5846e-04, -5.6217e-03, -1.1895e-03, -5.5443e-04,\n",
      "         1.0662e-02,  4.0456e-03, -4.0286e-03, -1.6165e-03,  1.0558e-03,\n",
      "         9.1924e-03, -1.5341e-03,  7.8300e-03,  5.2567e-04,  1.2817e-03,\n",
      "         3.2017e-03, -5.2962e-03, -5.2578e-03,  3.6398e-03,  2.9111e-04,\n",
      "         2.7798e-04, -8.6137e-04, -1.2532e-03,  5.2013e-03,  2.2648e-03,\n",
      "         7.5557e-03, -1.0655e-03,  5.7464e-03, -6.2516e-03, -1.5753e-03,\n",
      "        -6.5471e-04,  1.5355e-03, -2.1642e-03, -9.2265e-03,  4.0262e-03,\n",
      "         4.1390e-03,  1.4429e-02, -4.7149e-03, -1.9930e-04, -4.9347e-03,\n",
      "         4.0767e-03, -9.2796e-03,  1.0570e-03, -2.2412e-04, -2.7460e-03,\n",
      "         4.0263e-03,  3.7471e-03,  4.2351e-02, -2.1347e-03, -3.8469e-03,\n",
      "         5.1655e-03, -2.4092e-03, -3.6623e-03,  6.5360e-04,  6.9492e-04,\n",
      "        -8.0485e-03, -1.1389e-03,  2.0149e-03,  1.3720e-03, -1.2194e-05,\n",
      "        -5.9253e-04, -1.8110e-02, -2.4975e-03,  4.2670e-04,  2.8845e-02,\n",
      "        -6.5135e-04,  2.9865e-03,  1.7476e-03, -1.3480e-02,  9.4729e-03,\n",
      "         2.1649e-03,  2.6885e-03,  8.0199e-03, -3.2516e-03, -1.9356e-03,\n",
      "         2.3655e-03, -7.4659e-04,  1.9959e-02,  2.3291e-02, -3.5108e-03,\n",
      "        -8.3170e-03, -2.5064e-02, -2.3863e-03,  2.1803e-03,  5.6492e-03,\n",
      "         8.1366e-03, -6.5534e-03,  2.0796e-05, -3.5793e-03, -2.4462e-03,\n",
      "        -1.7883e-04, -2.1611e-04, -2.7721e-03, -2.3421e-03, -1.0520e-03,\n",
      "        -3.1774e-02,  1.6548e-03,  4.5835e-03, -3.6109e-03,  7.8712e-03,\n",
      "        -1.3668e-04,  1.0203e-02, -1.3268e-03,  3.5439e-04,  3.8827e-03,\n",
      "        -8.9051e-03,  6.7532e-04, -2.4357e-03, -3.8194e-03, -2.0129e-03,\n",
      "        -4.6445e-04,  5.2928e-03,  1.5647e-03,  4.0663e-03, -3.5318e-02,\n",
      "         2.7908e-04,  3.9217e-03,  2.6876e-03,  2.8133e-03, -4.3179e-03,\n",
      "         2.5614e-02, -1.6414e-02, -2.1243e-03, -1.7855e-03,  2.6032e-03,\n",
      "        -1.2215e-02, -8.2017e-04,  3.2723e-03, -7.3921e-04, -4.2113e-02,\n",
      "        -4.4246e-03, -2.1567e-02, -2.4573e-03,  1.2942e-03,  1.9428e-03,\n",
      "        -6.4926e-04, -5.9600e-04,  1.0171e-02, -1.5817e-03,  3.0497e-03,\n",
      "         4.2155e-03,  2.7408e-03,  2.8956e-02,  1.5234e-03,  1.3826e-03,\n",
      "         2.8846e-02, -1.0695e-03, -2.4152e-02,  2.2803e-02,  5.5372e-03,\n",
      "        -1.0730e-02,  1.1946e-03, -1.6284e-03, -3.8073e-03, -1.4073e-03,\n",
      "         1.0582e-02, -5.0112e-04,  6.3500e-04,  7.4685e-02, -1.0194e-03,\n",
      "        -1.5012e-02, -1.0512e-03, -3.6955e-02,  1.1541e-03,  3.7474e-04,\n",
      "        -3.8240e-02, -1.6906e-04, -9.5387e-04, -3.2910e-03, -6.3839e-03,\n",
      "        -1.3018e-03,  5.3061e-03,  1.0389e-04,  3.9984e-04,  1.7053e-03,\n",
      "        -1.3183e-02,  5.2139e-02,  3.7550e-03, -5.5868e-03, -6.5360e-03,\n",
      "         2.4347e-03,  1.4042e-04,  1.6337e-04, -3.1696e-02,  3.3165e-04,\n",
      "        -2.3964e-02,  3.6206e-03,  7.4071e-03, -1.0473e-02, -1.5112e-03,\n",
      "         5.0169e-03, -1.3402e-03,  4.6296e-03, -7.0419e-04, -2.4193e-03,\n",
      "         2.4856e-03,  5.2601e-03,  1.0980e-02, -5.0368e-04, -1.8329e-03,\n",
      "         1.8756e-03, -1.8410e-03, -6.0513e-03,  8.9893e-04,  4.2780e-03,\n",
      "         3.0248e-02,  1.6077e-03, -1.6632e-03, -3.9340e-03, -4.8343e-03,\n",
      "        -1.2400e-02, -2.2813e-03,  1.3819e-02, -2.5743e-03,  1.3482e-04,\n",
      "         1.3846e-03,  9.5837e-05, -1.5820e-02,  1.2031e-02,  7.8645e-03,\n",
      "        -1.1477e-02,  3.5632e-03,  4.7349e-03,  2.1056e-03,  7.3455e-03,\n",
      "        -3.6288e-03, -2.6480e-03,  4.9486e-03,  1.7861e-04,  1.6440e-02,\n",
      "        -2.2507e-04,  9.3915e-04,  7.6978e-05,  3.1502e-03, -6.0824e-02,\n",
      "        -1.5792e-03, -4.4195e-03, -8.5884e-04, -1.7014e-03, -3.3996e-03,\n",
      "         1.0079e-02, -1.5805e-03,  5.1770e-03, -3.5331e-03,  1.6590e-03,\n",
      "         3.3718e-04, -1.1380e-03,  5.7852e-03, -5.3163e-03, -8.1432e-03,\n",
      "         2.2010e-02,  1.0646e-02, -2.1405e-03, -3.0725e-03, -1.6844e-03,\n",
      "        -1.1576e-02,  1.4065e-02,  2.3793e-03, -4.3140e-03, -1.1090e-03,\n",
      "         6.9541e-03,  1.2642e-02, -2.0621e-03,  1.3801e-02,  6.8506e-03,\n",
      "        -2.2518e-03, -7.3106e-03, -1.2313e-02, -3.8577e-04, -5.6672e-04,\n",
      "         2.1502e-03, -1.4180e-02,  2.2680e-03, -3.0566e-03,  2.6097e-03,\n",
      "        -8.3797e-03,  6.6234e-03])), ('postnet.convolutions.2.1.running_var', tensor([0.0600, 0.0507, 0.0116, 0.0185, 0.0196, 0.0157, 0.0399, 0.0189, 0.0118,\n",
      "        0.0412, 0.0318, 0.0194, 0.0111, 0.0116, 0.0935, 0.0157, 0.0116, 0.0125,\n",
      "        0.0207, 0.0615, 0.0556, 0.0679, 0.0321, 0.0329, 0.0144, 0.0156, 0.0169,\n",
      "        0.0368, 0.0145, 0.0452, 0.0462, 0.0191, 0.0309, 0.0212, 0.0326, 0.0181,\n",
      "        0.0514, 0.0148, 0.0126, 0.0119, 0.0573, 0.0142, 0.0362, 0.0258, 0.1005,\n",
      "        0.0334, 0.0326, 0.0548, 0.0264, 0.0617, 0.0191, 0.0266, 0.0117, 0.0184,\n",
      "        0.0308, 0.0422, 0.0118, 0.0134, 0.0467, 0.0375, 0.0135, 0.0423, 0.0231,\n",
      "        0.0122, 0.0110, 0.0131, 0.0153, 0.0120, 0.0156, 0.0352, 0.0253, 0.0509,\n",
      "        0.0544, 0.0277, 0.0118, 0.0343, 0.0139, 0.0109, 0.0307, 0.0310, 0.0134,\n",
      "        0.0493, 0.0105, 0.0315, 0.0114, 0.0361, 0.0227, 0.0123, 0.0111, 0.0343,\n",
      "        0.0120, 0.0178, 0.0133, 0.0199, 0.0206, 0.0548, 0.0346, 0.0242, 0.0133,\n",
      "        0.0131, 0.0748, 0.0144, 0.0159, 0.0136, 0.0314, 0.0147, 0.0360, 0.0493,\n",
      "        0.0243, 0.0223, 0.0252, 0.0395, 0.0117, 0.0418, 0.0320, 0.0890, 0.0114,\n",
      "        0.0866, 0.0702, 0.0383, 0.0136, 0.0355, 0.0362, 0.0307, 0.0307, 0.0109,\n",
      "        0.0239, 0.0122, 0.0211, 0.0355, 0.0126, 0.0531, 0.0127, 0.0114, 0.0208,\n",
      "        0.0147, 0.0416, 0.0511, 0.1006, 0.0721, 0.0124, 0.1141, 0.0140, 0.0485,\n",
      "        0.0125, 0.0169, 0.0201, 0.0144, 0.0146, 0.0356, 0.0292, 0.0121, 0.0494,\n",
      "        0.0146, 0.0584, 0.0278, 0.0122, 0.0367, 0.0193, 0.0147, 0.0383, 0.0243,\n",
      "        0.0148, 0.0189, 0.0152, 0.0102, 0.0143, 0.0114, 0.0118, 0.0160, 0.0240,\n",
      "        0.0282, 0.0194, 0.0150, 0.0137, 0.0638, 0.0240, 0.0157, 0.0254, 0.0765,\n",
      "        0.0208, 0.0127, 0.0135, 0.0741, 0.0204, 0.0119, 0.0712, 0.0962, 0.0255,\n",
      "        0.0119, 0.0598, 0.0119, 0.0214, 0.0118, 0.0169, 0.0706, 0.0193, 0.0124,\n",
      "        0.0126, 0.0107, 0.0336, 0.0133, 0.0431, 0.0130, 0.0257, 0.0421, 0.0184,\n",
      "        0.0114, 0.0242, 0.0396, 0.0336, 0.0650, 0.0130, 0.0290, 0.0276, 0.0132,\n",
      "        0.0271, 0.0099, 0.0428, 0.0528, 0.0371, 0.0169, 0.0237, 0.0115, 0.0130,\n",
      "        0.0139, 0.0454, 0.0210, 0.0112, 0.0163, 0.0135, 0.0164, 0.0110, 0.0289,\n",
      "        0.0122, 0.0136, 0.0122, 0.0368, 0.0115, 0.0115, 0.0783, 0.0332, 0.0491,\n",
      "        0.0992, 0.0142, 0.0460, 0.0130, 0.0471, 0.0212, 0.0123, 0.0126, 0.0323,\n",
      "        0.0515, 0.0142, 0.0212, 0.0360, 0.0115, 0.0314, 0.0378, 0.0386, 0.0629,\n",
      "        0.0117, 0.0822, 0.0252, 0.0224, 0.0304, 0.0333, 0.0203, 0.0823, 0.0480,\n",
      "        0.0278, 0.0376, 0.0170, 0.0338, 0.0218, 0.0190, 0.0283, 0.0128, 0.0112,\n",
      "        0.0377, 0.0278, 0.0114, 0.0934, 0.0108, 0.0512, 0.0331, 0.0108, 0.0408,\n",
      "        0.0112, 0.0328, 0.0372, 0.0739, 0.0148, 0.0157, 0.0266, 0.0360, 0.0421,\n",
      "        0.0136, 0.0111, 0.0467, 0.0181, 0.0199, 0.0158, 0.0663, 0.0500, 0.0383,\n",
      "        0.0263, 0.0144, 0.0353, 0.0410, 0.0140, 0.0229, 0.0244, 0.0684, 0.0190,\n",
      "        0.0262, 0.0440, 0.0112, 0.0384, 0.0224, 0.0232, 0.0334, 0.0128, 0.0190,\n",
      "        0.0439, 0.0205, 0.0132, 0.0155, 0.0196, 0.0111, 0.0560, 0.0323, 0.0377,\n",
      "        0.0145, 0.0358, 0.0124, 0.0517, 0.0131, 0.0165, 0.0661, 0.0242, 0.0210,\n",
      "        0.0115, 0.0105, 0.0115, 0.0204, 0.0230, 0.0279, 0.0313, 0.0373, 0.0142,\n",
      "        0.0122, 0.0125, 0.0115, 0.0121, 0.0499, 0.0374, 0.0123, 0.0806, 0.0109,\n",
      "        0.0301, 0.0168, 0.0119, 0.0155, 0.0364, 0.0580, 0.0470, 0.0366, 0.0110,\n",
      "        0.0511, 0.0224, 0.0117, 0.0566, 0.0168, 0.0211, 0.0162, 0.0130, 0.0658,\n",
      "        0.0126, 0.0125, 0.0415, 0.0193, 0.0910, 0.0448, 0.0128, 0.0391, 0.0168,\n",
      "        0.0120, 0.0151, 0.0131, 0.0410, 0.0407, 0.0130, 0.1037, 0.0161, 0.0428,\n",
      "        0.0146, 0.0584, 0.0130, 0.0137, 0.0630, 0.0123, 0.0189, 0.0137, 0.0241,\n",
      "        0.0118, 0.0129, 0.0112, 0.0161, 0.0266, 0.0307, 0.0981, 0.0586, 0.0715,\n",
      "        0.0647, 0.0197, 0.0117, 0.0578, 0.0500, 0.0199, 0.0332, 0.0310, 0.0577,\n",
      "        0.0371, 0.0373, 0.0125, 0.0126, 0.0119, 0.0144, 0.0219, 0.0243, 0.0712,\n",
      "        0.0666, 0.0345, 0.0166, 0.0142, 0.0125, 0.0398, 0.0297, 0.0177, 0.0464,\n",
      "        0.0244, 0.0129, 0.0109, 0.0157, 0.0631, 0.0426, 0.0330, 0.0128, 0.0359,\n",
      "        0.0109, 0.0305, 0.0375, 0.0386, 0.0445, 0.0310, 0.0121, 0.0157, 0.0143,\n",
      "        0.0323, 0.0131, 0.0451, 0.0125, 0.0115, 0.0358, 0.0132, 0.0266, 0.0121,\n",
      "        0.0155, 0.1049, 0.0221, 0.0137, 0.0301, 0.0125, 0.0149, 0.0384, 0.0353,\n",
      "        0.0364, 0.0127, 0.0133, 0.0276, 0.0232, 0.0524, 0.0178, 0.0177, 0.0389,\n",
      "        0.0217, 0.0129, 0.0314, 0.0145, 0.0515, 0.0417, 0.0110, 0.0113, 0.0112,\n",
      "        0.0181, 0.0578, 0.0107, 0.0332, 0.0375, 0.0277, 0.0441, 0.0421, 0.0126,\n",
      "        0.0126, 0.0119, 0.0719, 0.0117, 0.0179, 0.0123, 0.0383, 0.0336])), ('postnet.convolutions.2.1.num_batches_tracked', tensor(18012)), ('postnet.convolutions.3.0.conv.weight', tensor([[[ 1.0699e-03, -3.1975e-03, -1.0606e-04, -6.3052e-04, -8.2263e-04],\n",
      "         [ 6.3245e-04,  1.7102e-03,  4.2286e-04, -1.1898e-03, -1.8420e-03],\n",
      "         [-8.3759e-03,  7.9765e-03,  3.5786e-04,  4.5956e-03,  5.4759e-03],\n",
      "         ...,\n",
      "         [-3.6477e-03,  6.4219e-03,  1.5591e-03, -9.7563e-03, -8.6034e-04],\n",
      "         [-7.1382e-04, -2.9048e-03, -1.4788e-03, -5.8904e-04,  7.2935e-03],\n",
      "         [ 9.8953e-05,  1.9482e-03,  2.2124e-03,  3.8058e-03,  5.4185e-03]],\n",
      "\n",
      "        [[ 3.5674e-05, -2.5573e-03,  6.9063e-05, -2.2964e-03,  2.0530e-03],\n",
      "         [-2.0320e-03, -5.3497e-03, -1.1959e-02, -2.7988e-03, -1.2864e-03],\n",
      "         [ 5.7093e-03,  5.6796e-03,  1.4021e-02, -9.9508e-04,  2.7161e-03],\n",
      "         ...,\n",
      "         [-3.8628e-03, -4.3391e-03,  2.1829e-03, -7.2734e-03,  1.7877e-03],\n",
      "         [ 2.9504e-03, -1.1449e-02, -1.1576e-02,  1.7859e-03,  1.1495e-03],\n",
      "         [-9.7477e-03,  1.1630e-03,  9.7851e-03,  3.6344e-02,  1.8818e-02]],\n",
      "\n",
      "        [[ 1.4440e-03, -3.1934e-03, -2.2136e-03,  2.3615e-03,  1.5591e-03],\n",
      "         [-1.5817e-05,  1.0228e-03,  1.9599e-03, -1.0014e-03, -1.4298e-03],\n",
      "         [ 3.4853e-03, -1.0219e-02,  7.5300e-03, -1.1910e-03, -2.9573e-03],\n",
      "         ...,\n",
      "         [-3.2023e-03, -1.3473e-03,  1.3394e-02,  2.0691e-03, -3.8792e-03],\n",
      "         [ 5.1676e-05, -3.9705e-04,  2.4501e-04,  2.3102e-03,  4.6329e-04],\n",
      "         [-4.8051e-04,  1.8149e-03,  2.3022e-03, -3.3133e-03, -3.9268e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.6214e-04,  5.0821e-04, -2.4067e-03, -1.2528e-03, -7.4165e-04],\n",
      "         [ 1.3303e-02,  8.9233e-03,  4.0073e-03, -1.4617e-05, -3.4666e-03],\n",
      "         [-9.3519e-03, -1.2390e-02, -7.7453e-03, -2.6486e-03, -1.1244e-03],\n",
      "         ...,\n",
      "         [ 2.8817e-03,  4.2277e-03,  6.5092e-03,  3.1735e-03,  3.6092e-03],\n",
      "         [-4.3432e-03,  8.0267e-04, -3.8248e-03, -1.6375e-03,  6.2873e-03],\n",
      "         [ 5.5664e-03, -2.3896e-03, -7.5040e-03, -9.9322e-03, -7.8928e-03]],\n",
      "\n",
      "        [[-7.2626e-03, -1.6481e-03,  1.2832e-04,  1.3866e-03, -2.6688e-04],\n",
      "         [ 2.9568e-03,  2.2447e-03, -1.2774e-03, -5.6804e-03, -4.5785e-03],\n",
      "         [ 1.4839e-03,  6.2749e-03, -5.3277e-03,  3.3451e-03,  9.6575e-04],\n",
      "         ...,\n",
      "         [ 5.5507e-04, -1.3758e-03, -1.0808e-03, -1.5244e-03,  2.2480e-03],\n",
      "         [-1.6235e-03, -5.5995e-04, -3.7011e-03,  5.5528e-04,  1.9860e-03],\n",
      "         [-2.2599e-03,  7.8530e-03,  1.3638e-02,  1.2794e-02,  1.4232e-02]],\n",
      "\n",
      "        [[ 5.7809e-03,  5.6420e-03,  4.4266e-05, -1.2446e-03,  2.1340e-03],\n",
      "         [-2.1680e-03, -3.8694e-03, -1.3935e-03,  1.7485e-03,  9.3126e-04],\n",
      "         [ 6.5294e-03, -3.2690e-03, -8.6288e-04,  3.1510e-03,  4.1506e-03],\n",
      "         ...,\n",
      "         [ 2.9929e-03,  3.9959e-03,  4.1002e-04, -1.0989e-03,  6.9892e-03],\n",
      "         [ 8.4618e-03,  8.2615e-03,  4.4428e-03,  3.1365e-03, -1.1859e-03],\n",
      "         [-4.1710e-05, -3.7708e-03, -2.2132e-05,  2.9094e-03, -2.0195e-03]]])), ('postnet.convolutions.3.0.conv.bias', tensor([ 5.3300e-05, -5.3076e-05,  6.5017e-05, -6.1440e-05,  5.1526e-05,\n",
      "        -1.3484e-05,  4.4555e-05, -3.3964e-05,  5.3120e-05, -8.8390e-05,\n",
      "         1.9430e-05,  6.5031e-05,  8.8089e-05,  2.3734e-05,  1.5421e-05,\n",
      "        -1.1877e-05,  2.8580e-05, -5.3679e-05,  3.2182e-05, -4.6473e-05,\n",
      "         3.2288e-05,  1.2668e-05, -1.9552e-05,  3.1702e-06,  2.8518e-05,\n",
      "        -1.5239e-04, -5.2134e-05,  1.7661e-05,  8.2987e-07,  6.9277e-05,\n",
      "         8.9967e-06,  4.5618e-05, -1.3892e-05,  1.1073e-05, -6.9772e-05,\n",
      "        -1.8300e-05,  3.2047e-05, -1.4395e-05, -8.4855e-05, -1.4709e-04,\n",
      "         9.6115e-06,  2.0581e-05,  1.1132e-04,  1.4486e-06,  2.8834e-05,\n",
      "        -3.2994e-05,  5.1250e-05,  1.3973e-04, -3.6973e-06, -1.9650e-05,\n",
      "        -4.1176e-05,  3.5859e-05,  8.9161e-05,  5.5636e-05, -6.3089e-05,\n",
      "         2.9816e-06, -2.5846e-07,  1.1611e-05, -7.3670e-06,  6.9505e-05,\n",
      "        -1.1276e-04,  4.7226e-05, -8.2317e-05, -3.9412e-05, -1.1867e-04,\n",
      "         1.9713e-05, -5.5717e-06,  4.2177e-05,  1.1930e-04, -8.9433e-05,\n",
      "         9.0726e-05,  2.5221e-05,  8.7358e-05, -3.5926e-05,  6.5387e-05,\n",
      "         3.0114e-05,  1.6627e-06,  1.4752e-05,  8.7253e-06,  1.6155e-05,\n",
      "        -6.2395e-06, -1.4906e-05,  8.2271e-05, -3.2424e-05, -2.6785e-05,\n",
      "        -6.1257e-05, -8.1915e-06,  9.2092e-05, -8.6849e-05,  3.9528e-05,\n",
      "         4.4061e-06,  1.2191e-04,  7.7810e-05,  1.7531e-05, -9.6620e-05,\n",
      "        -2.7510e-05, -4.8274e-05, -3.1944e-05, -3.2610e-05, -2.3068e-05,\n",
      "         1.4285e-05, -8.2691e-05, -1.8459e-05,  4.7434e-05,  1.0533e-05,\n",
      "        -7.3824e-05, -1.0943e-04,  3.4909e-05, -2.2957e-05, -3.7857e-05,\n",
      "         1.4735e-05, -5.7501e-06, -1.2272e-05, -4.1339e-05,  4.7740e-07,\n",
      "        -4.4419e-05,  3.6516e-05,  3.7873e-05, -2.2668e-06,  1.3515e-05,\n",
      "        -4.3337e-05,  1.8728e-05, -7.9154e-05,  4.6668e-05, -4.8551e-06,\n",
      "        -1.2286e-04, -1.8548e-05,  1.8020e-05, -4.1108e-05, -7.4593e-06,\n",
      "        -1.6960e-05,  7.7151e-06, -4.1680e-06, -1.6105e-05, -2.9138e-05,\n",
      "        -1.6400e-05,  2.0119e-05, -4.1930e-05,  5.1937e-06,  4.5551e-05,\n",
      "         1.4973e-05, -6.2602e-05,  1.2519e-05,  5.2068e-05, -2.4119e-05,\n",
      "         1.5805e-04, -8.7187e-05,  3.8445e-05, -7.4008e-05,  4.6119e-06,\n",
      "         4.8459e-05,  1.0181e-04,  4.6711e-05,  2.7148e-05, -4.8557e-05,\n",
      "         8.1383e-05, -1.0943e-05, -2.1262e-05, -3.1511e-05,  2.3617e-05,\n",
      "        -2.5888e-05, -7.3205e-06,  6.4094e-05,  1.0026e-04, -8.1732e-05,\n",
      "         5.7244e-05,  3.8297e-05, -5.2292e-05,  1.3802e-04, -6.6506e-06,\n",
      "        -1.0420e-04,  3.4231e-05, -4.9990e-05,  1.6309e-05,  4.3489e-05,\n",
      "        -3.6377e-05,  4.4616e-05, -6.8825e-06, -8.3969e-05,  6.4068e-05,\n",
      "        -1.1352e-05,  1.8119e-04, -7.5691e-05, -3.3878e-05,  8.9553e-06,\n",
      "         4.1095e-05,  2.8487e-05,  9.7254e-05, -6.9941e-06,  3.7288e-05,\n",
      "        -3.1614e-05, -3.7884e-05,  6.4476e-05, -5.3337e-05, -1.9826e-05,\n",
      "        -7.3724e-06,  3.1819e-06,  1.0359e-04,  1.7823e-05, -2.5816e-05,\n",
      "        -8.2856e-05, -1.3990e-05,  7.8304e-06,  2.8668e-05,  5.6803e-05,\n",
      "        -2.5274e-05, -5.7961e-05,  2.3723e-05,  2.3461e-05, -8.8920e-05,\n",
      "        -1.2012e-05, -5.7053e-06,  1.1390e-05,  3.2052e-05,  1.5251e-05,\n",
      "        -3.2985e-05,  4.7324e-05, -5.1262e-06, -3.5845e-05, -2.0364e-05,\n",
      "         4.2739e-05,  8.1858e-05, -2.2729e-06,  2.3185e-06,  9.5025e-05,\n",
      "        -4.0079e-06, -1.8742e-05, -4.7908e-06, -2.3547e-05, -9.0448e-05,\n",
      "        -2.0650e-05, -2.6569e-06, -2.5073e-05, -1.0553e-05, -4.9526e-05,\n",
      "        -7.3974e-05, -1.9163e-05, -4.0440e-05, -1.1187e-05,  1.4541e-05,\n",
      "        -1.1315e-04,  5.9750e-05,  1.2806e-04, -2.2281e-05, -5.3222e-05,\n",
      "        -5.4841e-05,  3.0544e-05, -7.8863e-06, -1.2901e-05,  2.8060e-05,\n",
      "         2.2950e-05, -6.9469e-05, -1.2306e-06,  1.0824e-06, -5.8127e-05,\n",
      "        -2.5108e-05,  1.2732e-05,  1.1244e-04, -4.2164e-05,  1.4121e-04,\n",
      "         8.2110e-06, -1.5445e-05,  6.1387e-05, -2.4841e-05, -2.3214e-05,\n",
      "        -5.1125e-05,  6.9880e-05, -4.6043e-05,  1.3158e-06, -3.7993e-05,\n",
      "         2.0232e-06, -1.4074e-05, -2.5971e-05,  4.4857e-05,  2.0928e-05,\n",
      "         7.6677e-05, -6.7360e-05,  9.9459e-05, -8.2651e-05, -3.5938e-05,\n",
      "        -1.3606e-04, -1.5181e-06,  9.4141e-05,  7.4030e-05,  7.4805e-06,\n",
      "         1.8915e-06, -6.6741e-05, -2.7557e-05,  3.4734e-05, -2.2141e-05,\n",
      "        -4.8261e-05, -2.6889e-05, -7.7997e-05, -3.4972e-05,  8.3216e-06,\n",
      "        -1.4400e-05, -4.2329e-05,  8.1732e-06, -1.1922e-05, -2.7498e-05,\n",
      "         1.4637e-05,  1.1024e-05,  1.1413e-05,  1.1751e-04, -4.7061e-05,\n",
      "        -3.4483e-05, -1.0935e-05,  1.6620e-05, -8.4656e-05,  1.6599e-05,\n",
      "        -7.0424e-05, -5.4690e-05,  9.2091e-05, -9.7776e-06,  2.0661e-05,\n",
      "         4.1085e-05,  6.0283e-06, -6.8911e-05,  6.4600e-05,  1.9715e-05,\n",
      "         2.8407e-05, -7.8640e-05,  4.9361e-06,  8.7670e-05, -6.4718e-06,\n",
      "         4.0215e-05, -1.3656e-04,  1.5877e-05,  5.9529e-06,  1.2207e-04,\n",
      "         4.1795e-05,  7.0730e-05,  1.3599e-05,  8.4594e-05,  1.1460e-05,\n",
      "        -5.7317e-06,  3.6516e-05, -4.7946e-05,  6.5585e-05, -5.3358e-05,\n",
      "         1.8659e-05,  1.0165e-04, -5.4089e-05,  8.4942e-05,  4.1087e-05,\n",
      "        -1.0969e-04,  9.3259e-05, -2.8810e-05, -3.2123e-05,  8.8127e-05,\n",
      "        -1.6465e-05, -7.0293e-05, -1.5114e-07,  4.5876e-05, -2.4716e-05,\n",
      "         4.2460e-05,  2.0918e-05,  1.2143e-04,  3.8033e-05,  1.7362e-05,\n",
      "        -3.1050e-05,  1.0024e-04, -5.3183e-05,  7.9495e-07, -1.3291e-05,\n",
      "         3.2881e-06,  4.6437e-05, -1.6754e-05, -6.1701e-05,  7.6815e-05,\n",
      "        -6.3310e-05, -9.3633e-05,  9.0750e-05, -6.8501e-05, -3.8937e-05,\n",
      "        -1.7191e-05, -3.5501e-05, -9.3195e-05,  1.4708e-05,  7.1289e-05,\n",
      "         2.9098e-05,  1.3223e-05, -1.8659e-05, -7.2512e-05,  5.4766e-05,\n",
      "        -5.4005e-05, -6.1294e-05,  5.5514e-05,  3.9447e-05, -1.0158e-05,\n",
      "         4.2717e-05, -7.0719e-06, -7.7481e-06, -5.7589e-05, -4.2217e-05,\n",
      "        -4.2728e-05,  6.4749e-05,  5.2040e-05,  1.1277e-04,  8.7858e-06,\n",
      "         3.4199e-05,  6.5733e-05, -2.1199e-05, -2.2084e-05,  1.1314e-05,\n",
      "         1.7112e-05,  1.2982e-04, -5.8841e-05,  6.4873e-05, -2.6795e-05,\n",
      "        -6.9659e-05,  1.7605e-05, -4.0939e-06, -3.0470e-05, -5.5050e-05,\n",
      "         3.5202e-05, -6.7026e-05,  1.8826e-05,  3.2028e-05, -1.8694e-04,\n",
      "         7.7962e-05,  4.2006e-05,  7.2167e-05, -3.8822e-05,  3.9553e-05,\n",
      "         2.0295e-06,  1.2336e-05, -3.0897e-05, -3.8933e-05, -7.2158e-05,\n",
      "         1.0074e-04,  6.3368e-05,  3.9964e-05,  1.0821e-05,  1.7823e-05,\n",
      "        -5.7210e-05,  3.2330e-05, -1.1659e-04,  1.1302e-05,  2.2064e-05,\n",
      "        -1.0365e-04, -4.8287e-05, -2.3710e-05, -3.9380e-05,  8.9447e-05,\n",
      "         1.3611e-05, -2.4817e-05,  3.2642e-05,  1.8819e-05, -4.1986e-07,\n",
      "         1.6146e-06, -6.1010e-05, -6.5815e-05, -3.1229e-05,  3.0967e-05,\n",
      "        -3.9131e-05, -7.0796e-05,  2.9033e-05, -4.7597e-05, -3.1277e-05,\n",
      "         8.9752e-05,  1.8597e-05,  5.5276e-05, -3.4085e-05,  7.1256e-05,\n",
      "        -4.8118e-05,  2.6914e-05,  2.3734e-05,  2.3673e-05,  2.7779e-05,\n",
      "         9.4791e-05,  6.8692e-05,  1.9824e-06,  4.2607e-05, -4.0019e-05,\n",
      "        -3.5043e-06, -5.3359e-05, -1.3365e-05,  2.3297e-05,  5.4834e-05,\n",
      "         1.4534e-05,  5.4699e-05,  3.2143e-05, -5.0643e-05, -1.0185e-04,\n",
      "         2.9873e-05, -8.4085e-05,  2.4969e-05,  2.7018e-05,  7.3852e-06,\n",
      "         8.3319e-06, -3.1003e-05,  2.0410e-05,  3.7513e-05,  7.1959e-05,\n",
      "         3.8857e-05, -5.1053e-05, -4.8640e-05,  9.8855e-05,  1.2542e-05,\n",
      "         1.1307e-05,  8.3206e-05,  6.9457e-05, -3.6932e-05, -4.6000e-05,\n",
      "        -1.2599e-06,  8.2796e-05, -2.9578e-05, -6.4495e-05, -4.6203e-05,\n",
      "        -1.4711e-05,  1.1587e-04])), ('postnet.convolutions.3.1.weight', tensor([ 0.0535,  0.3669,  0.0482,  0.0370,  0.0605,  0.0545,  0.0613,  0.0476,\n",
      "         0.0501,  0.5594,  0.0597,  0.0599,  0.0536,  0.0528,  0.0651,  0.1265,\n",
      "         0.0551,  0.0558,  0.6383,  0.0574,  1.2607,  0.0565,  0.0563,  0.0761,\n",
      "         0.0863,  0.0561,  0.0638,  0.0531,  1.4313,  0.6231,  0.0606,  0.0574,\n",
      "         0.0598,  0.9390,  0.0649,  0.0528,  0.0524,  0.0493,  0.0649,  1.2001,\n",
      "         0.0526,  0.0590,  0.0547,  0.0576,  0.7605,  0.7568,  0.0598,  0.6216,\n",
      "         0.8109,  0.0551,  0.0529,  0.0567,  0.8110,  0.7163,  1.7217,  0.4438,\n",
      "         0.7528,  0.6122,  0.9303,  1.0492,  0.0610,  0.1682,  0.0622,  0.8966,\n",
      "         0.0512,  1.0540,  0.9881,  0.0552,  0.0630,  0.7492,  0.0667,  0.0655,\n",
      "         0.0505,  1.3498,  0.0516,  0.6110,  0.0622,  0.0570,  0.0583,  0.0578,\n",
      "         0.0497,  0.0595,  0.0560,  0.0530,  0.0531,  0.0550,  0.0634,  0.7745,\n",
      "         0.0507,  0.0554,  0.0577,  0.0561,  0.8196,  0.7375,  0.0547,  0.7027,\n",
      "         0.0594,  1.0846,  0.0535,  0.1788,  0.0548,  0.8233,  1.0328,  0.0534,\n",
      "         0.0589,  0.0609,  0.0386,  0.0355,  0.1768,  0.0666,  0.8646,  0.0789,\n",
      "         0.5250,  0.5143,  0.0582,  0.0660,  0.7173,  0.0424,  0.0552,  0.0560,\n",
      "         0.0473,  0.0584,  0.0610,  0.8984,  0.0467,  0.0440,  0.0550,  0.0512,\n",
      "         0.0614,  0.7567,  0.0520,  0.2094,  0.0528,  0.0664,  0.0603,  0.8803,\n",
      "         0.0556,  0.0677,  1.0661,  0.0542,  0.0693,  0.0544,  0.0542,  0.4630,\n",
      "         1.3422,  0.0572,  0.1350,  0.0557,  0.3121,  0.0473,  0.0918,  0.0511,\n",
      "         0.0544,  0.0527,  0.0632,  0.8557,  0.0416,  0.0523,  0.0507,  0.0504,\n",
      "         0.0550,  0.0624,  0.0587,  0.0532,  0.5937,  0.3238,  0.0553,  0.0576,\n",
      "         0.6346,  0.0709,  0.0449,  0.0502,  0.0630,  0.0639,  0.0354,  0.0481,\n",
      "         0.0601,  0.0559,  0.0568,  0.0557,  0.0583,  0.8625,  0.7251,  0.0577,\n",
      "         0.0565,  0.7033,  0.0650,  0.6821,  0.0578,  0.0475,  0.0588,  0.0516,\n",
      "         0.7838,  0.0542,  0.5879,  0.0621,  0.0536,  0.0518,  0.0479,  0.0571,\n",
      "         0.0642,  0.2568,  0.0569,  0.0568,  0.7746,  0.0527,  0.0504,  0.7860,\n",
      "         0.0601,  1.3087,  0.0579,  0.0646,  1.0223,  0.0429,  0.1390,  0.0615,\n",
      "         0.0378,  0.4706,  0.0565,  0.0514,  0.0556,  0.0454,  0.0571,  0.7922,\n",
      "         0.0484,  0.0571,  0.0539,  0.0577,  0.0951,  0.9214,  1.2316,  0.7437,\n",
      "         0.0570,  0.6543,  0.0593,  1.0136,  0.0381,  0.8087,  0.0529,  0.0450,\n",
      "         0.0622,  0.2521,  0.7884,  0.0541,  0.0601,  0.0625,  0.0583,  0.0582,\n",
      "         0.0608,  0.0927,  0.0564,  0.0516,  0.0480,  0.0619,  0.0794,  0.0603,\n",
      "         0.0526,  0.0554,  0.9017,  0.2345,  0.0621,  0.0568,  0.0627,  0.0651,\n",
      "         0.0350,  0.0476,  0.8934,  0.0560,  0.0492,  0.0587,  0.1780,  0.0611,\n",
      "         0.0538,  0.0579,  0.0532,  0.0684,  0.0598,  0.0415,  0.0649,  0.1163,\n",
      "         0.7062,  0.0466,  0.0592,  0.3993,  0.0635,  0.0528,  0.7280,  0.0531,\n",
      "         0.0465,  0.5787,  0.6622,  0.0516,  0.0503,  0.8002,  0.2588,  0.0473,\n",
      "         0.0380,  0.0540,  0.0590,  0.0567,  0.0567,  0.8168,  0.0552,  0.0539,\n",
      "         0.0413,  0.0517,  0.0539,  0.0514,  0.0545,  0.0514,  0.0480,  0.0595,\n",
      "         0.0481,  0.0501,  0.0512,  0.8496,  0.0525,  0.0463,  0.7198,  0.0621,\n",
      "         0.0507,  0.0683,  0.0361,  0.0589,  0.0527,  0.0595,  0.0543,  0.9798,\n",
      "         0.0584,  0.9001,  0.0525,  0.0394,  0.0500,  0.7828,  0.0559,  0.0543,\n",
      "         0.0561,  0.0578,  0.0584,  0.0478,  0.0596,  0.6549,  0.0537,  0.0513,\n",
      "         0.0598,  0.0624,  0.9490,  0.0649,  0.7139,  0.0899,  1.0065,  0.0640,\n",
      "         0.0583,  0.0552,  0.4662,  0.0750,  0.0562,  0.0525,  0.0820,  0.0592,\n",
      "         0.0559,  0.6608,  0.7262,  0.0457,  0.0512,  0.0496,  0.9460,  0.0542,\n",
      "         0.0478,  1.0998,  0.6776,  0.0558,  0.8064,  0.0502,  0.0525,  0.0541,\n",
      "         0.0462,  0.5983,  0.8009,  0.5246,  0.6651,  0.0565,  0.0449,  0.0553,\n",
      "         0.4724,  0.0584,  0.0624,  0.6708,  0.6281,  0.0573,  0.0571,  0.0723,\n",
      "         0.7230,  0.0603,  0.6209,  0.8348,  0.1321,  0.0538,  0.0585,  0.0991,\n",
      "         0.0614,  0.0543,  0.0528,  0.2210,  0.0558,  0.0565,  0.0586,  0.9199,\n",
      "         0.0518,  0.0613,  0.0461,  0.5801,  0.0576,  1.0050,  0.0532,  0.0674,\n",
      "         0.0525,  0.3446,  0.0561,  1.0689,  0.0491,  0.5559,  0.0503,  0.6960,\n",
      "         0.0493,  0.8558,  0.0540,  0.0513,  0.0570,  0.0557,  0.0474,  0.9871,\n",
      "         0.7483,  0.0580,  0.0508,  0.0648,  0.0563,  0.0634,  0.0366,  0.0537,\n",
      "         0.0614,  0.0498,  0.0590,  0.0507,  0.0511,  0.0469,  0.8619,  0.0573,\n",
      "         0.0520,  0.0617,  0.0539,  0.6137,  0.0583,  0.0763,  0.0588,  0.0592,\n",
      "         0.0555,  1.0770,  0.0671,  0.7397,  0.0585,  0.8484,  0.0555,  0.0507,\n",
      "         0.0509,  0.0609,  0.7897,  0.0641,  0.1998,  0.0484,  0.0570,  0.0612,\n",
      "         0.9546,  0.0618,  0.1178,  0.0674,  0.0506,  0.0516,  0.0625, -0.0565,\n",
      "         0.0528,  0.0561,  0.6037,  0.0537,  0.4340,  0.0511,  1.1613,  0.0628,\n",
      "         0.0516,  0.0666,  0.0667,  0.0779,  0.1112,  0.9501,  0.7246,  0.0527,\n",
      "         0.0574,  0.0543,  0.0512,  0.6873,  0.0600,  0.0609,  0.1483,  0.1878,\n",
      "         0.0609,  0.0578,  0.0475,  0.0564,  1.6609,  0.6063,  0.0768,  0.0511])), ('postnet.convolutions.3.1.bias', tensor([-5.7331e-05,  9.1126e-03, -1.9471e-04,  2.2490e-04, -1.7550e-04,\n",
      "         4.3019e-05, -3.6513e-05, -1.3597e-04, -5.1458e-05,  1.2588e-01,\n",
      "         1.0215e-04, -5.0547e-04, -4.8741e-04, -3.4210e-04,  1.1950e-04,\n",
      "        -3.4993e-04,  3.7573e-04, -1.5716e-04,  1.6792e-01, -2.6558e-04,\n",
      "        -7.1006e-02, -7.2177e-04,  3.7997e-04, -4.4978e-04, -9.5326e-04,\n",
      "         2.1984e-04,  3.7127e-04,  4.2794e-04, -3.7232e-02, -1.2123e-01,\n",
      "        -5.6903e-04,  3.1696e-04, -1.2735e-04, -2.3904e-01, -1.9094e-04,\n",
      "         2.8565e-04, -3.4688e-06, -2.4472e-04, -8.9170e-07, -8.5260e-02,\n",
      "        -1.9047e-04, -3.0569e-04, -1.7774e-04, -3.2541e-04, -1.2085e-01,\n",
      "        -1.3273e-01,  2.6814e-04, -1.0252e-01, -1.3837e-01, -4.6418e-04,\n",
      "         8.8335e-04, -2.2228e-04,  1.7981e-01, -2.6091e-02, -1.0706e-01,\n",
      "        -7.0107e-03,  4.6312e-01, -8.5653e-02,  1.6347e-01,  2.7789e-01,\n",
      "         3.5524e-04, -1.1237e-03,  3.4993e-04, -2.0683e-01,  4.4945e-04,\n",
      "        -2.5506e-01, -2.6238e-01, -2.0075e-04, -2.4529e-04,  1.7075e-01,\n",
      "         3.8612e-04,  2.4410e-04, -2.7314e-04,  2.5659e-02, -2.7228e-04,\n",
      "        -2.5322e-01, -3.4824e-04, -1.2848e-04, -1.1947e-04,  2.3129e-04,\n",
      "         1.9423e-04, -2.9021e-05, -6.1510e-04, -6.7617e-05, -9.3754e-04,\n",
      "        -1.9487e-04,  7.2262e-04,  1.7413e-01,  6.1814e-05,  4.5375e-04,\n",
      "        -1.5141e-04,  3.1283e-06, -1.7469e-01, -4.1974e-02, -1.4060e-04,\n",
      "        -5.2833e-03, -1.8308e-04, -6.7338e-02,  2.8330e-04, -1.8006e-03,\n",
      "        -7.2715e-04,  1.5039e-01,  2.7705e-01,  1.7052e-04,  8.7799e-05,\n",
      "        -2.3656e-04,  2.1759e-04, -5.2793e-05, -1.0736e-03,  1.2678e-06,\n",
      "        -1.7592e-01, -2.2638e-04, -2.9798e-02, -2.8112e-02,  1.4505e-04,\n",
      "        -2.3893e-04,  8.8411e-02, -6.1445e-05,  6.7919e-04,  1.9057e-04,\n",
      "        -3.0154e-04, -2.1458e-04,  3.1173e-04, -2.0678e-01, -3.4043e-04,\n",
      "        -4.1805e-04,  1.0526e-04,  7.1043e-05,  1.9948e-04,  1.5440e-01,\n",
      "         6.1354e-04,  9.1310e-05,  3.2209e-04, -1.4227e-04, -4.4975e-04,\n",
      "        -8.2572e-02, -3.7093e-04,  3.5662e-04, -2.7375e-01, -2.9392e-04,\n",
      "         1.6603e-04,  9.7738e-05, -1.3501e-04, -2.3492e-02, -2.0517e-02,\n",
      "         8.7764e-04, -3.9015e-04, -1.1245e-04,  8.9316e-03, -1.9438e-04,\n",
      "         9.2839e-04,  3.3612e-05,  5.7320e-05,  5.8150e-04, -5.8974e-05,\n",
      "        -3.4682e-01,  4.5287e-04,  4.9998e-04,  3.8952e-04,  3.5746e-04,\n",
      "        -1.7567e-04,  1.1965e-04,  3.1196e-04,  2.8001e-04,  8.3124e-02,\n",
      "         1.7312e-03, -4.0115e-04, -1.5096e-04,  6.3268e-02, -3.8860e-04,\n",
      "         1.1060e-05,  2.5256e-04,  6.4731e-04,  3.4530e-04,  2.2379e-04,\n",
      "        -6.2438e-04, -2.7679e-04, -7.2876e-05, -6.9387e-04,  3.8894e-04,\n",
      "         1.4954e-04, -1.2443e-01, -1.3306e-01,  2.4070e-04,  6.1887e-05,\n",
      "         3.0966e-02, -1.7113e-04, -1.3110e-01,  3.5379e-05,  1.9108e-04,\n",
      "         3.4283e-04,  4.6774e-06,  2.3434e-01, -5.8802e-04, -7.1551e-02,\n",
      "        -1.1518e-04,  1.8555e-04, -5.8946e-04, -3.5494e-05,  2.9793e-04,\n",
      "        -3.3089e-04, -1.5007e-03, -6.7476e-04, -4.7003e-04,  1.8802e-01,\n",
      "        -4.6404e-05, -2.4514e-05,  3.2256e-01, -1.2376e-04, -3.6172e-02,\n",
      "        -1.5295e-04,  3.4431e-04, -1.2185e-01,  1.1537e-04, -7.6843e-04,\n",
      "        -4.7715e-05, -2.4036e-04, -1.8678e-02, -3.6253e-06, -2.5509e-04,\n",
      "         1.6469e-04, -1.0131e-04, -1.3200e-04, -1.4969e-01, -1.2139e-04,\n",
      "         2.8843e-04,  1.0827e-04, -5.8585e-05, -1.6361e-04,  2.2611e-02,\n",
      "         5.6913e-03, -8.2983e-02,  3.3693e-04,  1.0006e-01,  3.1271e-06,\n",
      "        -2.2557e-01,  2.6165e-04,  1.0065e-01, -1.4298e-04, -3.9945e-04,\n",
      "         6.9844e-04, -2.6205e-04, -1.7287e-01,  2.6590e-04, -1.2035e-04,\n",
      "         4.5600e-04,  3.6462e-04, -2.1166e-05,  1.1996e-04, -4.9719e-05,\n",
      "        -4.0023e-05, -4.6325e-04, -1.1148e-04,  3.3383e-04, -6.3525e-04,\n",
      "        -3.4769e-04, -1.9445e-04,  1.0566e-04,  2.2357e-01,  2.2661e-03,\n",
      "         4.1768e-04,  3.1747e-04,  1.8830e-04,  2.8898e-04, -5.5321e-04,\n",
      "         7.0959e-04, -1.9267e-01,  2.1388e-04, -1.6340e-04, -6.2736e-05,\n",
      "        -7.4241e-04, -6.2651e-04, -8.4682e-05,  7.7841e-04,  3.4151e-04,\n",
      "        -5.3557e-04, -6.0743e-04, -4.5921e-04, -7.4060e-05,  7.2594e-04,\n",
      "        -1.2946e-01, -1.1672e-04,  7.4555e-05,  1.1765e-02, -4.0038e-04,\n",
      "        -9.7055e-05, -4.5276e-01, -2.3651e-04, -1.6133e-04, -5.9856e-02,\n",
      "         4.8105e-02, -2.5296e-04,  2.6199e-04, -2.1634e-01,  3.0900e-03,\n",
      "         4.4000e-06, -1.1024e-04, -3.7142e-04,  2.3989e-04, -3.4451e-04,\n",
      "        -1.4952e-04, -5.6479e-02,  1.7474e-04, -9.5647e-05,  3.1658e-04,\n",
      "         4.7744e-06, -4.1604e-04, -6.7214e-04,  9.1574e-05,  2.7416e-04,\n",
      "        -1.7301e-04,  5.1285e-04, -8.9623e-05,  1.3137e-04, -1.2419e-05,\n",
      "         2.1290e-01, -6.4933e-04,  2.9548e-04,  2.1138e-01, -5.7142e-05,\n",
      "         4.9894e-05, -3.1931e-04, -3.4811e-04,  4.7426e-04, -1.0815e-04,\n",
      "        -1.3683e-05, -1.6520e-04,  2.2689e-01, -8.3162e-06,  1.6058e-01,\n",
      "         9.5596e-05, -2.2505e-04, -2.3071e-05, -6.0767e-02, -2.9771e-04,\n",
      "         4.9551e-04,  1.4662e-04,  8.5725e-05, -8.3513e-04, -2.9168e-04,\n",
      "         3.6750e-05, -3.1500e-01,  1.7538e-04, -2.7514e-04, -8.4119e-04,\n",
      "        -6.7563e-05, -8.0098e-02,  3.2761e-04, -5.2004e-02,  3.4593e-04,\n",
      "        -2.6190e-01,  2.2472e-04, -3.4114e-06,  7.6839e-04, -1.9111e-02,\n",
      "         6.5238e-05,  7.4841e-04, -3.7437e-04, -3.1079e-04,  4.0817e-04,\n",
      "        -4.8989e-05, -1.9698e-01, -2.0297e-01, -2.4231e-04,  1.7173e-05,\n",
      "         2.2390e-04,  2.3709e-01,  4.9503e-04, -5.7663e-04,  2.9764e-01,\n",
      "        -9.3016e-02,  6.4138e-04, -2.1171e-02,  7.4972e-05, -1.9156e-04,\n",
      "        -2.0422e-05, -4.5125e-05, -4.0893e-02,  1.8162e-01, -7.1036e-02,\n",
      "        -1.3789e-02,  1.7652e-04,  3.0997e-04, -1.7633e-04,  5.8450e-02,\n",
      "        -1.5502e-04,  3.2866e-04,  2.4946e-01, -6.5195e-02,  3.0981e-04,\n",
      "         2.6265e-04, -2.3879e-04, -2.2515e-01,  4.2833e-04, -6.6207e-02,\n",
      "        -7.1001e-02, -9.2306e-04, -2.5375e-04, -1.5801e-04,  3.4173e-04,\n",
      "        -2.7178e-04, -3.6455e-04,  1.9157e-04,  4.4516e-03,  3.9577e-05,\n",
      "        -3.1500e-06, -5.7652e-05, -2.0257e-01,  1.6127e-04,  1.9692e-04,\n",
      "        -3.9827e-04, -4.2493e-02,  1.9732e-04,  1.7598e-01, -1.1925e-04,\n",
      "         1.5690e-04,  5.5843e-04, -4.4539e-03,  4.9358e-04,  7.8330e-02,\n",
      "         1.8182e-04,  1.1286e-01,  7.1747e-04, -7.4297e-02, -6.2146e-05,\n",
      "        -1.3077e-01,  2.7380e-05, -1.3540e-04,  2.2276e-04,  1.5951e-04,\n",
      "        -1.7658e-05, -2.3318e-01, -2.7943e-01,  2.2348e-04, -2.3595e-04,\n",
      "        -7.8454e-05,  8.1078e-04,  2.7198e-04,  1.3229e-05, -3.3192e-04,\n",
      "        -1.9276e-04, -2.6293e-04, -4.4174e-04, -4.2430e-04, -1.1451e-04,\n",
      "         7.4230e-05, -2.5953e-01,  2.3200e-04,  7.3513e-05, -5.2336e-04,\n",
      "         3.2457e-05, -9.6435e-02,  6.1121e-05,  3.7053e-04, -2.7588e-04,\n",
      "         8.6944e-04,  2.4843e-04, -2.4095e-01,  1.4476e-04, -5.9543e-02,\n",
      "         5.4498e-04,  1.1398e-01,  1.8566e-04,  3.4483e-04,  7.5082e-04,\n",
      "        -5.3853e-04,  1.5020e-01, -1.8635e-05,  3.9652e-04,  6.3226e-04,\n",
      "         2.7890e-04, -5.8866e-05, -2.0663e-01,  1.0853e-04,  3.4734e-05,\n",
      "         6.6121e-05,  1.2299e-04, -2.4305e-04,  4.7159e-04,  8.9342e-05,\n",
      "         2.7424e-04,  1.5057e-06,  7.2398e-02,  4.8175e-04,  4.3812e-02,\n",
      "         7.8861e-05,  1.3389e-01,  5.2339e-04,  6.6553e-04, -5.3675e-04,\n",
      "         2.9549e-05, -3.6239e-04,  1.0309e-03,  2.4117e-01, -1.4131e-02,\n",
      "        -1.0726e-04, -5.0044e-05,  2.4312e-04,  5.7755e-04,  1.2671e-01,\n",
      "        -7.7610e-05, -2.5412e-04, -1.2876e-04,  1.5408e-03,  4.7821e-04,\n",
      "         7.0239e-05,  5.0205e-05, -1.9838e-04, -2.3109e-02, -5.7580e-02,\n",
      "        -1.4521e-04,  4.5021e-04])), ('postnet.convolutions.3.1.running_mean', tensor([-8.8222e-04, -7.9004e-03, -8.1908e-04, -3.3799e-02, -2.4381e-03,\n",
      "        -5.4688e-04,  1.2132e-03,  9.6565e-04,  7.5399e-04,  7.3583e-03,\n",
      "        -1.7969e-04, -4.1685e-04,  4.2656e-04,  2.6869e-04,  2.7204e-04,\n",
      "         1.3762e-03,  6.2086e-04, -6.6777e-04, -3.7124e-03, -7.0197e-04,\n",
      "        -4.2074e-03,  1.9098e-03,  5.9232e-04, -6.9704e-03, -1.1259e-02,\n",
      "        -1.6516e-03,  2.6210e-03,  2.0908e-03, -5.6542e-03, -1.8088e-03,\n",
      "        -2.3486e-04, -7.7303e-04,  2.9617e-03,  3.7172e-03, -1.7428e-03,\n",
      "        -4.4774e-03,  2.1238e-04,  5.2078e-04, -5.1776e-03,  1.4086e-03,\n",
      "         2.4511e-03,  1.9985e-03, -2.7574e-03,  9.2230e-04, -2.5851e-03,\n",
      "        -1.3338e-03, -1.7660e-03,  5.8381e-03,  1.9956e-03, -2.2960e-03,\n",
      "        -7.1213e-04,  1.5697e-03, -1.5637e-02, -4.8654e-03,  3.3928e-03,\n",
      "         2.4585e-03,  3.0600e-02, -9.6700e-04, -6.9373e-03, -6.5116e-03,\n",
      "         2.2532e-03, -3.4538e-03,  1.2758e-03,  1.6237e-02,  1.1662e-03,\n",
      "         3.4903e-03,  1.8675e-02, -2.0882e-03,  3.1349e-03,  6.1439e-03,\n",
      "        -5.6518e-04, -1.5371e-03, -1.5117e-03,  7.7631e-03, -1.4232e-03,\n",
      "        -3.5820e-02,  7.7699e-04,  2.2230e-03, -4.9885e-04, -1.4805e-03,\n",
      "        -3.3159e-04, -8.7370e-04, -1.2629e-03,  7.3246e-04,  2.6546e-03,\n",
      "        -2.0198e-03, -1.2848e-03, -7.6947e-03, -2.6764e-04, -1.8974e-03,\n",
      "         3.3334e-03,  3.0093e-04,  1.9668e-02,  9.2456e-03, -5.2453e-04,\n",
      "        -4.0916e-03,  1.3412e-03, -2.9723e-03,  7.4632e-04,  1.6410e-03,\n",
      "        -5.8369e-03, -6.3394e-03, -1.6428e-02, -6.0129e-04,  6.8918e-04,\n",
      "         2.1973e-03, -2.5604e-02, -2.2344e-02, -4.0184e-04, -7.3495e-03,\n",
      "         1.1906e-02, -8.3501e-03, -2.0983e-03, -4.1876e-03,  2.7535e-04,\n",
      "        -2.6653e-03,  7.6457e-04,  4.3691e-04,  2.6582e-03, -3.8894e-03,\n",
      "        -2.7990e-03, -1.8827e-03, -1.7041e-04, -3.2642e-03,  2.5038e-04,\n",
      "         4.1234e-04,  5.0229e-03,  8.8985e-05, -1.8800e-03, -1.2728e-02,\n",
      "         4.9464e-04,  2.0730e-03,  1.3344e-03,  4.2645e-04, -7.1986e-04,\n",
      "        -3.5566e-03, -8.2695e-04,  5.9026e-04,  1.9929e-04, -7.4496e-04,\n",
      "        -2.9783e-03,  8.2507e-04, -2.7672e-04, -3.6283e-03, -6.9289e-03,\n",
      "         8.2507e-04, -5.2774e-03,  9.9941e-04,  1.8497e-03,  6.0316e-04,\n",
      "         1.5102e-03,  6.8451e-04,  2.4833e-03, -2.9011e-04,  3.8160e-03,\n",
      "         5.9796e-03,  1.1915e-03,  6.2615e-03,  5.6153e-04, -1.1886e-03,\n",
      "         1.6659e-03,  1.5608e-03,  5.1187e-03,  7.4883e-06, -7.8436e-03,\n",
      "         4.0593e-04, -2.8519e-04, -1.3706e-03,  8.5061e-04, -8.1722e-03,\n",
      "         9.9588e-04,  5.8383e-03,  8.4885e-04, -1.3780e-03,  1.2830e-02,\n",
      "         4.7186e-04,  5.0026e-04, -7.1662e-04, -1.8722e-03, -2.2178e-03,\n",
      "        -3.5721e-04,  6.9469e-03,  9.5430e-03, -1.8845e-03,  1.9622e-03,\n",
      "        -4.4344e-03,  8.3264e-04, -1.0558e-03, -1.6741e-03,  2.5864e-03,\n",
      "        -5.0851e-04,  6.4559e-05, -8.0077e-03,  2.6200e-03, -1.9319e-03,\n",
      "        -1.9640e-03, -2.5097e-03, -8.6629e-04,  1.8835e-03,  4.0979e-04,\n",
      "         1.4041e-03, -2.4916e-03,  9.5543e-04, -2.2193e-03, -6.6092e-03,\n",
      "        -8.9495e-04,  2.1217e-03,  5.4147e-03, -8.5691e-04, -8.1299e-04,\n",
      "         1.0061e-03, -1.5717e-03, -1.0303e-03, -3.9450e-04, -4.3079e-03,\n",
      "        -6.0936e-05, -3.7011e-02, -1.6555e-03,  9.0193e-04,  2.0376e-03,\n",
      "         5.0650e-04, -2.2564e-03, -4.0650e-03,  9.0708e-03,  3.1597e-03,\n",
      "        -1.1085e-03, -2.8492e-04,  1.2371e-03, -1.4054e-04, -8.1278e-03,\n",
      "         1.8381e-04,  3.6546e-04, -9.6513e-04, -7.7716e-03,  1.6022e-05,\n",
      "         1.2307e-02, -2.2122e-02, -2.2819e-03,  1.9416e-03,  7.5536e-04,\n",
      "        -3.0223e-03,  7.8779e-03,  6.0734e-03,  3.4942e-03,  2.7775e-03,\n",
      "        -2.5522e-03,  6.1114e-03,  2.1679e-03, -3.3420e-05,  8.3737e-04,\n",
      "         4.5640e-04, -7.2997e-04,  3.3100e-03, -2.0115e-03,  4.0210e-03,\n",
      "        -3.5972e-04,  3.1395e-04,  1.1604e-03, -9.2829e-04,  2.9927e-03,\n",
      "        -4.4618e-03,  1.1931e-03, -2.2353e-03,  1.2024e-03, -1.6478e-02,\n",
      "         1.0673e-02,  1.5763e-02, -1.2387e-03,  1.8455e-03,  7.1155e-03,\n",
      "         2.6769e-03,  1.8905e-04,  2.7041e-03, -1.8661e-03,  1.3544e-03,\n",
      "         6.7306e-03,  4.5354e-03,  1.2352e-03, -1.8544e-03, -2.3011e-03,\n",
      "         9.9200e-03,  1.9659e-03,  2.3155e-03,  3.6117e-04,  1.2805e-03,\n",
      "         1.5688e-03, -4.7924e-02,  1.3378e-03, -4.7851e-03,  3.1964e-03,\n",
      "         4.9267e-04,  7.8131e-04, -2.2740e-03,  5.3713e-03, -4.6726e-03,\n",
      "         2.5528e-03, -2.0846e-03, -6.1049e-04, -1.2214e-04,  6.5766e-04,\n",
      "         9.7137e-04,  2.3684e-03,  1.1764e-03,  4.3390e-04,  8.9259e-03,\n",
      "         4.9562e-03, -1.1667e-03,  3.3926e-04, -6.9934e-04, -4.4800e-03,\n",
      "        -1.6304e-03, -4.4993e-04, -1.0615e-02,  2.4736e-03,  2.5148e-03,\n",
      "        -9.9455e-03, -1.7740e-03, -5.0363e-03,  4.9419e-03,  5.0176e-05,\n",
      "         1.1122e-03,  4.0004e-03,  1.4308e-02,  6.7953e-04,  1.2675e-03,\n",
      "        -2.3660e-04,  5.2151e-04, -4.5520e-03, -9.0668e-04, -4.0521e-03,\n",
      "        -7.8917e-04, -1.4095e-02, -4.5441e-03,  1.9158e-03, -7.3775e-04,\n",
      "        -1.6024e-03,  8.2607e-04,  7.8680e-04,  4.2864e-04, -4.3402e-03,\n",
      "         2.6492e-03, -4.4469e-02,  2.7752e-03,  5.4860e-04,  3.6621e-03,\n",
      "        -2.0799e-04, -3.3915e-03,  3.2498e-03,  1.1858e-02, -4.2119e-03,\n",
      "         3.6975e-03,  3.6020e-03, -4.0148e-04, -3.6557e-03,  2.5257e-03,\n",
      "         3.4964e-03,  5.3243e-05,  4.3298e-03,  8.4977e-04, -1.5127e-03,\n",
      "        -4.4037e-03, -4.8391e-03,  1.1627e-03,  1.5807e-03,  2.1836e-03,\n",
      "         6.1714e-04, -1.0629e-02,  1.8190e-03,  3.0101e-03,  4.4552e-04,\n",
      "         5.4090e-03,  2.9167e-04,  4.9231e-03,  1.8048e-03,  2.0913e-03,\n",
      "        -1.4630e-03,  6.0322e-04, -5.1832e-03, -1.3023e-03,  2.1716e-03,\n",
      "        -5.8142e-03,  9.8571e-04, -5.6052e-03,  4.4997e-03, -8.1198e-04,\n",
      "         1.0059e-03,  5.1261e-04,  8.0481e-03,  3.2854e-03, -1.1401e-04,\n",
      "        -1.7444e-03, -2.4263e-03,  4.3706e-03,  5.8451e-04, -4.3254e-03,\n",
      "         3.9752e-03, -3.3272e-03,  3.6955e-04, -8.5950e-05,  4.5006e-04,\n",
      "        -1.7962e-04,  2.1171e-04, -2.2891e-03,  1.2765e-03, -7.6184e-03,\n",
      "         6.1513e-04, -8.9912e-04,  1.4042e-03, -3.9030e-04,  1.2042e-03,\n",
      "        -4.1524e-03, -5.0564e-03,  4.3329e-04,  3.9340e-03, -7.4202e-04,\n",
      "        -2.0169e-03,  9.2426e-04, -5.1640e-03,  4.3325e-03,  2.9578e-04,\n",
      "         3.5880e-03, -1.0600e-02, -7.2051e-03,  1.0399e-02, -2.1246e-03,\n",
      "         1.9293e-03, -5.4492e-04,  1.6336e-03, -2.9582e-03, -2.9316e-03,\n",
      "         4.2478e-03,  2.0285e-03, -7.2676e-03, -3.2103e-03,  8.3224e-03,\n",
      "         2.7058e-03,  1.6540e-03,  2.6043e-03,  4.7005e-03,  1.4524e-03,\n",
      "        -6.0486e-03,  9.9573e-04, -8.3718e-04,  5.5977e-04,  1.5575e-03,\n",
      "        -8.3527e-04, -1.7660e-02, -2.3587e-03, -9.0592e-04, -6.6914e-04,\n",
      "         3.3372e-03,  1.2995e-03,  2.8689e-03, -2.9487e-03, -2.0576e-03,\n",
      "         3.4660e-03,  5.3528e-04,  4.8479e-03, -3.4082e-03, -8.6454e-03,\n",
      "        -4.2125e-04, -1.5406e-03, -1.3320e-03,  2.9180e-03,  2.3861e-03,\n",
      "         3.3350e-03, -8.9121e-04, -1.7344e-03, -1.5851e-03, -3.5665e-04,\n",
      "        -7.3422e-04,  8.0026e-04,  7.8899e-03,  3.5099e-05,  2.3156e-04,\n",
      "        -4.6799e-05,  1.0835e-03,  1.9252e-03, -4.2004e-04, -9.8246e-04,\n",
      "        -1.2081e-03,  4.0832e-04,  2.2084e-03, -2.3836e-04,  2.0427e-04,\n",
      "         2.1199e-03,  1.0025e-03,  1.1584e-03, -1.8938e-03,  2.4378e-04,\n",
      "         1.8353e-05, -2.0594e-03, -3.9873e-03, -1.1597e-02, -5.0496e-03,\n",
      "         2.4794e-04,  8.4087e-04,  5.9654e-04,  4.2530e-03,  1.2465e-02,\n",
      "        -1.8718e-03, -1.2630e-03,  1.6327e-03,  1.4156e-03, -9.1820e-04,\n",
      "        -3.0277e-03,  3.3033e-03,  3.2303e-03,  1.6793e-02, -9.8983e-04,\n",
      "        -1.4202e-04, -5.3457e-03])), ('postnet.convolutions.3.1.running_var', tensor([0.0142, 0.0319, 0.0200, 0.1261, 0.0154, 0.0103, 0.0105, 0.0168, 0.0100,\n",
      "        0.0227, 0.0097, 0.0108, 0.0122, 0.0098, 0.0100, 0.0129, 0.0142, 0.0109,\n",
      "        0.0337, 0.0113, 0.0275, 0.0108, 0.0099, 0.0396, 0.0461, 0.0119, 0.0135,\n",
      "        0.0150, 0.0671, 0.0272, 0.0130, 0.0095, 0.0122, 0.0353, 0.0085, 0.0198,\n",
      "        0.0083, 0.0226, 0.0220, 0.0244, 0.0182, 0.0106, 0.0128, 0.0126, 0.0123,\n",
      "        0.0418, 0.0109, 0.0339, 0.0280, 0.0120, 0.0107, 0.0110, 0.0364, 0.0342,\n",
      "        0.1180, 0.0151, 0.0587, 0.0271, 0.0301, 0.0360, 0.0129, 0.0207, 0.0102,\n",
      "        0.0345, 0.0187, 0.0471, 0.0404, 0.0098, 0.0083, 0.0571, 0.0088, 0.0080,\n",
      "        0.0149, 0.0590, 0.0270, 0.0546, 0.0087, 0.0105, 0.0102, 0.0111, 0.0127,\n",
      "        0.0113, 0.0153, 0.0244, 0.0179, 0.0139, 0.0112, 0.0347, 0.0090, 0.0177,\n",
      "        0.0132, 0.0114, 0.0503, 0.0350, 0.0122, 0.0372, 0.0090, 0.0231, 0.0180,\n",
      "        0.0140, 0.0414, 0.0385, 0.0398, 0.0105, 0.0127, 0.0111, 0.0943, 0.1248,\n",
      "        0.0082, 0.0250, 0.0359, 0.0381, 0.0253, 0.0183, 0.0097, 0.0114, 0.0368,\n",
      "        0.0486, 0.0213, 0.0128, 0.0281, 0.0132, 0.0123, 0.0339, 0.0235, 0.1088,\n",
      "        0.0190, 0.0099, 0.0122, 0.0427, 0.0207, 0.0155, 0.0097, 0.0129, 0.0099,\n",
      "        0.0374, 0.0119, 0.0081, 0.0355, 0.0142, 0.0206, 0.0094, 0.0119, 0.0280,\n",
      "        0.0548, 0.0112, 0.0151, 0.0114, 0.0159, 0.0117, 0.0099, 0.0127, 0.0137,\n",
      "        0.0153, 0.0157, 0.0545, 0.0831, 0.0232, 0.0122, 0.0186, 0.0109, 0.0099,\n",
      "        0.0335, 0.0135, 0.0282, 0.0194, 0.0165, 0.0130, 0.0411, 0.0436, 0.0186,\n",
      "        0.0227, 0.0135, 0.0151, 0.1085, 0.0219, 0.0082, 0.0104, 0.0136, 0.0105,\n",
      "        0.0101, 0.0448, 0.0450, 0.0099, 0.0106, 0.0302, 0.0096, 0.0613, 0.0101,\n",
      "        0.0205, 0.0084, 0.0097, 0.0571, 0.0126, 0.0251, 0.0107, 0.0114, 0.0098,\n",
      "        0.0218, 0.0095, 0.0083, 0.0108, 0.0141, 0.0112, 0.0548, 0.0092, 0.0108,\n",
      "        0.0340, 0.0095, 0.0400, 0.0108, 0.0085, 0.0166, 0.0193, 0.0133, 0.0109,\n",
      "        0.1155, 0.0210, 0.0111, 0.0118, 0.0113, 0.0227, 0.0161, 0.0324, 0.0214,\n",
      "        0.0263, 0.0092, 0.0104, 0.0174, 0.0395, 0.0549, 0.0413, 0.0100, 0.0339,\n",
      "        0.0173, 0.0372, 0.1284, 0.0262, 0.0104, 0.0246, 0.0109, 0.0257, 0.0488,\n",
      "        0.0183, 0.0139, 0.0123, 0.0162, 0.0110, 0.0070, 0.0244, 0.0090, 0.0211,\n",
      "        0.0189, 0.0088, 0.0190, 0.0184, 0.0118, 0.0119, 0.0354, 0.0137, 0.0101,\n",
      "        0.0157, 0.0092, 0.0092, 0.1155, 0.0443, 0.0320, 0.0112, 0.0226, 0.0156,\n",
      "        0.0135, 0.0120, 0.0132, 0.0111, 0.0127, 0.0354, 0.0130, 0.0217, 0.0135,\n",
      "        0.0221, 0.0324, 0.0287, 0.0125, 0.0492, 0.0087, 0.0155, 0.0630, 0.0110,\n",
      "        0.0278, 0.0276, 0.0301, 0.0088, 0.0186, 0.0423, 0.0166, 0.0326, 0.0631,\n",
      "        0.0136, 0.0111, 0.0102, 0.0098, 0.0513, 0.0093, 0.0099, 0.0575, 0.0230,\n",
      "        0.0107, 0.0137, 0.0100, 0.0211, 0.0094, 0.0100, 0.0265, 0.0158, 0.0116,\n",
      "        0.0354, 0.0169, 0.0176, 0.0236, 0.0127, 0.0139, 0.0146, 0.0941, 0.0166,\n",
      "        0.0126, 0.0091, 0.0135, 0.0352, 0.0092, 0.0477, 0.0094, 0.0944, 0.0207,\n",
      "        0.0351, 0.0082, 0.0126, 0.0128, 0.0088, 0.0081, 0.0174, 0.0103, 0.0568,\n",
      "        0.0109, 0.0207, 0.0201, 0.0098, 0.0152, 0.0118, 0.0360, 0.0153, 0.0387,\n",
      "        0.0115, 0.0158, 0.0151, 0.0338, 0.0147, 0.0132, 0.0179, 0.0127, 0.0138,\n",
      "        0.0185, 0.0268, 0.0395, 0.0185, 0.0176, 0.0111, 0.0404, 0.0347, 0.0204,\n",
      "        0.0419, 0.0543, 0.0106, 0.0439, 0.0764, 0.0136, 0.0118, 0.0168, 0.0257,\n",
      "        0.0319, 0.0178, 0.0311, 0.0096, 0.0371, 0.0179, 0.0236, 0.0117, 0.0106,\n",
      "        0.0324, 0.0267, 0.0133, 0.0126, 0.0179, 0.0447, 0.0098, 0.0219, 0.0477,\n",
      "        0.0177, 0.0122, 0.0105, 0.0183, 0.0089, 0.0179, 0.0088, 0.0169, 0.0190,\n",
      "        0.0118, 0.0090, 0.0282, 0.0140, 0.0096, 0.0513, 0.0248, 0.0110, 0.0186,\n",
      "        0.0136, 0.0082, 0.0199, 0.0189, 0.0112, 0.0190, 0.0257, 0.0238, 0.0273,\n",
      "        0.0361, 0.0146, 0.0274, 0.0107, 0.0088, 0.0122, 0.0120, 0.0238, 0.0369,\n",
      "        0.0329, 0.0103, 0.0748, 0.0150, 0.0127, 0.0101, 0.0665, 0.0186, 0.0199,\n",
      "        0.0210, 0.0108, 0.0113, 0.0204, 0.0225, 0.0558, 0.0129, 0.0218, 0.0101,\n",
      "        0.0217, 0.0300, 0.0106, 0.0300, 0.0087, 0.0158, 0.0097, 0.0352, 0.0101,\n",
      "        0.0433, 0.0134, 0.0258, 0.0124, 0.0154, 0.0187, 0.0079, 0.0276, 0.0088,\n",
      "        0.0134, 0.0145, 0.0103, 0.0094, 0.0364, 0.0094, 0.0124, 0.0182, 0.0158,\n",
      "        0.0126, 0.0104, 0.0082, 0.0177, 0.0131, 0.0153, 0.0087, 0.0136, 0.0136,\n",
      "        0.0216, 0.0087, 0.0177, 0.0090, 0.0080, 0.0334, 0.0150, 0.0400, 0.0221,\n",
      "        0.0176, 0.0085, 0.0137, 0.0124, 0.0265, 0.0174, 0.0082, 0.0185, 0.0149,\n",
      "        0.0084, 0.0140, 0.0217, 0.0172, 0.1278, 0.0179, 0.0462, 0.0253])), ('postnet.convolutions.3.1.num_batches_tracked', tensor(18012)), ('postnet.convolutions.4.0.conv.weight', tensor([[[-1.3108e-02,  2.2167e-02, -4.3219e-03,  1.8268e-02,  2.3212e-03],\n",
      "         [ 6.3896e-04,  6.9069e-03,  1.2113e-02,  5.2360e-04, -2.9538e-03],\n",
      "         [-4.4214e-05,  1.5340e-03,  1.0887e-02, -1.5600e-02,  5.4849e-03],\n",
      "         ...,\n",
      "         [ 3.8296e-03,  2.5724e-04, -6.8613e-03, -5.0338e-03, -1.2459e-03],\n",
      "         [-4.3423e-03, -1.3117e-02, -1.0156e-02,  5.7803e-03,  1.3737e-03],\n",
      "         [ 2.6030e-04, -9.5564e-04,  4.9724e-03, -1.2070e-03,  1.6044e-02]],\n",
      "\n",
      "        [[-1.2865e-02,  1.5866e-02, -2.5033e-03,  1.2434e-02, -2.6416e-03],\n",
      "         [-7.9207e-04,  5.7424e-03,  7.6491e-03, -2.5700e-03, -4.9747e-03],\n",
      "         [ 2.8396e-05,  5.6121e-03,  1.3501e-02, -1.3036e-02,  9.6057e-03],\n",
      "         ...,\n",
      "         [ 4.3806e-03, -4.1889e-04, -6.8658e-03, -4.1025e-03, -4.2182e-04],\n",
      "         [ 2.7130e-03, -6.2328e-03, -7.8123e-03,  5.2937e-03, -1.3660e-03],\n",
      "         [ 1.4296e-03, -2.7662e-03, -1.8346e-03, -6.6297e-03,  1.4555e-02]],\n",
      "\n",
      "        [[-9.1886e-03,  1.2345e-02,  2.1637e-03,  1.2001e-02,  1.2117e-03],\n",
      "         [-6.1210e-04,  1.7918e-03,  4.5362e-03, -1.8540e-03, -1.7822e-03],\n",
      "         [ 6.3721e-04,  2.4281e-03,  1.5226e-02, -9.6971e-03,  6.5801e-03],\n",
      "         ...,\n",
      "         [ 2.4788e-03,  2.0107e-05, -2.3071e-03, -4.9247e-03, -3.7593e-03],\n",
      "         [ 1.4314e-03, -3.8763e-03, -4.8293e-03,  6.3630e-03, -1.1679e-04],\n",
      "         [-1.6475e-03, -5.2362e-03, -3.9662e-04,  7.6933e-03,  2.2096e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.6691e-03, -8.0537e-03,  1.1867e-02,  2.9319e-02, -1.3961e-02],\n",
      "         [-1.5583e-03,  3.0919e-04, -2.5601e-03, -5.4877e-04,  1.0210e-03],\n",
      "         [ 1.4423e-03, -5.3684e-03,  4.3256e-02,  4.6727e-02,  4.8100e-03],\n",
      "         ...,\n",
      "         [-8.5577e-04, -1.2213e-03, -1.5602e-04,  9.2967e-04,  1.0334e-04],\n",
      "         [ 1.0848e-02,  1.2412e-02,  3.0694e-02,  3.3841e-02,  3.5083e-02],\n",
      "         [-9.6935e-04,  3.2154e-03,  1.2987e-02, -1.1149e-02, -1.7250e-03]],\n",
      "\n",
      "        [[-5.2653e-03, -7.3982e-03,  1.4337e-02,  4.7906e-02, -1.2722e-02],\n",
      "         [-5.7439e-04,  1.9597e-04, -1.8954e-03,  5.7021e-04,  2.6022e-03],\n",
      "         [-9.3772e-04, -1.7675e-02,  1.5646e-02,  1.6914e-02, -4.4234e-03],\n",
      "         ...,\n",
      "         [-1.6930e-03, -2.0549e-03, -8.3058e-04, -8.1274e-04, -1.9782e-03],\n",
      "         [ 8.8978e-03,  8.6581e-03,  2.3846e-02,  2.7000e-02,  2.9169e-02],\n",
      "         [-4.1272e-03, -1.5486e-03,  8.3165e-03, -1.5776e-02, -3.5205e-03]],\n",
      "\n",
      "        [[-6.2741e-03, -7.9717e-03,  1.2798e-02,  5.0663e-02, -1.4222e-02],\n",
      "         [-5.9432e-04,  6.5363e-04, -1.3637e-03,  1.3583e-03,  3.8345e-03],\n",
      "         [-4.1963e-03, -2.3399e-02, -7.5587e-05, -1.0126e-03, -1.3971e-02],\n",
      "         ...,\n",
      "         [-2.1907e-03, -2.6191e-03, -1.8451e-03, -1.6084e-03, -3.0352e-03],\n",
      "         [ 1.0371e-02,  1.0198e-02,  2.2881e-02,  2.2860e-02,  2.4752e-02],\n",
      "         [-3.7262e-03, -2.9113e-03,  1.9288e-03, -1.8873e-02, -2.0324e-03]]])), ('postnet.convolutions.4.0.conv.bias', tensor([ 6.8488e-05, -6.8861e-05, -8.1745e-05, -1.7626e-05, -3.9937e-05,\n",
      "        -3.5459e-05,  1.5186e-04,  1.4900e-04,  1.7624e-05, -5.6642e-05,\n",
      "         2.6786e-05,  1.7717e-06,  1.9094e-04,  6.2348e-05, -1.5611e-05,\n",
      "         9.6722e-05,  6.8205e-05,  3.9248e-05,  2.0386e-04,  4.6876e-05,\n",
      "        -2.6447e-05, -1.0089e-05, -1.1920e-04, -6.6312e-05, -1.2044e-04,\n",
      "        -2.3843e-04,  5.9327e-05, -1.4451e-05,  8.7220e-05,  4.6796e-05,\n",
      "         6.6688e-05,  1.3046e-05,  9.8908e-05, -2.0410e-05,  1.2561e-05,\n",
      "         8.4649e-05, -1.9637e-04, -3.4556e-05, -1.0625e-04,  8.7497e-05,\n",
      "         2.2771e-05, -1.2415e-05, -1.0980e-04, -9.6745e-05,  6.8010e-05,\n",
      "        -8.1560e-05, -1.9706e-04,  8.2251e-05,  3.9828e-05, -8.8657e-05,\n",
      "         2.0125e-05,  1.0294e-04,  4.4301e-06, -7.4937e-05, -2.1914e-05,\n",
      "         1.5730e-04,  1.2799e-04, -3.6321e-05, -9.0376e-06,  2.5008e-05,\n",
      "         1.6454e-05,  7.4010e-05,  9.9234e-05,  6.5868e-05,  6.1774e-05,\n",
      "         5.2195e-05,  1.1801e-05,  2.0146e-04,  4.1731e-04, -8.4758e-05,\n",
      "        -2.4049e-04,  4.5925e-05, -1.4107e-04,  4.3760e-04,  6.2649e-06,\n",
      "         1.0374e-04,  3.3037e-05, -1.2441e-04, -3.1460e-05, -4.8015e-05])), ('postnet.convolutions.4.1.weight', tensor([0.0594, 0.0486, 0.0455, 0.0717, 0.0982, 0.1049, 0.1041, 0.1058, 0.1113,\n",
      "        0.1161, 0.1134, 0.1084, 0.1085, 0.1133, 0.1151, 0.1141, 0.1103, 0.1107,\n",
      "        0.1098, 0.1081, 0.1081, 0.1119, 0.1139, 0.1114, 0.1117, 0.1101, 0.1062,\n",
      "        0.1027, 0.1005, 0.0979, 0.0967, 0.0970, 0.0979, 0.0971, 0.0996, 0.0951,\n",
      "        0.0947, 0.0952, 0.0964, 0.0966, 0.0977, 0.0999, 0.0996, 0.0974, 0.0952,\n",
      "        0.0923, 0.0909, 0.0904, 0.0943, 0.1002, 0.1012, 0.1015, 0.1017, 0.1061,\n",
      "        0.1126, 0.1150, 0.1131, 0.1116, 0.1152, 0.1203, 0.1187, 0.1134, 0.1113,\n",
      "        0.1128, 0.1153, 0.1194, 0.1225, 0.1244, 0.1251, 0.1232, 0.1205, 0.1181,\n",
      "        0.1207, 0.1258, 0.1276, 0.1273, 0.1270, 0.1305, 0.1369, 0.1315])), ('postnet.convolutions.4.1.bias', tensor([-4.2825e-05, -2.3457e-05, -6.0431e-05, -8.6893e-06, -1.7366e-05,\n",
      "        -2.0283e-05, -5.6965e-06, -2.9198e-05, -4.9789e-05, -5.7367e-05,\n",
      "         1.9406e-05, -1.1346e-05,  2.6969e-05,  1.5101e-05,  6.2514e-05,\n",
      "         4.6547e-05,  5.1492e-05,  1.3887e-05,  1.9335e-05, -7.9571e-06,\n",
      "         8.7233e-06, -2.8962e-05,  1.3265e-05, -2.0604e-06, -3.2004e-05,\n",
      "        -9.3920e-05,  2.8110e-05, -3.3292e-05, -4.5793e-05, -3.6344e-05,\n",
      "        -4.7169e-06, -7.8371e-06, -8.6833e-06,  6.5854e-07,  1.8077e-05,\n",
      "        -3.5101e-05, -1.7579e-05, -4.1273e-05, -6.6275e-06, -1.4976e-05,\n",
      "         5.9488e-06,  1.9308e-05,  1.3621e-05, -4.3276e-05,  1.6593e-05,\n",
      "         1.8233e-05,  1.3123e-05, -7.4147e-06, -2.9470e-05, -2.0815e-05,\n",
      "        -9.0852e-06, -1.6973e-05, -8.6214e-06,  2.1345e-05,  2.6605e-05,\n",
      "        -1.4145e-06, -8.0596e-06,  2.5386e-05,  2.8633e-06,  1.2392e-06,\n",
      "        -6.6323e-06, -1.7376e-05, -1.3629e-05, -5.3053e-05,  1.0217e-05,\n",
      "        -2.8582e-05,  1.5839e-05,  9.3583e-07, -2.1534e-05, -4.5520e-05,\n",
      "        -1.3309e-05,  6.6495e-06, -1.9956e-05,  2.1127e-05, -1.1851e-05,\n",
      "        -5.3439e-05, -2.6535e-05,  2.4645e-05,  9.7037e-06,  2.9823e-05])), ('postnet.convolutions.4.1.running_mean', tensor([-0.0071,  0.0052, -0.0068,  0.0014,  0.0096,  0.0050, -0.0049, -0.0064,\n",
      "        -0.0006,  0.0041,  0.0012,  0.0069,  0.0036,  0.0067,  0.0040,  0.0025,\n",
      "        -0.0012,  0.0017, -0.0048, -0.0003,  0.0021,  0.0047, -0.0013, -0.0066,\n",
      "        -0.0013,  0.0007, -0.0088, -0.0047, -0.0048,  0.0042, -0.0019, -0.0014,\n",
      "         0.0067,  0.0044,  0.0034,  0.0056,  0.0053,  0.0081,  0.0089,  0.0096,\n",
      "         0.0050,  0.0075,  0.0009, -0.0005, -0.0014, -0.0092, -0.0111, -0.0100,\n",
      "        -0.0139, -0.0176, -0.0052, -0.0128, -0.0021, -0.0061, -0.0013, -0.0005,\n",
      "        -0.0054, -0.0002,  0.0005, -0.0031, -0.0093, -0.0078, -0.0130, -0.0077,\n",
      "        -0.0054,  0.0006,  0.0008,  0.0009, -0.0025, -0.0041, -0.0025, -0.0047,\n",
      "        -0.0018,  0.0002, -0.0016, -0.0017, -0.0005, -0.0008, -0.0017, -0.0009])), ('postnet.convolutions.4.1.running_var', tensor([0.0281, 0.0201, 0.0200, 0.0276, 0.0407, 0.0435, 0.0427, 0.0465, 0.0509,\n",
      "        0.0581, 0.0570, 0.0527, 0.0531, 0.0587, 0.0599, 0.0630, 0.0561, 0.0565,\n",
      "        0.0553, 0.0539, 0.0541, 0.0572, 0.0590, 0.0584, 0.0553, 0.0544, 0.0499,\n",
      "        0.0481, 0.0452, 0.0426, 0.0417, 0.0419, 0.0420, 0.0422, 0.0434, 0.0419,\n",
      "        0.0423, 0.0415, 0.0429, 0.0450, 0.0473, 0.0521, 0.0535, 0.0511, 0.0486,\n",
      "        0.0465, 0.0435, 0.0428, 0.0454, 0.0477, 0.0499, 0.0489, 0.0518, 0.0541,\n",
      "        0.0603, 0.0626, 0.0606, 0.0606, 0.0615, 0.0675, 0.0648, 0.0596, 0.0556,\n",
      "        0.0558, 0.0583, 0.0607, 0.0620, 0.0618, 0.0625, 0.0628, 0.0593, 0.0559,\n",
      "        0.0572, 0.0611, 0.0618, 0.0613, 0.0632, 0.0680, 0.0713, 0.0703])), ('postnet.convolutions.4.1.num_batches_tracked', tensor(18012)), ('duration_predictor.lstm.weight_ih_l0', tensor([[ 0.0142, -0.0008, -0.0141,  ...,  0.0225,  0.0044, -0.0296],\n",
      "        [ 0.0247,  0.0269,  0.0296,  ..., -0.0284,  0.0184, -0.0440],\n",
      "        [-0.0070, -0.0030, -0.0113,  ...,  0.0026,  0.0321,  0.0125],\n",
      "        ...,\n",
      "        [ 0.0337,  0.0046,  0.0315,  ..., -0.0108, -0.0166,  0.0440],\n",
      "        [-0.0422, -0.0210, -0.0295,  ...,  0.0114, -0.0085,  0.0254],\n",
      "        [-0.0063,  0.0047,  0.0040,  ...,  0.0146, -0.0197, -0.0343]])), ('duration_predictor.lstm.weight_hh_l0', tensor([[ 0.0221, -0.0390, -0.0361,  ..., -0.0334,  0.0414, -0.0166],\n",
      "        [ 0.0145,  0.0148,  0.0097,  ...,  0.0140,  0.0339,  0.0337],\n",
      "        [ 0.0235, -0.0372,  0.0045,  ...,  0.0333,  0.0413, -0.0363],\n",
      "        ...,\n",
      "        [ 0.0135,  0.0414, -0.0353,  ...,  0.0003,  0.0360, -0.0179],\n",
      "        [ 0.0263,  0.0437, -0.0111,  ...,  0.0200, -0.0404, -0.0088],\n",
      "        [-0.0119,  0.0315, -0.0405,  ..., -0.0436,  0.0049, -0.0174]])), ('duration_predictor.lstm.bias_ih_l0', tensor([-0.0399,  0.0320,  0.0087,  ...,  0.0116,  0.0442,  0.0334])), ('duration_predictor.lstm.bias_hh_l0', tensor([ 0.0210,  0.0237, -0.0120,  ..., -0.0141,  0.0376, -0.0155])), ('duration_predictor.lstm.weight_ih_l0_reverse', tensor([[ 2.5910e-02, -2.6263e-02, -2.6018e-02,  ...,  2.7957e-03,\n",
      "          3.7638e-02,  4.2692e-02],\n",
      "        [-2.8448e-02,  1.1490e-02, -3.6556e-02,  ...,  3.4109e-02,\n",
      "          3.0067e-02,  3.4065e-05],\n",
      "        [-3.7033e-02,  1.0985e-02,  1.0210e-02,  ..., -4.3086e-02,\n",
      "         -2.8659e-02,  4.0152e-02],\n",
      "        ...,\n",
      "        [-3.3249e-02, -3.5282e-02,  1.5134e-02,  ...,  1.6087e-02,\n",
      "          2.6143e-02, -1.5007e-04],\n",
      "        [-1.8775e-02,  2.3585e-02, -1.0077e-03,  ..., -3.7200e-02,\n",
      "         -2.5079e-02, -1.8486e-02],\n",
      "        [ 1.8301e-02,  7.1461e-03,  3.4872e-02,  ...,  1.1325e-02,\n",
      "         -2.0046e-02,  6.2314e-03]])), ('duration_predictor.lstm.weight_hh_l0_reverse', tensor([[-0.0134, -0.0031,  0.0334,  ..., -0.0380,  0.0117, -0.0347],\n",
      "        [ 0.0339, -0.0040,  0.0311,  ..., -0.0085,  0.0261, -0.0401],\n",
      "        [-0.0036, -0.0375,  0.0240,  ..., -0.0256, -0.0098, -0.0438],\n",
      "        ...,\n",
      "        [ 0.0389,  0.0110, -0.0416,  ..., -0.0044,  0.0161, -0.0173],\n",
      "        [ 0.0441, -0.0386, -0.0437,  ...,  0.0101,  0.0371,  0.0036],\n",
      "        [-0.0245, -0.0149,  0.0440,  ...,  0.0405, -0.0064, -0.0025]])), ('duration_predictor.lstm.bias_ih_l0_reverse', tensor([-0.0209,  0.0383, -0.0207,  ..., -0.0334,  0.0429,  0.0147])), ('duration_predictor.lstm.bias_hh_l0_reverse', tensor([-0.0162, -0.0421, -0.0294,  ...,  0.0254,  0.0207, -0.0232])), ('duration_predictor.lstm.weight_ih_l1', tensor([[-0.0329, -0.0347, -0.0153,  ...,  0.0228, -0.0058,  0.0269],\n",
      "        [ 0.0036, -0.0112,  0.0151,  ...,  0.0236,  0.0252,  0.0077],\n",
      "        [-0.0400, -0.0183, -0.0215,  ...,  0.0131,  0.0360, -0.0017],\n",
      "        ...,\n",
      "        [ 0.0040,  0.0293, -0.0177,  ...,  0.0397,  0.0412, -0.0352],\n",
      "        [ 0.0319,  0.0080, -0.0152,  ...,  0.0285, -0.0007, -0.0102],\n",
      "        [-0.0385,  0.0087, -0.0285,  ...,  0.0218,  0.0220,  0.0028]])), ('duration_predictor.lstm.weight_hh_l1', tensor([[-0.0084,  0.0011,  0.0382,  ...,  0.0012,  0.0073, -0.0027],\n",
      "        [-0.0412, -0.0430,  0.0090,  ...,  0.0377,  0.0339,  0.0373],\n",
      "        [ 0.0117,  0.0423,  0.0219,  ...,  0.0333, -0.0188, -0.0105],\n",
      "        ...,\n",
      "        [ 0.0050, -0.0316,  0.0211,  ..., -0.0241, -0.0356,  0.0275],\n",
      "        [-0.0254,  0.0068, -0.0028,  ...,  0.0046,  0.0124, -0.0344],\n",
      "        [-0.0175, -0.0322,  0.0040,  ...,  0.0307,  0.0122,  0.0068]])), ('duration_predictor.lstm.bias_ih_l1', tensor([ 0.0388, -0.0043,  0.0320,  ...,  0.0007,  0.0236,  0.0212])), ('duration_predictor.lstm.bias_hh_l1', tensor([ 0.0230,  0.0410, -0.0377,  ...,  0.0258, -0.0350,  0.0218])), ('duration_predictor.lstm.weight_ih_l1_reverse', tensor([[-0.0313,  0.0291, -0.0073,  ..., -0.0008, -0.0004, -0.0281],\n",
      "        [-0.0192,  0.0383, -0.0050,  ..., -0.0260, -0.0052, -0.0108],\n",
      "        [ 0.0402, -0.0371, -0.0163,  ...,  0.0336, -0.0036,  0.0327],\n",
      "        ...,\n",
      "        [-0.0413,  0.0028,  0.0067,  ..., -0.0073,  0.0242, -0.0028],\n",
      "        [-0.0200,  0.0339,  0.0229,  ...,  0.0214,  0.0154,  0.0319],\n",
      "        [-0.0138,  0.0402, -0.0430,  ..., -0.0129, -0.0055, -0.0120]])), ('duration_predictor.lstm.weight_hh_l1_reverse', tensor([[ 0.0015, -0.0430, -0.0228,  ...,  0.0134, -0.0315, -0.0181],\n",
      "        [-0.0439, -0.0202, -0.0286,  ...,  0.0348, -0.0294,  0.0364],\n",
      "        [ 0.0183, -0.0255, -0.0340,  ...,  0.0156,  0.0125, -0.0235],\n",
      "        ...,\n",
      "        [-0.0249, -0.0166, -0.0405,  ...,  0.0370,  0.0117,  0.0399],\n",
      "        [ 0.0406, -0.0199,  0.0045,  ...,  0.0133, -0.0110,  0.0269],\n",
      "        [-0.0361, -0.0289,  0.0270,  ...,  0.0103,  0.0159,  0.0343]])), ('duration_predictor.lstm.bias_ih_l1_reverse', tensor([ 0.0237, -0.0150, -0.0305,  ...,  0.0351,  0.0430, -0.0165])), ('duration_predictor.lstm.bias_hh_l1_reverse', tensor([-0.0329, -0.0306,  0.0352,  ..., -0.0222,  0.0309, -0.0422])), ('duration_predictor.proj.linear_layer.weight', tensor([[ 0.0682, -0.0462,  0.0760,  ...,  0.0436,  0.0296,  0.0046]])), ('duration_predictor.proj.linear_layer.bias', tensor([-0.0092])), ('decoder.attention_rnn.weight_ih', tensor([[ 0.0168, -0.0133,  0.0216,  ...,  0.0047,  0.0110, -0.0168],\n",
      "        [ 0.0066, -0.0226,  0.0602,  ...,  0.0040, -0.0032, -0.0055],\n",
      "        [-0.0199, -0.0185, -0.2456,  ..., -0.0366,  0.0142, -0.0204],\n",
      "        ...,\n",
      "        [-0.0169, -0.0389, -0.0179,  ..., -0.0056, -0.0021,  0.0075],\n",
      "        [-0.0094, -0.0351, -0.0769,  ..., -0.0156, -0.0062, -0.0113],\n",
      "        [-0.0080, -0.0416,  0.0146,  ...,  0.0165, -0.0094, -0.0040]])), ('decoder.attention_rnn.weight_hh', tensor([[ 0.0667, -0.0009,  0.0134,  ..., -0.0065,  0.0182,  0.0158],\n",
      "        [ 0.0154,  0.0945, -0.0425,  ...,  0.0186,  0.0005,  0.0487],\n",
      "        [-0.0906, -0.0441,  0.0731,  ..., -0.0579,  0.0277,  0.0264],\n",
      "        ...,\n",
      "        [-0.0486,  0.0132,  0.0074,  ..., -0.0360,  0.0380,  0.0468],\n",
      "        [-0.0227,  0.0190, -0.0482,  ..., -0.0117,  0.1044, -0.0077],\n",
      "        [ 0.1041,  0.0189, -0.0175,  ..., -0.0101, -0.0532,  0.1697]])), ('decoder.attention_rnn.bias_ih', tensor([-0.0050, -0.0097,  0.0016,  ..., -0.0243,  0.0063,  0.0147])), ('decoder.attention_rnn.bias_hh', tensor([-0.0094, -0.0229,  0.0101,  ..., -0.0265,  0.0200,  0.0147])), ('decoder.attention_layer.query_layer.linear_layer.weight', tensor([[-0.0239,  0.0967,  0.1148,  ...,  0.1096, -0.1100,  0.0531],\n",
      "        [-0.0359,  0.0469,  0.0608,  ..., -0.0997, -0.0061,  0.0176],\n",
      "        [-0.0038,  0.0248, -0.0408,  ...,  0.1805,  0.0315,  0.0038],\n",
      "        ...,\n",
      "        [ 0.0258, -0.2310, -0.0418,  ..., -0.0746,  0.0953,  0.0055],\n",
      "        [ 0.0211, -0.0216,  0.0451,  ...,  0.0066, -0.0179,  0.0772],\n",
      "        [-0.1226,  0.0424,  0.1468,  ..., -0.0230,  0.0312,  0.0185]])), ('decoder.attention_layer.memory_layer.linear_layer.weight', tensor([[-0.0568,  0.0688, -0.0211,  ..., -0.1349, -0.0132, -0.0609],\n",
      "        [ 0.0394,  0.0369, -0.1144,  ..., -0.0920, -0.1232,  0.0889],\n",
      "        [ 0.0528,  0.0453, -0.0005,  ...,  0.1195,  0.1337,  0.0851],\n",
      "        ...,\n",
      "        [ 0.0439,  0.0795,  0.2247,  ..., -0.1091,  0.1462,  0.0263],\n",
      "        [-0.0032, -0.0151,  0.0226,  ...,  0.1033, -0.1477, -0.0972],\n",
      "        [-0.0687, -0.0486,  0.0240,  ..., -0.0071,  0.1186, -0.0799]])), ('decoder.attention_layer.v.linear_layer.weight', tensor([[-0.1701, -0.1633, -0.2471, -0.2126,  0.2853, -1.0387,  0.2317, -0.1266,\n",
      "         -0.2051,  0.3442, -0.5701,  0.3481, -0.6835, -0.3367,  0.2295,  0.4067,\n",
      "          0.3210,  0.4304,  0.2487, -0.3930,  0.3874,  0.2399,  0.3397, -0.2374,\n",
      "         -0.1913,  0.2472,  0.1402,  0.4380,  0.3778,  0.5430, -0.3154,  0.5384,\n",
      "         -0.1846,  0.2581, -0.1833,  0.1647, -0.1882,  0.5891,  0.5383,  0.1473,\n",
      "         -0.9692, -0.2158,  0.3263, -0.3033, -0.4187,  0.2455, -0.1749,  0.5189,\n",
      "         -0.4237,  0.2012,  0.2142, -0.2038,  0.4933,  0.2926, -0.3322,  0.9700,\n",
      "         -0.3269,  0.4060,  0.2312, -0.2001, -0.1140, -0.3993,  0.1660,  0.1811,\n",
      "         -0.1933,  0.1770, -0.5517, -0.3905, -0.2154, -0.1222, -0.3664,  0.1576,\n",
      "          0.1497,  0.2741, -0.2520,  0.5247,  0.2067,  0.7409, -0.2458, -0.2570,\n",
      "          0.4318, -0.3970,  0.4477,  0.4428,  0.2746,  0.1403,  0.1251,  0.9036,\n",
      "          0.2492,  0.1448, -0.3281,  0.6065, -0.4436, -0.5781, -0.5577,  0.2024,\n",
      "          0.6785,  0.3429, -0.1428, -0.1484, -0.4045,  0.2757,  0.1753, -0.1565,\n",
      "          0.1799, -0.1071, -0.2067, -0.1684, -0.4752, -0.1995,  0.4458,  0.3258,\n",
      "          0.1848,  0.1375, -0.1857,  0.2214, -0.2438, -0.4034,  0.1487, -0.2131,\n",
      "          0.1283,  0.2946, -0.1259,  0.4010, -0.2567,  0.1840, -0.1504,  0.2670]])), ('decoder.attention_layer.location_layer.location_conv.conv.weight', tensor([[[ 0.0330,  0.0396,  0.0106,  ...,  0.0624,  0.0838,  0.0722],\n",
      "         [-0.0268, -0.0095, -0.0032,  ..., -0.0398, -0.0029, -0.1015]],\n",
      "\n",
      "        [[-0.0484, -0.0625, -0.0547,  ..., -0.0298, -0.0445, -0.0827],\n",
      "         [-0.0196,  0.0133,  0.0219,  ..., -0.0727,  0.0170,  0.0459]],\n",
      "\n",
      "        [[ 0.0654,  0.0443,  0.0291,  ...,  0.0107, -0.0073, -0.0309],\n",
      "         [-0.0006, -0.0124, -0.0023,  ..., -0.0021, -0.0108, -0.0049]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0053, -0.0218, -0.0356,  ...,  0.0222,  0.0287,  0.0571],\n",
      "         [ 0.0320, -0.0091,  0.0032,  ...,  0.0173, -0.0019, -0.0300]],\n",
      "\n",
      "        [[ 0.0481,  0.0197,  0.0285,  ..., -0.0003, -0.0149, -0.0174],\n",
      "         [-0.0438,  0.0193, -0.0013,  ..., -0.0776, -0.0939, -0.0317]],\n",
      "\n",
      "        [[ 0.0279,  0.0398,  0.0197,  ...,  0.0009, -0.0184, -0.0081],\n",
      "         [-0.0042, -0.0138, -0.0341,  ...,  0.0059,  0.0915,  0.0596]]])), ('decoder.attention_layer.location_layer.location_dense.linear_layer.weight', tensor([[ 0.2056, -0.1850,  0.2634,  ..., -0.2608,  0.2511,  0.2636],\n",
      "        [-0.0566, -0.0959, -0.1997,  ...,  0.2041, -0.1135,  0.2263],\n",
      "        [ 0.2237,  0.1740, -0.2437,  ..., -0.2470,  0.0270,  0.1909],\n",
      "        ...,\n",
      "        [ 0.2597, -0.1369, -0.1580,  ..., -0.2336,  0.1679,  0.2805],\n",
      "        [-0.2582, -0.1467, -0.2021,  ..., -0.0353,  0.0044,  0.2521],\n",
      "        [ 0.2771, -0.1391, -0.2494,  ...,  0.1959, -0.1653, -0.0347]])), ('decoder.decoder_rnn.weight_ih', tensor([[-0.0680, -0.0159, -0.0423,  ...,  0.0268, -0.0001,  0.0379],\n",
      "        [ 0.0113,  0.0054,  0.0106,  ..., -0.0322,  0.0149, -0.0321],\n",
      "        [ 0.0087, -0.0361,  0.0604,  ..., -0.0119, -0.0101,  0.0031],\n",
      "        ...,\n",
      "        [-0.0174,  0.0576, -0.0278,  ..., -0.0174,  0.0132, -0.0042],\n",
      "        [-0.0381, -0.0358,  0.0221,  ..., -0.0160,  0.0307, -0.0003],\n",
      "        [ 0.0133,  0.0668,  0.0117,  ...,  0.0025,  0.0249,  0.0284]])), ('decoder.decoder_rnn.weight_hh', tensor([[ 0.1313,  0.0102, -0.0738,  ...,  0.0597, -0.0339, -0.0639],\n",
      "        [-0.0279,  0.0092, -0.0102,  ...,  0.0300, -0.0708, -0.0447],\n",
      "        [ 0.0352,  0.0345, -0.1609,  ..., -0.0247,  0.0231,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0118, -0.0072, -0.0365,  ..., -0.0205,  0.0085,  0.0840],\n",
      "        [ 0.0497,  0.0313, -0.2033,  ..., -0.0145, -0.0229,  0.0325],\n",
      "        [-0.0032, -0.0007, -0.0279,  ..., -0.0348,  0.0318,  0.0446]])), ('decoder.decoder_rnn.bias_ih', tensor([-0.0234, -0.0069, -0.0058,  ...,  0.0197, -0.0025, -0.0127])), ('decoder.decoder_rnn.bias_hh', tensor([-0.0286, -0.0118,  0.0249,  ..., -0.0087, -0.0088, -0.0214]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> model_dict[\"decoder.attention_layer.location_layer.location_conv.conv.weight\"]\n",
      "tensor([[[ 0.0330,  0.0396,  0.0106,  ...,  0.0624,  0.0838,  0.0722],\n",
      "         [-0.0268, -0.0095, -0.0032,  ..., -0.0398, -0.0029, -0.1015]],\n",
      "\n",
      "        [[-0.0484, -0.0625, -0.0547,  ..., -0.0298, -0.0445, -0.0827],\n",
      "         [-0.0196,  0.0133,  0.0219,  ..., -0.0727,  0.0170,  0.0459]],\n",
      "\n",
      "        [[ 0.0654,  0.0443,  0.0291,  ...,  0.0107, -0.0073, -0.0309],\n",
      "         [-0.0006, -0.0124, -0.0023,  ..., -0.0021, -0.0108, -0.0049]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0053, -0.0218, -0.0356,  ...,  0.0222,  0.0287,  0.0571],\n",
      "         [ 0.0320, -0.0091,  0.0032,  ...,  0.0173, -0.0019, -0.0300]],\n",
      "\n",
      "        [[ 0.0481,  0.0197,  0.0285,  ..., -0.0003, -0.0149, -0.0174],\n",
      "         [-0.0438,  0.0193, -0.0013,  ..., -0.0776, -0.0939, -0.0317]],\n",
      "\n",
      "        [[ 0.0279,  0.0398,  0.0197,  ...,  0.0009, -0.0184, -0.0081],\n",
      "         [-0.0042, -0.0138, -0.0341,  ...,  0.0059,  0.0915,  0.0596]]])\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Tacotron2:\n\tUnexpected key(s) in state_dict: \"decoder.attention_rnn.weight_ih\", \"decoder.attention_rnn.weight_hh\", \"decoder.attention_rnn.bias_ih\", \"decoder.attention_rnn.bias_hh\", \"decoder.attention_layer.query_layer.linear_layer.weight\", \"decoder.attention_layer.memory_layer.linear_layer.weight\", \"decoder.attention_layer.v.linear_layer.weight\", \"decoder.attention_layer.location_layer.location_conv.conv.weight\", \"decoder.attention_layer.location_layer.location_dense.linear_layer.weight\", \"decoder.decoder_rnn.weight_ih\", \"decoder.decoder_rnn.weight_hh\", \"decoder.decoder_rnn.bias_ih\", \"decoder.decoder_rnn.bias_hh\". \n\tsize mismatch for decoder.linear_projection.linear_layer.weight: copying a param with shape torch.Size([80, 1536]) from checkpoint, the shape in current model is torch.Size([80, 1568]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32102/2684241687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTacotron2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m tt2.from_pretrained(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mwarm_start_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/models/base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(self, warm_start_path, device, ignore_layers, model_dict)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Tacotron2:\n\tUnexpected key(s) in state_dict: \"decoder.attention_rnn.weight_ih\", \"decoder.attention_rnn.weight_hh\", \"decoder.attention_rnn.bias_ih\", \"decoder.attention_rnn.bias_hh\", \"decoder.attention_layer.query_layer.linear_layer.weight\", \"decoder.attention_layer.memory_layer.linear_layer.weight\", \"decoder.attention_layer.v.linear_layer.weight\", \"decoder.attention_layer.location_layer.location_conv.conv.weight\", \"decoder.attention_layer.location_layer.location_dense.linear_layer.weight\", \"decoder.decoder_rnn.weight_ih\", \"decoder.decoder_rnn.weight_hh\", \"decoder.decoder_rnn.bias_ih\", \"decoder.decoder_rnn.bias_hh\". \n\tsize mismatch for decoder.linear_projection.linear_layer.weight: copying a param with shape torch.Size([80, 1536]) from checkpoint, the shape in current model is torch.Size([80, 1568])."
     ]
    }
   ],
   "source": [
    "tt2 = Tacotron2(HParams(**config))\n",
    "tt2.from_pretrained(warm_start_path=hparams.warm_start_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.positional_embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tacotron2(hparams)\n",
    "if torch.cuda.is_available() and hparams.cudnn_enabled:\n",
    "    model.cuda()\n",
    "trainer = Tacotron2Trainer(hparams, rank=0, world_size=0)\n",
    "train_set, val_set, train_loader, sampler, collate_fn = trainer.initialize_loader(\n",
    "    include_durations=hparams.include_durations\n",
    ")\n",
    "batch = next(enumerate(train_loader))[1]\n",
    "X, y = model.parse_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_output = model(X)\n",
    "# assert len(forward_output) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "config = NON_ATTENTIVE_DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14617b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b93cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.trainer.tacotron2 import Tacotron2Trainer\n",
    "import json\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "\n",
    "config = DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "hparams.speaker_embedding_dim = 1\n",
    "model = Tacotron2(hparams)\n",
    "if torch.cuda.is_available() and hparams.cudnn_enabled:\n",
    "    model.cuda()\n",
    "trainer = Tacotron2Trainer(hparams, rank=0, world_size=0)\n",
    "train_set, val_set, train_loader, sampler, collate_fn = trainer.initialize_loader()\n",
    "batch = next(enumerate(train_loader))[1]\n",
    "\n",
    "X, y = model.parse_batch(batch)\n",
    "forward_output = model(X)\n",
    "# assert len(forward_output) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_output.mel_outputs_postnet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c29d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(enumerate(train_loader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ef875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "from uberduck_ml_dev.data_loader import MelSTFT\n",
    "from uberduck_ml_dev.text.symbols import NVIDIA_TACO2_SYMBOLS\n",
    "from uberduck_ml_dev.text.util import text_to_sequence\n",
    "from uberduck_ml_dev.utils.plot import plot_attention, plot_attention_phonemes\n",
    "from uberduck_ml_dev.vocoders.hifigan import HiFiGanGenerator\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "model = Tacotron2(DEFAULTS)\n",
    "loaded = torch.load(\"../models/tacotron2-eminem-arpabet-400-2021-12-14.pt\")\n",
    "model.load_state_dict(loaded)\n",
    "hg = HiFiGanGenerator(\"../models/config_v1.json\", \"../models/g_02590000_8spk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3629122",
   "metadata": {},
   "source": [
    "## Example: partial teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "%matplotlib inline\n",
    "model.eval()\n",
    "sequence = torch.LongTensor(\n",
    "    text_to_sequence(\n",
    "        \"Let's hope this is a high variance utterance.\",\n",
    "        [\"english_cleaners\"],\n",
    "        p_arpabet=1,\n",
    "        symbol_set=NVIDIA_TACO2_SYMBOLS,\n",
    "    )\n",
    ")\n",
    "mel_out, mel_out_postnet, gate_out, attn, *_ = model.inference(\n",
    "    (sequence[None], torch.LongTensor([len(sequence)]), [0])\n",
    ")\n",
    "audio = hg.infer(mel_out_postnet)\n",
    "display(Audio(audio, rate=22050))\n",
    "plot_attention_phonemes(\n",
    "    sequence, attn[0].transpose(0, 1), symbol_set=NVIDIA_TACO2_SYMBOLS\n",
    ")\n",
    "new_sequence = torch.LongTensor(\n",
    "    text_to_sequence(\n",
    "        \"Let's hope this is a highlight of your life.\",\n",
    "        [\"english_cleaners\"],\n",
    "        p_arpabet=1,\n",
    "        symbol_set=NVIDIA_TACO2_SYMBOLS,\n",
    "    )\n",
    ")\n",
    "_mel_out, _mel_out_postnet, _gate_out, _attn = model.inference_partial_tf(\n",
    "    (new_sequence[None], torch.LongTensor([len(new_sequence)])), mel_out_postnet, 90,\n",
    ")\n",
    "audio = hg.infer(_mel_out_postnet)\n",
    "display(Audio(audio, rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a95e52",
   "metadata": {},
   "source": [
    "## Example: attention-guided rhythm transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "model.eval()\n",
    "sequence = torch.LongTensor(\n",
    "    text_to_sequence(\n",
    "        \"Let's hope this is a high variance utterance.\",\n",
    "        [\"english_cleaners\"],\n",
    "        p_arpabet=1,\n",
    "        symbol_set=NVIDIA_TACO2_SYMBOLS,\n",
    "    )\n",
    ")\n",
    "mel_out, mel_out_postnet, gate_out, prev_attn, *_ = model.inference(\n",
    "    (sequence[None], torch.LongTensor([len(sequence)]), [0])\n",
    ")\n",
    "shortened_attn = torch.empty(\n",
    "    prev_attn.shape[1] // 2, prev_attn.shape[0], prev_attn.shape[2]\n",
    ")\n",
    "shortened_attn.shape\n",
    "for idx in range(len(shortened_attn)):\n",
    "    shortened_attn[idx, :, :] = (\n",
    "        prev_attn[:, 2 * idx, :] + prev_attn[:, 2 * idx + 1, :]\n",
    "    ) / 2\n",
    "\n",
    "plot_attention(shortened_attn.transpose(0, 1)[0])\n",
    "\n",
    "transcription = \"Well you know as you know the web's a pretty miraculous thing and it was a very simple paradigm that was invented which was.\"\n",
    "mel = torch.load(\"./test/fixtures/stevejobs-1.pt\")\n",
    "\n",
    "input_text = text_to_sequence(\n",
    "    transcription,\n",
    "    p_arpabet=1,\n",
    "    symbol_set=NVIDIA_TACO2_SYMBOLS,\n",
    "    cleaner_names=[\"english_cleaners\"],\n",
    ")\n",
    "input_lengths = torch.LongTensor([len(input_text)])\n",
    "input_text = torch.LongTensor(input_text)[None]\n",
    "print(input_text.shape)\n",
    "targets = mel[None]\n",
    "print(targets.shape)\n",
    "max_len = targets.size(2)\n",
    "output_lengths = torch.LongTensor([targets.size(2)])\n",
    "speaker_ids = torch.LongTensor([0])\n",
    "input_ = (input_text, input_lengths, targets, max_len, output_lengths, speaker_ids)\n",
    "\n",
    "model_out = model.forward(input_)\n",
    "print(len(model_out))\n",
    "mel_out, mel_out_postnet, gate_out, attn = model_out\n",
    "print(input_text.shape, input_lengths.shape, speaker_ids.shape, attn.shape)\n",
    "\n",
    "plot_attention_phonemes(input_text[0], attn[0].transpose(0, 1), NVIDIA_TACO2_SYMBOLS)\n",
    "\n",
    "mel, mel_postnet, gate, attn = model.inference_noattention(\n",
    "    [input_text, input_lengths, speaker_ids, attn.transpose(0, 1)]\n",
    ")\n",
    "\n",
    "input_text.shape, attn.shape\n",
    "\n",
    "audio = hg.infer(mel_postnet)\n",
    "display(Audio(audio, rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f157e0",
   "metadata": {},
   "source": [
    "## Example: has_speaker_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "import IPython.display as ipd\n",
    "\n",
    "from uberduck_ml_dev.text.symbols import NVIDIA_TACO2_SYMBOLS\n",
    "from uberduck_ml_dev.text.util import text_to_sequence\n",
    "from uberduck_ml_dev.utils.audio import mel_to_audio\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "tt = Tacotron2(DEFAULTS)\n",
    "t1_count = count_parameters(tt)\n",
    "config = dict(DEFAULTS.values())\n",
    "config[\"has_speaker_embedding\"] = True\n",
    "tt2 = Tacotron2(HParams(**config))\n",
    "t2_count = count_parameters(tt2)\n",
    "assert t1_count < t2_count\n",
    "tt2.from_pretrained(\n",
    "    model_dict=torch.load(\"../models/tacotron2-eminem-arpabet-400-2021-12-14.pt\")\n",
    ")\n",
    "tt.from_pretrained(\n",
    "    model_dict=torch.load(\"../models/tacotron2-eminem-arpabet-400-2021-12-14.pt\")\n",
    ")\n",
    "seq = text_to_sequence(\n",
    "    \"The quick brown fox jumped over the lazy dog.\",\n",
    "    [\"english_cleaners\"],\n",
    "    p_arpabet=1.0,\n",
    "    symbol_set=NVIDIA_TACO2_SYMBOLS,\n",
    ")\n",
    "seq = torch.IntTensor(seq)[None]\n",
    "print(seq.shape)\n",
    "mel, mel_postnet, _, _, _ = tt.inference(\n",
    "    (seq, torch.LongTensor([seq.size(1)]), torch.LongTensor([0]))\n",
    ")\n",
    "audio = mel_to_audio(mel_postnet[0])\n",
    "\n",
    "ipd.display(ipd.Audio(audio.data.numpy(), rate=22050))\n",
    "mel, mel_postnet, *_ = tt2.inference(\n",
    "    (seq, torch.LongTensor([seq.size(1)]), torch.LongTensor([0]))\n",
    ")\n",
    "audio = mel_to_audio(mel_postnet[0])\n",
    "ipd.display(ipd.Audio(audio.data.numpy(), rate=22050))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
