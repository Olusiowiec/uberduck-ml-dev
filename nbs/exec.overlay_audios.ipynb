{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9493bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exec.overlay_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8686d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import argparse\n",
    "import sys\n",
    "import librosa  # NOTE(zach): importing torch before librosa causes LLVM issues for some unknown reason.\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-d\",\"--data-folder\", help=\"Path to folder with .wav files\")\n",
    "    parser.add_argument(\"-b\",\"--background\" help=\"Path to single .wav background file\")\n",
    "    args = parser.parse_args(args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ebe102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run(hparams):\n",
    "\n",
    "    music_audio_segment = AudioSegment.from_file(args.background)\n",
    "\n",
    "    for file in os.listdir(args.data_folder):\n",
    "        if os.path.splitext(file)[-1].lower() == \".wav\":\n",
    "\n",
    "            played_togther = vocal_audio_segment.overlay(music_audio_segment)\n",
    "\n",
    "    # Create model\n",
    "    model = GradTTS(hparams)\n",
    "    model.load_state_dict(torch.load(hparams.checkpoint))\n",
    "    model = model.cuda()\n",
    "\n",
    "    stft = MelSTFT(\n",
    "        filter_length=hparams.filter_length,\n",
    "        hop_length=hparams.hop_length,\n",
    "        win_length=hparams.win_length,\n",
    "        n_mel_channels=hparams.n_feats,\n",
    "        sampling_rate=hparams.sampling_rate,\n",
    "        mel_fmin=hparams.mel_fmin,\n",
    "        mel_fmax=hparams.mel_fmax,\n",
    "        padding=(hparams.filter_length - hparams.hop_length) // 2,\n",
    "    )\n",
    "\n",
    "    hifigan = HiFiGanGenerator(\n",
    "        config=hparams.hifigan_config,\n",
    "        checkpoint=hparams.hifigan_checkpoint,\n",
    "        cudnn_enabled=True,\n",
    "    )\n",
    "\n",
    "    # Get reference audio mel spectrogram\n",
    "    #     sample_rate, wav_data = read(hparams.reference_audio)\n",
    "    vocal_data, vocal_sample_rate = librosa.load(\n",
    "        hparams.reference_vocals, sr=hparams.sampling_rate\n",
    "    )\n",
    "    music_data, music_sample_rate = librosa.load(\n",
    "        hparams.reference_music, sr=hparams.sampling_rate\n",
    "    )\n",
    "    music_data = music_data / hparams.max_wav_value\n",
    "    assert vocal_sample_rate == music_sample_rate\n",
    "\n",
    "    #     audio_norm = torch.FloatTensor(wav_data) / hparams.max_wav_value\n",
    "    audio_norm = torch.FloatTensor(vocal_data) / hparams.max_wav_value\n",
    "    audio_norm = audio_norm.unsqueeze(0)\n",
    "    melspec_original = stft.mel_spectrogram(audio_norm).cuda()\n",
    "\n",
    "    with open(hparams.customizations, \"r\") as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        for i, row in enumerate(datareader):\n",
    "            regex = r\"\\|(.*?)\\|\"\n",
    "            substitution = f\"| {row[1]} |\"\n",
    "            new_transcription = re.sub(regex, substitution, hparams.transcription)\n",
    "            print(new_transcription)\n",
    "\n",
    "            y_dec1, y_dec2, y_dec_edit, y_dec_cat = model.infer_editts_edit_content(\n",
    "                hparams.transcription,\n",
    "                new_transcription,\n",
    "                n_timesteps=10,\n",
    "                symbol_set=\"gradtts\",\n",
    "                mel1=melspec_original.cuda(),\n",
    "            )\n",
    "            personalized_vocals = hifigan.infer(y_dec_edit)\n",
    "\n",
    "            #             vocal_pydub = AudioSegment.from\n",
    "            vocal_audio_segment = AudioSegment(\n",
    "                personalized_vocals.tobytes(),\n",
    "                frame_rate=vocal_sample_rate,\n",
    "                sample_width=personalized_vocals.dtype.itemsize,\n",
    "                channels=1,\n",
    "            )\n",
    "\n",
    "            music_audio_segment = AudioSegment.from_file(hparams.reference_music)\n",
    "\n",
    "            played_togther = vocal_audio_segment.overlay(music_audio_segment)\n",
    "\n",
    "            #             final_audio = overlay(personalized_vocals, music_data)\n",
    "            #             sound.get_array_of_samples()\n",
    "            #             melspec = stft.mel_spectrogram(audio_norm).cuda()\n",
    "            #             plot_spectrogram(melspec.squeeze().cpu())\n",
    "            #             plt.show()\n",
    "            played_together.export(f\"{hparams.log_dir}/edited_{i}.wav\")\n",
    "\n",
    "\n",
    "#             write(f\"{hparams.log_dir}/edited_{i}.wav\", hparams.sampling_rate, final_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f84292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "try:\n",
    "    from nbdev.imports import IN_NOTEBOOK\n",
    "except:\n",
    "    IN_NOTEBOOK = False\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    args = parse_args(sys.argv[1:])\n",
    "    config = GRADTTS_DEFAULTS.values()\n",
    "    if args.config:\n",
    "        with open(args.config) as f:\n",
    "            config.update(json.load(f))\n",
    "    hparams = HParams(**config)\n",
    "    run(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63ced84f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This year you won | one hundred | now that's a stack\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'played_together' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25805/2251705691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25805/4206357652.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#             plot_spectrogram(melspec.squeeze().cpu())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#             plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mplayed_together\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{hparams.log_dir}/edited_{i}.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m#             write(f\"{hparams.log_dir}/edited_{i}.wav\", hparams.sampling_rate, final_audio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'played_together' is not defined"
     ]
    }
   ],
   "source": [
    "config = GRADTTS_DEFAULTS.values()\n",
    "with open(\"../configs/editts.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "run(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82087a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def overlay(audio1, audio2):\n",
    "#     audio1_padded = np.pad(audio1, (0,max(0,len(audio2)-len(audio1))))\n",
    "#     audio2_padded = np.pad(audio2, (0,max(0,len(audio1)-len(audio2))))\n",
    "#     return audio1_padded + audio2_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d345cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "wav1, s1 = librosa.load(\"../data/beat_trim.wav\", sr=22050)\n",
    "wav2, s2 = librosa.load(\"../data/vocal_trim.wav\", sr=22050)\n",
    "\n",
    "assert s1 == s2, \"sample rates must be equal\"\n",
    "overlay_wav = overlay(wav1, wav2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(overlay_wav, rate=22050)  # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e590ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ipd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25805/3455509709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load a local WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ipd' is not defined"
     ]
    }
   ],
   "source": [
    "ipd.Audio(wav1, rate=22050)  # load a local WAV file\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c82de0ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ipd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25805/4143477486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load a local WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ipd' is not defined"
     ]
    }
   ],
   "source": [
    "ipd.Audio(wav2, rate=22050)  # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1, 1])\n",
    "y = np.array([2, 2, 2, 2, 2, 2])\n",
    "\n",
    "x = np.pad(x, (0, len(y) - len(x)))\n",
    "y = np.pad(y, (0, len(x) - len(y)))\n",
    "\n",
    "print(x, y)\n",
    "print(z.shape)\n",
    "\n",
    "print(z + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f97eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
