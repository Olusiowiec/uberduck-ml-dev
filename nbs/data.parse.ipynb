{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7467cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dab9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# def load_filepaths_and_text(filename: str, split: str = \"|\"):\n",
    "#     with open(filename, encoding=\"utf-8\") as f:\n",
    "#         filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "#     return filepaths_and_text\n",
    "\n",
    "# def _parse_vctk(root: str):\n",
    "#     \"\"\"Parse VCTK dataset and return a dict representation.\"\"\"\n",
    "#     wav_dir = os.path.join(root, \"wav48_silence_trimmed\")\n",
    "#     txt_dir = os.path.join(root, \"txt\")\n",
    "#     speaker_wavs = os.listdir(wav_dir)\n",
    "#     speaker_txts = os.listdir(txt_dir)\n",
    "#     speakers = list(set(speaker_wavs) & set(speaker_txts))\n",
    "#     output_dict = {}\n",
    "#     for speaker in speakers:\n",
    "#         speaker_wav_dir = os.path.join(wav_dir, speaker)\n",
    "#         speaker_txt_dir = os.path.join(txt_dir, speaker)\n",
    "#         wav_files_speaker = np.asarray(os.listdir(speaker_wav_dir))\n",
    "#         txt_files_speaker = np.asarray(os.listdir(speaker_txt_dir))\n",
    "\n",
    "#         transcription_basenames = np.asarray([t[:8] for t in txt_files_speaker])\n",
    "#         audio_basenames = np.asarray([w[:8] for w in wav_files_speaker])\n",
    "#         mic = np.asarray([w[12] for w in wav_files_speaker])\n",
    "#         mic1_ind = mic == \"1\"\n",
    "#         wav_files_speaker = wav_files_speaker[mic1_ind]\n",
    "#         audio_basenames = audio_basenames[mic1_ind]\n",
    "\n",
    "#         combined_files = np.intersect1d(transcription_basenames, audio_basenames)\n",
    "#         matching_inds1 = np.where(np.isin(transcription_basenames, combined_files))[0]\n",
    "#         matching_inds2 = np.where(np.isin(audio_basenames, combined_files))[0]\n",
    "#         inds1 = matching_inds1[transcription_basenames[matching_inds1].argsort()]\n",
    "#         inds2 = matching_inds2[audio_basenames[matching_inds2].argsort()]\n",
    "#         txt_files_speaker = txt_files_speaker[inds1]\n",
    "#         wav_files_speaker = wav_files_speaker[inds2]\n",
    "#         texts, wavs = [], []\n",
    "#         for text_basename, wav_basename in zip(txt_files_speaker, wav_files_speaker):\n",
    "#             text_file = os.path.join(speaker_txt_dir, text_basename)\n",
    "#             with open(text_file) as f:\n",
    "#                 contents = f.read().strip(\"\\n\")\n",
    "#             texts.append(contents)\n",
    "#             wav_file = os.path.join(speaker_wav_dir, wav_basename)\n",
    "#             wavs.append(wav_file)\n",
    "\n",
    "#         if len(wavs):\n",
    "#             output_dict[speaker] = list(zip(texts, wavs))\n",
    "#     return output_dict\n",
    "\n",
    "# def _convert_vctk(f, inp: str):\n",
    "#     vctk_data = parse_vctk(inp)\n",
    "#     speaker_id = 0\n",
    "#     conn = sqlite3.connect(str(CACHE_LOCATION))\n",
    "#     with conn:\n",
    "#         for speaker_name, speaker_data in tqdm(vctk_data.items()):\n",
    "#             insert_speaker(f.name, speaker_name, speaker_id, conn)\n",
    "#             speaker_out_path = Path(out_path) / speaker_name\n",
    "#             if not speaker_out_path.exists():\n",
    "#                 os.makedirs(speaker_out_path)\n",
    "#             for transcription, flac_path in speaker_data:\n",
    "#                 assert flac_path.endswith(\".flac\")\n",
    "#                 wav_path = flac_path.replace(\".flac\", \".wav\")\n",
    "#                 convert_to_wav(flac_path, wav_path)\n",
    "#                 full_path = Path(full_path).resolve()\n",
    "#                 f.write(f\"{full_path}|{transcription}|{speaker_id}\\n\")\n",
    "#             speaker_id += 1\n",
    "\n",
    "import sqlite3\n",
    "import uuid\n",
    "from pathlib import PosixPath\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "CACHE_LOCATION = Path.home() / Path(\".cache/uberduck/uberduck-ml-exp.db\")\n",
    "STANDARD_MULTISPEAKER = \"standard-multispeaker\"\n",
    "STANDARD_SINGLESPEAKER = \"standard-singlespeaker\"\n",
    "VCTK = \"vctk\"\n",
    "\n",
    "\n",
    "def _log_filelists(\n",
    "    file, fmt, conn, speaker_name: str, dir_path: str = None, dataset_name: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    logs a filelist into the speaker database\n",
    "    \"\"\"\n",
    "    if fmt == STANDARD_MULTISPEAKER:\n",
    "        _parse_ms(file, dir_path=dir_path, dataset_name=dataset_name)\n",
    "    if fmt == STANDARD_SINGLESPEAKER:\n",
    "        _parse_ss(\n",
    "            conn=conn,\n",
    "            root=file,\n",
    "            speaker_name=speaker_name,\n",
    "            dir_path=dir_path,\n",
    "            dataset_name=dataset_name,\n",
    "        )\n",
    "    if fmt == VCTK:\n",
    "        raise\n",
    "\n",
    "\n",
    "def _add_speaker_to_db(\n",
    "    filelist_path: str,\n",
    "    speaker_name: str,\n",
    "    speaker_id=None,\n",
    "    dir_path: str = None,\n",
    "    rel_path: str = None,\n",
    "    dataset_name: str = None,\n",
    "    conn=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    filelist: the path of the filelist being added\n",
    "    speaker_name: the name of the speaker\n",
    "    dir_path: the path of the data repository containing the filelist\n",
    "    rel_path: the path of the wavs within the repository\n",
    "    dataset_name: the name of the dataset\n",
    "    \"\"\"\n",
    "    uuid_ = uuid.uuid4()\n",
    "    if conn is None:\n",
    "        conn = sqlite3.connect(str(CACHE_LOCATION_EXP))\n",
    "    conn.execute(\n",
    "        \"INSERT OR REPLACE INTO FILELISTS VALUES (?, ?, ?,?,?,?,?)\",\n",
    "        (\n",
    "            str(uuid_),\n",
    "            filelist_path,\n",
    "            speaker_name,\n",
    "            speaker_id,\n",
    "            dir_path,\n",
    "            rel_path,\n",
    "            dataset_name,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def _parse_ms(root: str, dir_path: str, dataset_name: str, conn):\n",
    "    speakers = os.listdir(root)\n",
    "    for speaker in tqdm(speakers):\n",
    "        path = Path(root) / Path(speaker)\n",
    "        if not path.is_dir() or path.parts[-1].startswith(\".\"):\n",
    "            continue\n",
    "        _parse_ss(\n",
    "            root=path,\n",
    "            speaker_name=speaker,\n",
    "            speaker_id=None,\n",
    "            dir_path=dir_path,\n",
    "            dataset_name=dataset_name,\n",
    "            rel_path=speaker,\n",
    "            conn=conn,\n",
    "        )\n",
    "\n",
    "\n",
    "def _parse_ss(\n",
    "    conn,\n",
    "    root: str,\n",
    "    speaker_name: str,\n",
    "    speaker_id=None,\n",
    "    dir_path: str = None,\n",
    "    dataset_name: str = None,\n",
    "    rel_path=\"\",\n",
    "):\n",
    "    files = os.listdir(root)\n",
    "    filelist_paths = [f for f in files if f.endswith(\".txt\")]\n",
    "    for filelist_path in filelist_paths:\n",
    "        _add_speaker_to_db(\n",
    "            filelist_path=filelist_path,\n",
    "            speaker_name=speaker_name,\n",
    "            speaker_id=speaker_id,\n",
    "            dir_path=dir_path,\n",
    "            dataset_name=dataset_name,\n",
    "            rel_path=rel_path,\n",
    "            conn=conn,\n",
    "        )\n",
    "\n",
    "\n",
    "def _generate_filelist(config_path, conn):\n",
    "\n",
    "    conn = sqlite3.connect(str(CACHE_LOCATION_EXP))\n",
    "    with open(config_path) as f:\n",
    "        filelist_config = json.load(f)\n",
    "    speaker_id = 0\n",
    "    save_path = Path(filelist_config[\"output\"])\n",
    "    exp_path = Path(os.path.join(*peth.parts[:-1]))\n",
    "    if not os.path.exists(exp_path):\n",
    "        exp_path.mkdir(parents=True)\n",
    "    with open(save_path, \"w\") as f_out:\n",
    "        for filelist in filelist_config[\"filelists\"]:\n",
    "            uuid = filelist[\"uuid\"]\n",
    "            dir_path = filelist[\"dir_path\"]\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\n",
    "                \"SELECT DIR_PATH,REL_PATH,FILELIST_PATH FROM FILELISTS WHERE UUID == '{uuid}'\".format(\n",
    "                    uuid=uuid\n",
    "                )\n",
    "            )\n",
    "            results = cursor.fetchall()\n",
    "            assert len(results) == 1\n",
    "            in_path = Path(os.path.join(*results[0]))\n",
    "            with (in_path).open(\"r\") as txn_f:\n",
    "                transcriptions = txn_f.readlines()\n",
    "            for line in transcriptions:\n",
    "                line = line.strip(\"\\n\")\n",
    "                try:\n",
    "                    line_path, line_txn, *_ = line.split(\"|\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(line)\n",
    "                    raise\n",
    "                out_path = os.path.join(*([dir_path] + list(results[0][1:])))\n",
    "                f_out.write(f\"{out_path}|{line_txn}|{speaker_id}\\n\")\n",
    "            speaker_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06cf2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(str(CACHE_LOCATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bab7174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully........\n"
     ]
    }
   ],
   "source": [
    "CACHE_LOCATION_EXP = PosixPath(\"/home/s_uberduck_ai/.cache/uberduck/uberduck-ml-exp.db\")\n",
    "conn = sqlite3.connect(str(CACHE_LOCATION_EXP))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS FILELISTS\")\n",
    "sql = \"\"\"CREATE TABLE FILELISTS(\n",
    "   UUID CHAR(50),\n",
    "   FILELIST_PATH CHAR(100),\n",
    "   SPEAKER_NAME CHAR(50),\n",
    "   SPEAKER_ID INT,\n",
    "   DIR_PATH CHAR(100),\n",
    "   REL_PATH CHAR(100),\n",
    "   DATASET_NAME CHAR(50)\n",
    ")\"\"\"\n",
    "cursor.execute(sql)\n",
    "print(\"Table created successfully........\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1467fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_ubmulti = \"/mnt/disks/uberduck-experiments-v0/data/uberduck-multispeaker/\"\n",
    "root_eminem = \"/mnt/disks/uberduck-experiments-v0/data/uberduck-multispeaker/eminem/\"\n",
    "root_zwf = \"/mnt/disks/uberduck-experiments-v0/data/zwf/zwf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "260527e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_filelists(\n",
    "    root_zwf,\n",
    "    \"standard-singlespeaker\",\n",
    "    conn,\n",
    "    \"zwf\",\n",
    "    dir_path=\"/mnt/disks/uberduck-experiments-v0/bucket/data/zwf\",\n",
    "    dataset_name=\"zwf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ef13f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_filelists(\n",
    "    root_eminem,\n",
    "    \"standard-singlespeaker\",\n",
    "    conn,\n",
    "    \"eminem_early\",\n",
    "    dir_path=\"/mnt/disks/uberduck-experiments-v0/bucket/data/uberduck-multispeaker/eminem/\",\n",
    "    dataset_name=\"ubmulti\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dfcf82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1a45d629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>FILELIST_PATH</th>\n",
       "      <th>SPEAKER_NAME</th>\n",
       "      <th>SPEAKER_ID</th>\n",
       "      <th>DIR_PATH</th>\n",
       "      <th>REL_PATH</th>\n",
       "      <th>DATASET_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1e9e762-77b3-452e-a502-67694d3a5b46</td>\n",
       "      <td>all.txt</td>\n",
       "      <td>zwf</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/disks/uberduck-experiments-v0/bucket/data...</td>\n",
       "      <td></td>\n",
       "      <td>zwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815b5331-c8a9-45ca-afe6-9722305152f8</td>\n",
       "      <td>list.txt</td>\n",
       "      <td>zwf</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/disks/uberduck-experiments-v0/bucket/data...</td>\n",
       "      <td></td>\n",
       "      <td>zwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0fe7068d-8dd4-46dc-ba5b-516443f82ad3</td>\n",
       "      <td>list22050.txt</td>\n",
       "      <td>eminem_early</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/disks/uberduck-experiments-v0/bucket/data...</td>\n",
       "      <td></td>\n",
       "      <td>ubmulti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   UUID  FILELIST_PATH  SPEAKER_NAME  \\\n",
       "0  f1e9e762-77b3-452e-a502-67694d3a5b46        all.txt           zwf   \n",
       "1  815b5331-c8a9-45ca-afe6-9722305152f8       list.txt           zwf   \n",
       "2  0fe7068d-8dd4-46dc-ba5b-516443f82ad3  list22050.txt  eminem_early   \n",
       "\n",
       "  SPEAKER_ID                                           DIR_PATH REL_PATH  \\\n",
       "0       None  /mnt/disks/uberduck-experiments-v0/bucket/data...            \n",
       "1       None  /mnt/disks/uberduck-experiments-v0/bucket/data...            \n",
       "2       None  /mnt/disks/uberduck-experiments-v0/bucket/data...            \n",
       "\n",
       "  DATASET_NAME  \n",
       "0          zwf  \n",
       "1          zwf  \n",
       "2      ubmulti  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = conn.execute(\"SELECT * From FILELISTS\")\n",
    "cols = [column[0] for column in query.description]\n",
    "results = pd.DataFrame.from_records(data=query.fetchall(), columns=cols)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08204709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/mnt/disks/uberduck-experiments-v0/bucket/data/uberduck-multispeaker/eminem/', '', 'list22050.txt')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ece2a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(str(CACHE_LOCATION_EXP))\n",
    "# cursor = conn.cursor()\n",
    "# cursor.execute(\"SELECT DIR_PATH,REL_PATH,FILELIST_PATH FROM FILELISTS WHERE SPEAKER_NAME == 'eminem_early'\")\n",
    "# results = cursor.fetchall()\n",
    "# print(results)\n",
    "\n",
    "config_path = \"/mnt/disks/uberduck-experiments-v0/uberduck-ml-exp/configs/filelists/eminem-zwf-vertex_v2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5c1e0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(str(CACHE_LOCATION_EXP))\n",
    "with open(config_path) as f:\n",
    "    filelist_config = json.load(f)\n",
    "speaker_id = 0\n",
    "save_path = Path(filelist_config[\"output\"])\n",
    "exp_path = Path(os.path.join(*peth.parts[:-1]))\n",
    "if not os.path.exists(exp_path):\n",
    "    exp_path.mkdir(parents=True)\n",
    "with open(save_path, \"w\") as f_out:\n",
    "    for filelist in filelist_config[\"filelists\"]:\n",
    "        uuid = filelist[\"uuid\"]\n",
    "        dir_path = filelist[\"dir_path\"]\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\n",
    "            \"SELECT DIR_PATH,REL_PATH,FILELIST_PATH FROM FILELISTS WHERE UUID == '{uuid}'\".format(\n",
    "                uuid=uuid\n",
    "            )\n",
    "        )\n",
    "        results = cursor.fetchall()\n",
    "        assert len(results) == 1\n",
    "        in_path = Path(os.path.join(*results[0]))\n",
    "        with (in_path).open(\"r\") as txn_f:\n",
    "            transcriptions = txn_f.readlines()\n",
    "        for line in transcriptions:\n",
    "            line = line.strip(\"\\n\")\n",
    "            try:\n",
    "                line_path, line_txn, *_ = line.split(\"|\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(line)\n",
    "                raise\n",
    "            out_path = os.path.join(*([dir_path] + list(results[0][1:])))\n",
    "            #                out_path = (path / line_path).resolve()\n",
    "            f_out.write(f\"{out_path}|{line_txn}|{speaker_id}\\n\")\n",
    "        speaker_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b347dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peth = Path(\n",
    "    \"/mnt/disks/uberduck-experiments-v0/uberduck-ml-exp/experiments/em_zwf_vertex_v2/filelist.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5f9a659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/disks/uberduck-experiments-v0/uberduck-ml-exp/experiments/em_zwf_vertex_v2'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304e3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1868c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_data = _parse_vctk(\"/mnt/disks/uberduck-experiments-v0/data/vctk/\")\n",
    "# speaker_data['p314']\n",
    "# speaker_data['p314'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
