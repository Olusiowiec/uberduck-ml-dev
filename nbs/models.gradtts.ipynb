{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a067534",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2050747",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb666f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.gradtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import random\n",
    "import math\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from uberduck_ml_dev.models.base import TTSModel\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.text.symbols import SYMBOL_SETS\n",
    "from uberduck_ml_dev.text.util import text_to_sequence, text_to_sequence_for_editts\n",
    "from uberduck_ml_dev.utils.utils import intersperse, intersperse_emphases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class BaseModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModule, self).__init__()\n",
    "\n",
    "    @property\n",
    "    def nparams(self):\n",
    "        \"\"\"\n",
    "        Returns number of trainable parameters of the module.\n",
    "        \"\"\"\n",
    "        num_params = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                num_params += np.prod(param.detach().cpu().numpy().shape)\n",
    "        return num_params\n",
    "\n",
    "    def relocate_input(self, x: list):\n",
    "        \"\"\"\n",
    "        Relocates provided tensors to the same device set for the module.\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        for i in range(len(x)):\n",
    "            if isinstance(x[i], torch.Tensor) and x[i].device != device:\n",
    "                x[i] = x[i].to(device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class Mish(BaseModule):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(torch.nn.functional.softplus(x))\n",
    "\n",
    "\n",
    "class Upsample(BaseModule):\n",
    "    def __init__(self, dim):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = torch.nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Downsample(BaseModule):\n",
    "    def __init__(self, dim):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Rezero(BaseModule):\n",
    "    def __init__(self, fn):\n",
    "        super(Rezero, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.g = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) * self.g\n",
    "\n",
    "\n",
    "class Block(BaseModule):\n",
    "    def __init__(self, dim, dim_out, groups=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(dim, dim_out, 3, padding=1),\n",
    "            torch.nn.GroupNorm(groups, dim_out),\n",
    "            Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        output = self.block(x * mask)\n",
    "        return output * mask\n",
    "\n",
    "\n",
    "class ResnetBlock(BaseModule):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim, groups=8):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.mlp = torch.nn.Sequential(Mish(), torch.nn.Linear(time_emb_dim, dim_out))\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        if dim != dim_out:\n",
    "            self.res_conv = torch.nn.Conv2d(dim, dim_out, 1)\n",
    "        else:\n",
    "            self.res_conv = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x, mask, time_emb):\n",
    "        h = self.block1(x, mask)\n",
    "        h += self.mlp(time_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        h = self.block2(h, mask)\n",
    "        output = h + self.res_conv(x * mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LinearAttention(BaseModule):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super(LinearAttention, self).__init__()\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = torch.nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = torch.nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x)\n",
    "        q, k, v = rearrange(\n",
    "            qkv, \"b (qkv heads c) h w -> qkv b heads c (h w)\", heads=self.heads, qkv=3\n",
    "        )\n",
    "        k = k.softmax(dim=-1)\n",
    "        context = torch.einsum(\"bhdn,bhen->bhde\", k, v)\n",
    "        out = torch.einsum(\"bhde,bhdn->bhen\", context, q)\n",
    "        out = rearrange(\n",
    "            out, \"b heads c (h w) -> b (heads c) h w\", heads=self.heads, h=h, w=w\n",
    "        )\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class Residual(BaseModule):\n",
    "    def __init__(self, fn):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        output = self.fn(x, *args, **kwargs) + x\n",
    "        return output\n",
    "\n",
    "\n",
    "class SinusoidalPosEmb(BaseModule):\n",
    "    def __init__(self, dim):\n",
    "        super(SinusoidalPosEmb, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x, scale=1000):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device).float() * -emb)\n",
    "        emb = scale * x.unsqueeze(1) * emb.unsqueeze(0)\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class GradLogPEstimator2d(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_mults=(1, 2, 4),\n",
    "        groups=8,\n",
    "        n_spks=None,\n",
    "        spk_emb_dim=64,\n",
    "        n_feats=80,\n",
    "        pe_scale=1000,\n",
    "    ):\n",
    "        super(GradLogPEstimator2d, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.dim_mults = dim_mults\n",
    "        self.groups = groups\n",
    "        self.n_spks = n_spks if not isinstance(n_spks, type(None)) else 1\n",
    "        self.spk_emb_dim = spk_emb_dim\n",
    "        self.pe_scale = pe_scale\n",
    "\n",
    "        if n_spks > 1:\n",
    "            self.spk_mlp = torch.nn.Sequential(\n",
    "                torch.nn.Linear(spk_emb_dim, spk_emb_dim * 4),\n",
    "                Mish(),\n",
    "                torch.nn.Linear(spk_emb_dim * 4, n_feats),\n",
    "            )\n",
    "        self.time_pos_emb = SinusoidalPosEmb(dim)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, dim * 4), Mish(), torch.nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "\n",
    "        dims = [2 + (1 if n_spks > 1 else 0), *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "        self.downs = torch.nn.ModuleList([])\n",
    "        self.ups = torch.nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "            self.downs.append(\n",
    "                torch.nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_in, dim_out, time_emb_dim=dim),\n",
    "                        ResnetBlock(dim_out, dim_out, time_emb_dim=dim),\n",
    "                        Residual(Rezero(LinearAttention(dim_out))),\n",
    "                        Downsample(dim_out) if not is_last else torch.nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, time_emb_dim=dim)\n",
    "        self.mid_attn = Residual(Rezero(LinearAttention(mid_dim)))\n",
    "        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, time_emb_dim=dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            self.ups.append(\n",
    "                torch.nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_out * 2, dim_in, time_emb_dim=dim),\n",
    "                        ResnetBlock(dim_in, dim_in, time_emb_dim=dim),\n",
    "                        Residual(Rezero(LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        self.final_block = Block(dim, dim)\n",
    "        self.final_conv = torch.nn.Conv2d(dim, 1, 1)\n",
    "\n",
    "    def forward(self, x, mask, mu, t, spk=None):\n",
    "        if not isinstance(spk, type(None)):\n",
    "            s = self.spk_mlp(spk)\n",
    "\n",
    "        t = self.time_pos_emb(t, scale=self.pe_scale)\n",
    "        t = self.mlp(t)\n",
    "\n",
    "        if self.n_spks < 2:\n",
    "            x = torch.stack([mu, x], 1)\n",
    "        else:\n",
    "            s = s.unsqueeze(-1).repeat(1, 1, x.shape[-1])\n",
    "            x = torch.stack([mu, x, s], 1)\n",
    "        mask = mask.unsqueeze(1)\n",
    "\n",
    "        hiddens = []\n",
    "        masks = [mask]\n",
    "        for resnet1, resnet2, attn, downsample in self.downs:\n",
    "            mask_down = masks[-1]\n",
    "            x = resnet1(x, mask_down, t)\n",
    "            x = resnet2(x, mask_down, t)\n",
    "            x = attn(x)\n",
    "            hiddens.append(x)\n",
    "            x = downsample(x * mask_down)\n",
    "            masks.append(mask_down[:, :, :, ::2])\n",
    "\n",
    "        masks = masks[:-1]\n",
    "        mask_mid = masks[-1]\n",
    "        x = self.mid_block1(x, mask_mid, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, mask_mid, t)\n",
    "\n",
    "        for resnet1, resnet2, attn, upsample in self.ups:\n",
    "            mask_up = masks.pop()\n",
    "            x = torch.cat((x, hiddens.pop()), dim=1)\n",
    "            x = resnet1(x, mask_up, t)\n",
    "            x = resnet2(x, mask_up, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x * mask_up)\n",
    "\n",
    "        x = self.final_block(x, mask)\n",
    "        output = self.final_conv(x * mask)\n",
    "\n",
    "        return (output * mask).squeeze(1)\n",
    "\n",
    "\n",
    "def get_noise(t, beta_init, beta_term, cumulative=False):\n",
    "    if cumulative:\n",
    "        noise = beta_init * t + 0.5 * (beta_term - beta_init) * (t ** 2)\n",
    "    else:\n",
    "        noise = beta_init + (beta_term - beta_init) * t\n",
    "    return noise\n",
    "\n",
    "\n",
    "class Diffusion(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats,\n",
    "        dim,\n",
    "        n_spks=1,\n",
    "        spk_emb_dim=64,\n",
    "        beta_min=0.05,\n",
    "        beta_max=20,\n",
    "        pe_scale=1000,\n",
    "    ):\n",
    "        super(Diffusion, self).__init__()\n",
    "        self.n_feats = n_feats\n",
    "        self.dim = dim\n",
    "        self.n_spks = n_spks\n",
    "        self.spk_emb_dim = spk_emb_dim\n",
    "        self.beta_min = beta_min\n",
    "        self.beta_max = beta_max\n",
    "        self.pe_scale = pe_scale\n",
    "\n",
    "        self.estimator = GradLogPEstimator2d(\n",
    "            dim, n_spks=n_spks, spk_emb_dim=spk_emb_dim, pe_scale=pe_scale\n",
    "        )\n",
    "\n",
    "    def forward_diffusion(self, x0, mask, mu, t):\n",
    "        time = t.unsqueeze(-1).unsqueeze(-1)\n",
    "        cum_noise = get_noise(time, self.beta_min, self.beta_max, cumulative=True)\n",
    "        mean = x0 * torch.exp(-0.5 * cum_noise) + mu * (\n",
    "            1.0 - torch.exp(-0.5 * cum_noise)\n",
    "        )\n",
    "        variance = 1.0 - torch.exp(-cum_noise)\n",
    "        z = torch.randn(x0.shape, dtype=x0.dtype, device=x0.device, requires_grad=False)\n",
    "        xt = mean + z * torch.sqrt(variance)\n",
    "        return xt * mask, z * mask\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reverse_diffusion(self, z, mask, mu, n_timesteps, stoc=False, spk=None):\n",
    "        h = 1.0 / n_timesteps\n",
    "        xt = z * mask\n",
    "        for i in range(n_timesteps):\n",
    "            t = (1.0 - (i + 0.5) * h) * torch.ones(\n",
    "                z.shape[0], dtype=z.dtype, device=z.device\n",
    "            )\n",
    "            time = t.unsqueeze(-1).unsqueeze(-1)\n",
    "            noise_t = get_noise(time, self.beta_min, self.beta_max, cumulative=False)\n",
    "            if stoc:  # adds stochastic term\n",
    "                dxt_det = 0.5 * (mu - xt) - self.estimator(xt, mask, mu, t, spk)\n",
    "                dxt_det = dxt_det * noise_t * h\n",
    "                dxt_stoc = torch.randn(\n",
    "                    z.shape, dtype=z.dtype, device=z.device, requires_grad=False\n",
    "                )\n",
    "                dxt_stoc = dxt_stoc * torch.sqrt(noise_t * h)\n",
    "                dxt = dxt_det + dxt_stoc\n",
    "            else:\n",
    "                dxt = 0.5 * (mu - xt - self.estimator(xt, mask, mu, t, spk))\n",
    "                dxt = dxt * noise_t * h\n",
    "            xt = (xt - dxt) * mask\n",
    "        return xt\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, z, mask, mu, n_timesteps, stoc=False, spk=None):\n",
    "        return self.reverse_diffusion(z, mask, mu, n_timesteps, stoc, spk)\n",
    "\n",
    "    def loss_t(self, x0, mask, mu, t, spk=None):\n",
    "        xt, z = self.forward_diffusion(x0, mask, mu, t)\n",
    "        time = t.unsqueeze(-1).unsqueeze(-1)\n",
    "        cum_noise = get_noise(time, self.beta_min, self.beta_max, cumulative=True)\n",
    "        noise_estimation = self.estimator(xt, mask, mu, t, spk)\n",
    "        noise_estimation *= torch.sqrt(1.0 - torch.exp(-cum_noise))\n",
    "        loss = torch.sum((noise_estimation + z) ** 2) / (torch.sum(mask) * self.n_feats)\n",
    "        return loss, xt\n",
    "\n",
    "    def compute_loss(self, x0, mask, mu, spk=None, offset=1e-5):\n",
    "        t = torch.rand(\n",
    "            x0.shape[0], dtype=x0.dtype, device=x0.device, requires_grad=False\n",
    "        )\n",
    "        t = torch.clamp(t, offset, 1.0 - offset)\n",
    "        return self.loss_t(x0, mask, mu, t, spk)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def double_forward_pitch(\n",
    "        self,\n",
    "        z,\n",
    "        z_edit,\n",
    "        mu,\n",
    "        mu_edit,\n",
    "        mask,\n",
    "        mask_edit,\n",
    "        n_timesteps,\n",
    "        stoc=False,\n",
    "        soften_mask=True,\n",
    "        n_soften=20,\n",
    "    ):\n",
    "        if soften_mask:\n",
    "            kernel = [\n",
    "                2 ** ((n_soften - 1) - abs(n_soften - 1 - i))\n",
    "                for i in range(2 * n_soften - 1)\n",
    "            ]  # [1, 2, 4, ..., 2^n_soften , 2^(n_soften-1), ..., 2, 1]\n",
    "            kernel = [i / sum(kernel[: len(kernel) // 2 + 1]) for i in kernel]\n",
    "            w = torch.tensor(kernel).view(1, 1, 1, len(kernel)).to(mask_edit.device)\n",
    "            mask_edit_soft = mask_edit.unsqueeze(1).contiguous()\n",
    "            mask_edit_soft = F.pad(\n",
    "                mask_edit_soft,\n",
    "                (len(kernel) // 2, len(kernel) // 2, 0, 0),\n",
    "                mode=\"replicate\",\n",
    "            )\n",
    "            mask_edit_soft = F.conv2d(\n",
    "                mask_edit_soft,\n",
    "                w,\n",
    "                bias=None,\n",
    "                stride=1,\n",
    "            )\n",
    "            mask_edit_soft = mask_edit_soft.squeeze(1)\n",
    "            mask_edit = mask_edit + (1 - mask_edit) * mask_edit_soft\n",
    "\n",
    "        h = 1.0 / n_timesteps\n",
    "        xt = z * mask\n",
    "        xt_edit = z_edit * mask\n",
    "\n",
    "        for i in range(n_timesteps):\n",
    "            t = (1.0 - (i + 0.5) * h) * torch.ones(\n",
    "                z.shape[0], dtype=z.dtype, device=z.device\n",
    "            )\n",
    "            time = t.unsqueeze(-1).unsqueeze(-1)\n",
    "            noise_t = get_noise(time, self.beta_min, self.beta_max, cumulative=False)\n",
    "            if stoc:  # adds stochastic term\n",
    "                # NOTE: should not come here\n",
    "                assert False\n",
    "                dxt_det = 0.5 * (mu - xt) - self.estimator(xt, mask, mu, t)\n",
    "                dxt_det = dxt_det * noise_t * h\n",
    "                dxt_stoc = torch.randn(\n",
    "                    z.shape, dtype=z.dtype, device=z.device, requires_grad=False\n",
    "                )\n",
    "                dxt_stoc = dxt_stoc * torch.sqrt(noise_t * h)\n",
    "                dxt = dxt_det + dxt_stoc\n",
    "            else:\n",
    "                dxt = 0.5 * (mu - xt - self.estimator(xt, mask, mu, t))\n",
    "                dxt = dxt * noise_t * h\n",
    "                dxt_edit = 0.5 * (\n",
    "                    mu_edit - xt_edit - self.estimator(xt_edit, mask, mu_edit, t)\n",
    "                )\n",
    "                dxt_edit = dxt_edit * noise_t * h\n",
    "            xt = (xt - dxt) * mask\n",
    "            xt_edit = (xt_edit - ((1 - mask_edit) * dxt + mask_edit * dxt_edit)) * mask\n",
    "        return xt, xt_edit\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def double_forward_text(\n",
    "        self,\n",
    "        z,\n",
    "        z_edit,\n",
    "        mu,\n",
    "        mu_edit,\n",
    "        mask,\n",
    "        mask_edit_net,\n",
    "        mask_edit_grad,\n",
    "        i1,\n",
    "        j1,\n",
    "        i2,\n",
    "        j2,\n",
    "        n_timesteps,\n",
    "        stoc=False,\n",
    "        soften_mask=True,\n",
    "        n_soften=20,\n",
    "    ):\n",
    "        if soften_mask:\n",
    "            kernel = [\n",
    "                2 ** ((n_soften - 1) - abs(n_soften - 1 - i))\n",
    "                for i in range(2 * n_soften - 1)\n",
    "            ]  # [1, 2, 4, ..., 2^n_soften , 2^(n_soften-1), ..., 2, 1]\n",
    "            kernel = [i / sum(kernel[: len(kernel) // 2 + 1]) for i in kernel]\n",
    "            w = (\n",
    "                torch.tensor(kernel)\n",
    "                .view(1, 1, 1, len(kernel))\n",
    "                .to(mask_edit_grad.device)\n",
    "                .float()\n",
    "            )\n",
    "            mask_edit_soft = mask_edit_grad.unsqueeze(1).contiguous()\n",
    "            mask_edit_soft = F.pad(\n",
    "                mask_edit_soft,\n",
    "                (len(kernel) // 2, len(kernel) // 2, 0, 0),\n",
    "                mode=\"replicate\",\n",
    "            )\n",
    "            mask_edit_soft = F.conv2d(\n",
    "                mask_edit_soft,\n",
    "                w,\n",
    "                bias=None,\n",
    "                stride=1,\n",
    "            )\n",
    "            mask_edit_soft = mask_edit_soft.squeeze(1)\n",
    "            mask_edit_grad = mask_edit_grad + (1 - mask_edit_grad) * mask_edit_soft\n",
    "\n",
    "        h = 1.0 / n_timesteps\n",
    "        xt = z * mask\n",
    "        xt_edit = z_edit * mask_edit_net\n",
    "\n",
    "        for i in range(n_timesteps):\n",
    "            t = (1.0 - (i + 0.5) * h) * torch.ones(\n",
    "                z.shape[0], dtype=z.dtype, device=z.device\n",
    "            )\n",
    "            time = t.unsqueeze(-1).unsqueeze(-1)\n",
    "            noise_t = get_noise(time, self.beta_min, self.beta_max, cumulative=False)\n",
    "            if stoc:  # adds stochastic term\n",
    "                # NOTE: should not come here\n",
    "                assert False\n",
    "                dxt_det = 0.5 * (mu - xt) - self.estimator(xt, mask, mu, t)\n",
    "                dxt_det = dxt_det * noise_t * h\n",
    "                dxt_stoc = torch.randn(\n",
    "                    z.shape, dtype=z.dtype, device=z.device, requires_grad=False\n",
    "                )\n",
    "                dxt_stoc = dxt_stoc * torch.sqrt(noise_t * h)\n",
    "                dxt = dxt_det + dxt_stoc\n",
    "            else:\n",
    "                dxt = 0.5 * (mu - xt - self.estimator(xt, mask, mu, t))\n",
    "                dxt = dxt * noise_t * h\n",
    "                dxt_edit = 0.5 * (\n",
    "                    mu_edit\n",
    "                    - xt_edit\n",
    "                    - self.estimator(xt_edit, mask_edit_net, mu_edit, t)\n",
    "                )\n",
    "                dxt_edit = dxt_edit * noise_t * h\n",
    "\n",
    "            xt = (xt - dxt) * mask\n",
    "\n",
    "            dxt_trg = torch.zeros_like(dxt_edit)\n",
    "            dxt_trg[:, :, i1 : i1 + (j2 - i2)] = dxt[:, :, i2:j2]\n",
    "\n",
    "            xt_edit = (\n",
    "                xt_edit - (mask_edit_grad * dxt_trg + (1 - mask_edit_grad) * dxt_edit)\n",
    "            ) * mask_edit_net\n",
    "\n",
    "        return xt, xt_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64999a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\"\"\" from https://github.com/jaywalnut310/glow-tts \"\"\"\n",
    "\n",
    "\n",
    "def sequence_mask(length, max_length=None):\n",
    "    if max_length is None:\n",
    "        max_length = length.max()\n",
    "    x = torch.arange(int(max_length), dtype=length.dtype, device=length.device)\n",
    "    return x.unsqueeze(0) < length.unsqueeze(1)\n",
    "\n",
    "\n",
    "def fix_len_compatibility(length, num_downsamplings_in_unet=2):\n",
    "    while True:\n",
    "        if length % (2 ** num_downsamplings_in_unet) == 0:\n",
    "            return length\n",
    "        length += 1\n",
    "\n",
    "\n",
    "def fix_len_compatibility_text_edit(length, num_downsamplings_in_unet=2):\n",
    "    while True:\n",
    "        if length % (2 ** num_downsamplings_in_unet) == 0:\n",
    "            return length\n",
    "        length -= 1\n",
    "\n",
    "\n",
    "def convert_pad_shape(pad_shape):\n",
    "    l = pad_shape[::-1]\n",
    "    pad_shape = [item for sublist in l for item in sublist]\n",
    "    return pad_shape\n",
    "\n",
    "\n",
    "def generate_path(duration, mask):\n",
    "    device = duration.device\n",
    "\n",
    "    b, t_x, t_y = mask.shape\n",
    "    cum_duration = torch.cumsum(duration, 1)\n",
    "    path = torch.zeros(b, t_x, t_y, dtype=mask.dtype).to(device=device)\n",
    "\n",
    "    cum_duration_flat = cum_duration.view(b * t_x)\n",
    "    path = sequence_mask(cum_duration_flat, t_y).to(mask.dtype)\n",
    "    path = path.view(b, t_x, t_y)\n",
    "    path = (\n",
    "        path\n",
    "        - torch.nn.functional.pad(path, convert_pad_shape([[0, 0], [1, 0], [0, 0]]))[\n",
    "            :, :-1\n",
    "        ]\n",
    "    )\n",
    "    path = path * mask\n",
    "    return path\n",
    "\n",
    "\n",
    "def duration_loss(logw, logw_, lengths):\n",
    "    loss = torch.sum((logw - logw_) ** 2) / torch.sum(lengths)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\"\"\" from https://github.com/jaywalnut310/glow-tts \"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class LayerNorm(BaseModule):\n",
    "    def __init__(self, channels, eps=1e-4):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.eps = eps\n",
    "\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(channels))\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_dims = len(x.shape)\n",
    "        mean = torch.mean(x, 1, keepdim=True)\n",
    "        variance = torch.mean((x - mean) ** 2, 1, keepdim=True)\n",
    "\n",
    "        x = (x - mean) * torch.rsqrt(variance + self.eps)\n",
    "\n",
    "        shape = [1, -1] + [1] * (n_dims - 2)\n",
    "        x = x * self.gamma.view(*shape) + self.beta.view(*shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvReluNorm(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        n_layers,\n",
    "        p_dropout,\n",
    "    ):\n",
    "        super(ConvReluNorm, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_layers = n_layers\n",
    "        self.p_dropout = p_dropout\n",
    "\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        self.norm_layers = torch.nn.ModuleList()\n",
    "        self.conv_layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels, hidden_channels, kernel_size, padding=kernel_size // 2\n",
    "            )\n",
    "        )\n",
    "        self.norm_layers.append(LayerNorm(hidden_channels))\n",
    "        self.relu_drop = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(), torch.nn.Dropout(p_dropout)\n",
    "        )\n",
    "        for _ in range(n_layers - 1):\n",
    "            self.conv_layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    hidden_channels,\n",
    "                    hidden_channels,\n",
    "                    kernel_size,\n",
    "                    padding=kernel_size // 2,\n",
    "                )\n",
    "            )\n",
    "            self.norm_layers.append(LayerNorm(hidden_channels))\n",
    "        self.proj = torch.nn.Conv1d(hidden_channels, out_channels, 1)\n",
    "        self.proj.weight.data.zero_()\n",
    "        self.proj.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        x_org = x\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x * x_mask)\n",
    "            x = self.norm_layers[i](x)\n",
    "            x = self.relu_drop(x)\n",
    "        x = x_org + self.proj(x)\n",
    "        return x * x_mask\n",
    "\n",
    "\n",
    "class DurationPredictor(BaseModule):\n",
    "    def __init__(self, in_channels, filter_channels, kernel_size, p_dropout):\n",
    "        super(DurationPredictor, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.filter_channels = filter_channels\n",
    "        self.p_dropout = p_dropout\n",
    "\n",
    "        self.drop = torch.nn.Dropout(p_dropout)\n",
    "        self.conv_1 = torch.nn.Conv1d(\n",
    "            in_channels, filter_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.norm_1 = LayerNorm(filter_channels)\n",
    "        self.conv_2 = torch.nn.Conv1d(\n",
    "            filter_channels, filter_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.norm_2 = LayerNorm(filter_channels)\n",
    "        self.proj = torch.nn.Conv1d(filter_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        x = self.conv_1(x * x_mask)\n",
    "        x = torch.relu(x)\n",
    "        x = self.norm_1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.conv_2(x * x_mask)\n",
    "        x = torch.relu(x)\n",
    "        x = self.norm_2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.proj(x * x_mask)\n",
    "        return x * x_mask\n",
    "\n",
    "\n",
    "class MultiHeadAttention(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        out_channels,\n",
    "        n_heads,\n",
    "        window_size=None,\n",
    "        heads_share=True,\n",
    "        p_dropout=0.0,\n",
    "        proximal_bias=False,\n",
    "        proximal_init=False,\n",
    "    ):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert channels % n_heads == 0\n",
    "\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.window_size = window_size\n",
    "        self.heads_share = heads_share\n",
    "        self.proximal_bias = proximal_bias\n",
    "        self.p_dropout = p_dropout\n",
    "        self.attn = None\n",
    "\n",
    "        self.k_channels = channels // n_heads\n",
    "        self.conv_q = torch.nn.Conv1d(channels, channels, 1)\n",
    "        self.conv_k = torch.nn.Conv1d(channels, channels, 1)\n",
    "        self.conv_v = torch.nn.Conv1d(channels, channels, 1)\n",
    "        if window_size is not None:\n",
    "            n_heads_rel = 1 if heads_share else n_heads\n",
    "            rel_stddev = self.k_channels ** -0.5\n",
    "            self.emb_rel_k = torch.nn.Parameter(\n",
    "                torch.randn(n_heads_rel, window_size * 2 + 1, self.k_channels)\n",
    "                * rel_stddev\n",
    "            )\n",
    "            self.emb_rel_v = torch.nn.Parameter(\n",
    "                torch.randn(n_heads_rel, window_size * 2 + 1, self.k_channels)\n",
    "                * rel_stddev\n",
    "            )\n",
    "        self.conv_o = torch.nn.Conv1d(channels, out_channels, 1)\n",
    "        self.drop = torch.nn.Dropout(p_dropout)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.conv_q.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.conv_k.weight)\n",
    "        if proximal_init:\n",
    "            self.conv_k.weight.data.copy_(self.conv_q.weight.data)\n",
    "            self.conv_k.bias.data.copy_(self.conv_q.bias.data)\n",
    "        torch.nn.init.xavier_uniform_(self.conv_v.weight)\n",
    "\n",
    "    def forward(self, x, c, attn_mask=None):\n",
    "        q = self.conv_q(x)\n",
    "        k = self.conv_k(c)\n",
    "        v = self.conv_v(c)\n",
    "\n",
    "        x, self.attn = self.attention(q, k, v, mask=attn_mask)\n",
    "\n",
    "        x = self.conv_o(x)\n",
    "        return x\n",
    "\n",
    "    def attention(self, query, key, value, mask=None):\n",
    "        b, d, t_s, t_t = (*key.size(), query.size(2))\n",
    "        query = query.view(b, self.n_heads, self.k_channels, t_t).transpose(2, 3)\n",
    "        key = key.view(b, self.n_heads, self.k_channels, t_s).transpose(2, 3)\n",
    "        value = value.view(b, self.n_heads, self.k_channels, t_s).transpose(2, 3)\n",
    "\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.k_channels)\n",
    "        if self.window_size is not None:\n",
    "            assert (\n",
    "                t_s == t_t\n",
    "            ), \"Relative attention is only available for self-attention.\"\n",
    "            key_relative_embeddings = self._get_relative_embeddings(self.emb_rel_k, t_s)\n",
    "            rel_logits = self._matmul_with_relative_keys(query, key_relative_embeddings)\n",
    "            rel_logits = self._relative_position_to_absolute_position(rel_logits)\n",
    "            scores_local = rel_logits / math.sqrt(self.k_channels)\n",
    "            scores = scores + scores_local\n",
    "        if self.proximal_bias:\n",
    "            assert t_s == t_t, \"Proximal bias is only available for self-attention.\"\n",
    "            scores = scores + self._attention_bias_proximal(t_s).to(\n",
    "                device=scores.device, dtype=scores.dtype\n",
    "            )\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e4)\n",
    "        p_attn = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_attn = self.drop(p_attn)\n",
    "        output = torch.matmul(p_attn, value)\n",
    "        if self.window_size is not None:\n",
    "            relative_weights = self._absolute_position_to_relative_position(p_attn)\n",
    "            value_relative_embeddings = self._get_relative_embeddings(\n",
    "                self.emb_rel_v, t_s\n",
    "            )\n",
    "            output = output + self._matmul_with_relative_values(\n",
    "                relative_weights, value_relative_embeddings\n",
    "            )\n",
    "        output = output.transpose(2, 3).contiguous().view(b, d, t_t)\n",
    "        return output, p_attn\n",
    "\n",
    "    def _matmul_with_relative_values(self, x, y):\n",
    "        ret = torch.matmul(x, y.unsqueeze(0))\n",
    "        return ret\n",
    "\n",
    "    def _matmul_with_relative_keys(self, x, y):\n",
    "        ret = torch.matmul(x, y.unsqueeze(0).transpose(-2, -1))\n",
    "        return ret\n",
    "\n",
    "    def _get_relative_embeddings(self, relative_embeddings, length):\n",
    "        pad_length = max(length - (self.window_size + 1), 0)\n",
    "        slice_start_position = max((self.window_size + 1) - length, 0)\n",
    "        slice_end_position = slice_start_position + 2 * length - 1\n",
    "        if pad_length > 0:\n",
    "            padded_relative_embeddings = torch.nn.functional.pad(\n",
    "                relative_embeddings,\n",
    "                convert_pad_shape([[0, 0], [pad_length, pad_length], [0, 0]]),\n",
    "            )\n",
    "        else:\n",
    "            padded_relative_embeddings = relative_embeddings\n",
    "        used_relative_embeddings = padded_relative_embeddings[\n",
    "            :, slice_start_position:slice_end_position\n",
    "        ]\n",
    "        return used_relative_embeddings\n",
    "\n",
    "    def _relative_position_to_absolute_position(self, x):\n",
    "        batch, heads, length, _ = x.size()\n",
    "        x = torch.nn.functional.pad(\n",
    "            x, convert_pad_shape([[0, 0], [0, 0], [0, 0], [0, 1]])\n",
    "        )\n",
    "        x_flat = x.view([batch, heads, length * 2 * length])\n",
    "        x_flat = torch.nn.functional.pad(\n",
    "            x_flat, convert_pad_shape([[0, 0], [0, 0], [0, length - 1]])\n",
    "        )\n",
    "        x_final = x_flat.view([batch, heads, length + 1, 2 * length - 1])[\n",
    "            :, :, :length, length - 1 :\n",
    "        ]\n",
    "        return x_final\n",
    "\n",
    "    def _absolute_position_to_relative_position(self, x):\n",
    "        batch, heads, length, _ = x.size()\n",
    "        x = torch.nn.functional.pad(\n",
    "            x, convert_pad_shape([[0, 0], [0, 0], [0, 0], [0, length - 1]])\n",
    "        )\n",
    "        x_flat = x.view([batch, heads, length ** 2 + length * (length - 1)])\n",
    "        x_flat = torch.nn.functional.pad(\n",
    "            x_flat, convert_pad_shape([[0, 0], [0, 0], [length, 0]])\n",
    "        )\n",
    "        x_final = x_flat.view([batch, heads, length, 2 * length])[:, :, :, 1:]\n",
    "        return x_final\n",
    "\n",
    "    def _attention_bias_proximal(self, length):\n",
    "        r = torch.arange(length, dtype=torch.float32)\n",
    "        diff = torch.unsqueeze(r, 0) - torch.unsqueeze(r, 1)\n",
    "        return torch.unsqueeze(torch.unsqueeze(-torch.log1p(torch.abs(diff)), 0), 0)\n",
    "\n",
    "\n",
    "class FFN(BaseModule):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, filter_channels, kernel_size, p_dropout=0.0\n",
    "    ):\n",
    "        super(FFN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.filter_channels = filter_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p_dropout = p_dropout\n",
    "\n",
    "        self.conv_1 = torch.nn.Conv1d(\n",
    "            in_channels, filter_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.conv_2 = torch.nn.Conv1d(\n",
    "            filter_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.drop = torch.nn.Dropout(p_dropout)\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        x = self.conv_1(x * x_mask)\n",
    "        x = torch.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.conv_2(x * x_mask)\n",
    "        return x * x_mask\n",
    "\n",
    "\n",
    "class Encoder(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        filter_channels,\n",
    "        n_heads,\n",
    "        n_layers,\n",
    "        kernel_size=1,\n",
    "        p_dropout=0.0,\n",
    "        window_size=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.filter_channels = filter_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.drop = torch.nn.Dropout(p_dropout)\n",
    "        self.attn_layers = torch.nn.ModuleList()\n",
    "        self.norm_layers_1 = torch.nn.ModuleList()\n",
    "        self.ffn_layers = torch.nn.ModuleList()\n",
    "        self.norm_layers_2 = torch.nn.ModuleList()\n",
    "        for _ in range(self.n_layers):\n",
    "            self.attn_layers.append(\n",
    "                MultiHeadAttention(\n",
    "                    hidden_channels,\n",
    "                    hidden_channels,\n",
    "                    n_heads,\n",
    "                    window_size=window_size,\n",
    "                    p_dropout=p_dropout,\n",
    "                )\n",
    "            )\n",
    "            self.norm_layers_1.append(LayerNorm(hidden_channels))\n",
    "            self.ffn_layers.append(\n",
    "                FFN(\n",
    "                    hidden_channels,\n",
    "                    hidden_channels,\n",
    "                    filter_channels,\n",
    "                    kernel_size,\n",
    "                    p_dropout=p_dropout,\n",
    "                )\n",
    "            )\n",
    "            self.norm_layers_2.append(LayerNorm(hidden_channels))\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        attn_mask = x_mask.unsqueeze(2) * x_mask.unsqueeze(-1)\n",
    "        for i in range(self.n_layers):\n",
    "            x = x * x_mask\n",
    "            y = self.attn_layers[i](x, x, attn_mask)\n",
    "            y = self.drop(y)\n",
    "            x = self.norm_layers_1[i](x + y)\n",
    "            y = self.ffn_layers[i](x, x_mask)\n",
    "            y = self.drop(y)\n",
    "            x = self.norm_layers_2[i](x + y)\n",
    "        x = x * x_mask\n",
    "        return x\n",
    "\n",
    "\n",
    "class TextEncoder(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_vocab,\n",
    "        n_feats,\n",
    "        n_channels,\n",
    "        filter_channels,\n",
    "        filter_channels_dp,\n",
    "        n_heads,\n",
    "        n_layers,\n",
    "        kernel_size,\n",
    "        p_dropout,\n",
    "        window_size=None,\n",
    "        spk_emb_dim=64,\n",
    "        n_spks=1,\n",
    "    ):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_feats = n_feats\n",
    "        self.n_channels = n_channels\n",
    "        self.filter_channels = filter_channels\n",
    "        self.filter_channels_dp = filter_channels_dp\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.window_size = window_size\n",
    "        self.spk_emb_dim = spk_emb_dim\n",
    "        self.n_spks = n_spks\n",
    "\n",
    "        self.emb = torch.nn.Embedding(n_vocab, n_channels)\n",
    "        torch.nn.init.normal_(self.emb.weight, 0.0, n_channels ** -0.5)\n",
    "\n",
    "        self.prenet = ConvReluNorm(\n",
    "            n_channels, n_channels, n_channels, kernel_size=5, n_layers=3, p_dropout=0.5\n",
    "        )\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            n_channels + (spk_emb_dim if n_spks > 1 else 0),\n",
    "            filter_channels,\n",
    "            n_heads,\n",
    "            n_layers,\n",
    "            kernel_size,\n",
    "            p_dropout,\n",
    "            window_size=window_size,\n",
    "        )\n",
    "\n",
    "        self.proj_m = torch.nn.Conv1d(\n",
    "            n_channels + (spk_emb_dim if n_spks > 1 else 0), n_feats, 1\n",
    "        )\n",
    "        self.proj_w = DurationPredictor(\n",
    "            n_channels + (spk_emb_dim if n_spks > 1 else 0),\n",
    "            filter_channels_dp,\n",
    "            kernel_size,\n",
    "            p_dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_lengths, spk=None):\n",
    "        x = self.emb(x) * math.sqrt(self.n_channels)\n",
    "        x = torch.transpose(x, 1, -1)\n",
    "        x_mask = torch.unsqueeze(sequence_mask(x_lengths, x.size(2)), 1).to(x.dtype)\n",
    "\n",
    "        x = self.prenet(x, x_mask)\n",
    "        if self.n_spks > 1:\n",
    "            x = torch.cat([x, spk.unsqueeze(-1).repeat(1, 1, x.shape[-1])], dim=1)\n",
    "        x = self.encoder(x, x_mask)\n",
    "        mu = self.proj_m(x) * x_mask\n",
    "\n",
    "        x_dp = torch.detach(x)\n",
    "        logw = self.proj_w(x_dp, x_mask)\n",
    "\n",
    "        return mu, logw, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import monotonic_align\n",
    "\n",
    "\n",
    "class GradTTS(TTSModel):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        self.n_vocab = (\n",
    "            len(SYMBOL_SETS[hparams.symbol_set]) + 1\n",
    "            if hparams.intersperse_text\n",
    "            else len(SYMBOL_SETS[hparams.symbol_set])\n",
    "        )\n",
    "        self.n_spks = hparams.n_spks\n",
    "        self.spk_emb_dim = hparams.spk_emb_dim\n",
    "        self.n_enc_channels = hparams.n_enc_channels\n",
    "        self.filter_channels = hparams.filter_channels\n",
    "        self.filter_channels_dp = hparams.filter_channels_dp\n",
    "        self.n_heads = hparams.n_heads\n",
    "        self.n_enc_layers = hparams.n_enc_layers\n",
    "        self.enc_kernel = hparams.enc_kernel\n",
    "        self.enc_dropout = hparams.enc_dropout\n",
    "        self.window_size = hparams.window_size\n",
    "        self.n_feats = hparams.n_feats\n",
    "        self.dec_dim = hparams.dec_dim\n",
    "        self.beta_min = hparams.beta_min\n",
    "        self.beta_max = hparams.beta_max\n",
    "        self.pe_scale = hparams.pe_scale\n",
    "\n",
    "        if self.n_spks > 1:\n",
    "            self.spk_emb = torch.nn.Embedding(self.n_spks, self.spk_emb_dim)\n",
    "        self.encoder = TextEncoder(\n",
    "            self.n_vocab,\n",
    "            self.n_feats,\n",
    "            self.n_enc_channels,\n",
    "            self.filter_channels,\n",
    "            self.filter_channels_dp,\n",
    "            self.n_heads,\n",
    "            self.n_enc_layers,\n",
    "            self.enc_kernel,\n",
    "            self.enc_dropout,\n",
    "            self.window_size,\n",
    "        )\n",
    "        self.decoder = Diffusion(\n",
    "            self.n_feats,\n",
    "            self.dec_dim,\n",
    "            self.n_spks,\n",
    "            self.spk_emb_dim,\n",
    "            self.beta_min,\n",
    "            self.beta_max,\n",
    "            self.pe_scale,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def nparams(self):\n",
    "        \"\"\"\n",
    "        Returns number of trainable parameters of the module.\n",
    "        \"\"\"\n",
    "        num_params = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                num_params += np.prod(param.detach().cpu().numpy().shape)\n",
    "        return num_params\n",
    "\n",
    "    def relocate_input(self, x: list):\n",
    "        \"\"\"\n",
    "        Relocates provided tensors to the same device set for the module.\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        for i in range(len(x)):\n",
    "            if isinstance(x[i], torch.Tensor) and x[i].device != device:\n",
    "                x[i] = x[i].to(device)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        x_lengths,\n",
    "        n_timesteps,\n",
    "        temperature=1.0,\n",
    "        stoc=False,\n",
    "        spk=None,\n",
    "        length_scale=1.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generates mel-spectrogram from text. Returns:\n",
    "            1. encoder outputs\n",
    "            2. decoder outputs\n",
    "            3. generated alignment\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): batch of texts, converted to a tensor with phoneme embedding ids.\n",
    "            x_lengths (torch.Tensor): lengths of texts in batch.\n",
    "            n_timesteps (int): number of steps to use for reverse diffusion in decoder.\n",
    "            temperature (float, optional): controls variance of terminal distribution.\n",
    "            stoc (bool, optional): flag that adds stochastic term to the decoder sampler.\n",
    "                Usually, does not provide synthesis improvements.\n",
    "            length_scale (float, optional): controls speech pace.\n",
    "                Increase value to slow down generated speech and vice versa.\n",
    "        \"\"\"\n",
    "        x, x_lengths = self.relocate_input([x, x_lengths])\n",
    "\n",
    "        if self.n_spks > 1:\n",
    "            # Get speaker embedding\n",
    "            spk = self.spk_emb(spk)\n",
    "\n",
    "        # Get encoder_outputs `mu_x` and log-scaled token durations `logw`\n",
    "        mu_x, logw, x_mask = self.encoder(x, x_lengths, spk)\n",
    "\n",
    "        w = torch.exp(logw) * x_mask\n",
    "        w_ceil = torch.ceil(w) * length_scale\n",
    "        y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n",
    "        y_max_length = int(y_lengths.max())\n",
    "        y_max_length_ = fix_len_compatibility(y_max_length)\n",
    "\n",
    "        # Using obtained durations `w` construct alignment map `attn`\n",
    "        y_mask = sequence_mask(y_lengths, y_max_length_).unsqueeze(1).to(x_mask.dtype)\n",
    "        attn_mask = x_mask.unsqueeze(-1) * y_mask.unsqueeze(2)\n",
    "        attn = generate_path(w_ceil.squeeze(1), attn_mask.squeeze(1)).unsqueeze(1)\n",
    "\n",
    "        # Align encoded text and get mu_y\n",
    "        mu_y = torch.matmul(attn.squeeze(1).transpose(1, 2), mu_x.transpose(1, 2))\n",
    "        mu_y = mu_y.transpose(1, 2)\n",
    "        encoder_outputs = mu_y[:, :, :y_max_length]\n",
    "\n",
    "        # Sample latent representation from terminal distribution N(mu_y, I)\n",
    "        z = mu_y + torch.randn_like(mu_y, device=mu_y.device) / temperature\n",
    "        # Generate sample by performing reverse dynamics\n",
    "        decoder_outputs = self.decoder(z, y_mask, mu_y, n_timesteps, stoc, spk)\n",
    "        decoder_outputs = decoder_outputs[:, :, :y_max_length]\n",
    "\n",
    "        return encoder_outputs, decoder_outputs, attn[:, :, :y_max_length]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def infer(\n",
    "        self,\n",
    "        text,\n",
    "        n_timesteps,\n",
    "        cleaner_names=[\"english_cleaners\"],\n",
    "        temperature=1.0,\n",
    "        stoc=False,\n",
    "        spk=None,\n",
    "        length_scale=1.0,\n",
    "        intersperse_text=True,\n",
    "        intersperse_token=148,\n",
    "    ):\n",
    "        seq = text_to_sequence(\n",
    "            text, cleaner_names=cleaner_names, p_arpabet=1.0, symbol_set=\"gradtts\"\n",
    "        )\n",
    "        if intersperse_text:\n",
    "            x = torch.LongTensor(intersperse(seq, intersperse_token)).cuda()[None]\n",
    "        else:\n",
    "            x = torch.LongTensor(seq).cuda()[None]\n",
    "\n",
    "        x_lengths = torch.LongTensor([x.shape[-1]]).cuda()\n",
    "\n",
    "        y_enc, y_dec, attn = self.forward(\n",
    "            x,\n",
    "            x_lengths,\n",
    "            n_timesteps=n_timesteps,\n",
    "            temperature=temperature,\n",
    "            stoc=stoc,\n",
    "            spk=spk,\n",
    "            length_scale=length_scale,\n",
    "        )\n",
    "        return y_enc, y_dec, attn\n",
    "\n",
    "    def infer_editts_edit_content(\n",
    "        self,\n",
    "        text1,\n",
    "        text2,\n",
    "        n_timesteps,\n",
    "        symbol_set,\n",
    "        mel1=None,\n",
    "        mel2=None,\n",
    "        intersperse_token=148,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        EdiTTS\n",
    "        Edit speech/audio via content substitution.\n",
    "        This function will substitute the desired portion of text2 into the specified location of text1.\n",
    "\n",
    "        Arguments:\n",
    "        text1 (str): text to substitute content in to. e.g. \"This is a | blue | pencil\"\n",
    "        text2 (str): text to substitute audio from. e.g. \"This is a | red | pen.\"\n",
    "        n_timesteps (int): number of steps to use for reverse diffusion in decoder.\n",
    "        symbol_set (str): symbol set key to lookup the symbol set\n",
    "        intersperse_token (int): value used for interspersing\n",
    "\n",
    "        Output:\n",
    "        y_dec1: Mel spectrogram of text1\n",
    "        y_dec2: Mel spectrogram of text2\n",
    "        y_dec_edit: Mel spectrogram of source of text2 substituted in to text1 via EdiTTS\n",
    "        y_dec_cat: Mel spectrogram of source of text2 substituted in to text1 via mel concatenation\n",
    "\n",
    "        Usage:\n",
    "        y_dec1, y_dec2, y_dec_edit, y_dec_cat = model.infer_editts_edit_content(\"This is a | blue | pencil.\",\n",
    "                                                                    \"This is a | red | pen.\",\n",
    "                                                                    n_timesteps=10,\n",
    "                                                                    symbol_set=\"gradtts\")\n",
    "        y_dec1: \"this is a blue pencil\"\n",
    "        y_dec2: \"this is a red pen\"\n",
    "        y_dec_edit: \"this is a red pencil\" (EdiTTS)\n",
    "        y_dec_cat: \"this is a red pencil\" (Mel concatenation)\n",
    "\n",
    "        \"\"\"\n",
    "        sequence1, emphases1 = text_to_sequence_for_editts(\n",
    "            text1, cleaner_names=[\"english_cleaners\"], symbol_set=symbol_set\n",
    "        )\n",
    "        sequence2, emphases2 = text_to_sequence_for_editts(\n",
    "            text2, cleaner_names=[\"english_cleaners\"], symbol_set=symbol_set\n",
    "        )\n",
    "        x1 = torch.LongTensor(intersperse(sequence1, intersperse_token)).cuda()[None]\n",
    "        x2 = torch.LongTensor(intersperse(sequence2, intersperse_token)).cuda()[None]\n",
    "        emphases1 = intersperse_emphases(emphases1)\n",
    "        emphases2 = intersperse_emphases(emphases2)\n",
    "        x_lengths1 = torch.LongTensor([x1.shape[-1]]).cuda()\n",
    "        x_lengths2 = torch.LongTensor([x2.shape[-1]]).cuda()\n",
    "\n",
    "        y_dec1, y_dec2, y_dec_edit, y_dec_cat = self.editts_edit_content(\n",
    "            x1,\n",
    "            x2,\n",
    "            x_lengths1,\n",
    "            x_lengths2,\n",
    "            emphases1,\n",
    "            emphases2,\n",
    "            mel1,\n",
    "            mel2,\n",
    "            n_timesteps=n_timesteps,\n",
    "            temperature=1.5,\n",
    "            stoc=False,\n",
    "            length_scale=0.91,\n",
    "        )\n",
    "        return y_dec1, y_dec2, y_dec_edit, y_dec_cat\n",
    "\n",
    "    def infer_editts_real_audio(\n",
    "        self, text1, text2, n_timesteps, symbol_set, intersperse_token=148\n",
    "    ):\n",
    "        # TODO\n",
    "        return None\n",
    "\n",
    "    def compute_loss(self, x, x_lengths, y, y_lengths, spk=None, out_size=None):\n",
    "        \"\"\"\n",
    "        Computes 3 losses:\n",
    "            1. duration loss: loss between predicted token durations and those extracted by Monotinic Alignment Search (MAS).\n",
    "            2. prior loss: loss between mel-spectrogram and encoder outputs.\n",
    "            3. diffusion loss: loss between gaussian noise and its reconstruction by diffusion-based decoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): batch of texts, converted to a tensor with phoneme embedding ids.\n",
    "            x_lengths (torch.Tensor): lengths of texts in batch.\n",
    "            y (torch.Tensor): batch of corresponding mel-spectrograms.\n",
    "            y_lengths (torch.Tensor): lengths of mel-spectrograms in batch.\n",
    "            out_size (int, optional): length (in mel's sampling rate) of segment to cut, on which decoder will be trained.\n",
    "                Should be divisible by 2^{num of UNet downsamplings}. Needed to increase batch size.\n",
    "        \"\"\"\n",
    "        x, x_lengths, y, y_lengths = self.relocate_input([x, x_lengths, y, y_lengths])\n",
    "\n",
    "        if self.n_spks > 1:\n",
    "            # Get speaker embedding\n",
    "            spk = self.spk_emb(spk)\n",
    "\n",
    "        # Get encoder_outputs `mu_x` and log-scaled token durations `logw`\n",
    "        mu_x, logw, x_mask = self.encoder(x, x_lengths, spk)\n",
    "        y_max_length = y.shape[-1]\n",
    "\n",
    "        y_mask = sequence_mask(y_lengths, y_max_length).unsqueeze(1).to(x_mask)\n",
    "        attn_mask = x_mask.unsqueeze(-1) * y_mask.unsqueeze(2)\n",
    "\n",
    "        # Use MAS to find most likely alignment `attn` between text and mel-spectrogram\n",
    "        with torch.no_grad():\n",
    "            const = -0.5 * math.log(2 * math.pi) * self.n_feats\n",
    "            factor = -0.5 * torch.ones(mu_x.shape, dtype=mu_x.dtype, device=mu_x.device)\n",
    "            y_square = torch.matmul(factor.transpose(1, 2), y ** 2)\n",
    "            y_mu_double = torch.matmul(2.0 * (factor * mu_x).transpose(1, 2), y)\n",
    "            mu_square = torch.sum(factor * (mu_x ** 2), 1).unsqueeze(-1)\n",
    "            log_prior = y_square - y_mu_double + mu_square + const\n",
    "            attn = monotonic_align.maximum_path_gradtts(log_prior, attn_mask.squeeze(1))\n",
    "            attn = attn.detach()\n",
    "\n",
    "        # Compute loss between predicted log-scaled durations and those obtained from MAS\n",
    "        logw_ = torch.log(1e-8 + torch.sum(attn.unsqueeze(1), -1)) * x_mask\n",
    "        dur_loss = duration_loss(logw, logw_, x_lengths)\n",
    "\n",
    "        # Cut a small segment of mel-spectrogram in order to increase batch size\n",
    "        if not isinstance(out_size, type(None)):\n",
    "            max_offset = (y_lengths - out_size).clamp(0)\n",
    "            offset_ranges = list(\n",
    "                zip([0] * max_offset.shape[0], max_offset.cpu().numpy())\n",
    "            )\n",
    "            out_offset = torch.LongTensor(\n",
    "                [\n",
    "                    torch.tensor(random.choice(range(start, end)) if end > start else 0)\n",
    "                    for start, end in offset_ranges\n",
    "                ]\n",
    "            ).to(y_lengths)\n",
    "\n",
    "            attn_cut = torch.zeros(\n",
    "                attn.shape[0],\n",
    "                attn.shape[1],\n",
    "                out_size,\n",
    "                dtype=attn.dtype,\n",
    "                device=attn.device,\n",
    "            )\n",
    "            y_cut = torch.zeros(\n",
    "                y.shape[0], self.n_feats, out_size, dtype=y.dtype, device=y.device\n",
    "            )\n",
    "            y_cut_lengths = []\n",
    "            for i, (y_, out_offset_) in enumerate(zip(y, out_offset)):\n",
    "                y_cut_length = out_size + (y_lengths[i] - out_size).clamp(None, 0)\n",
    "                y_cut_lengths.append(y_cut_length)\n",
    "                cut_lower, cut_upper = out_offset_, out_offset_ + y_cut_length\n",
    "                y_cut[i, :, :y_cut_length] = y_[:, cut_lower:cut_upper]\n",
    "                attn_cut[i, :, :y_cut_length] = attn[i, :, cut_lower:cut_upper]\n",
    "            y_cut_lengths = torch.LongTensor(y_cut_lengths)\n",
    "            y_cut_mask = sequence_mask(y_cut_lengths).unsqueeze(1).to(y_mask)\n",
    "\n",
    "            attn = attn_cut\n",
    "            y = y_cut\n",
    "            y_mask = F.pad(\n",
    "                input=y_cut_mask,\n",
    "                pad=(0, out_size - y_cut_mask.shape[2], 0, 0),\n",
    "                mode=\"constant\",\n",
    "                value=0,\n",
    "            )\n",
    "\n",
    "        # Align encoded text with mel-spectrogram and get mu_y segment\n",
    "        mu_y = torch.matmul(attn.squeeze(1).transpose(1, 2), mu_x.transpose(1, 2))\n",
    "        mu_y = mu_y.transpose(1, 2)\n",
    "\n",
    "        # Compute loss of score-based decoder\n",
    "        diff_loss, xt = self.decoder.compute_loss(y, y_mask, mu_y, spk)\n",
    "\n",
    "        # Compute loss between aligned encoder outputs and mel-spectrogram\n",
    "        prior_loss = torch.sum(0.5 * ((y - mu_y) ** 2 + math.log(2 * math.pi)) * y_mask)\n",
    "        prior_loss = prior_loss / (torch.sum(y_mask) * self.n_feats)\n",
    "\n",
    "        return dur_loss, prior_loss, diff_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def editts_edit_pitch(\n",
    "        self,\n",
    "        x,\n",
    "        x_lengths,\n",
    "        n_timesteps,\n",
    "        temperature=1.0,\n",
    "        stoc=False,\n",
    "        length_scale=1.0,\n",
    "        soften_mask=True,\n",
    "        n_soften=16,\n",
    "        emphases=None,\n",
    "        direction=\"up\",\n",
    "    ):\n",
    "        x, x_lengths = self.relocate_input([x, x_lengths])\n",
    "\n",
    "        mu_x, logw, x_mask = self.encoder(x, x_lengths)\n",
    "\n",
    "        w = torch.exp(logw) * x_mask\n",
    "        w_ceil = torch.ceil(w) * length_scale\n",
    "        y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n",
    "        y_max_length = int(y_lengths.max())\n",
    "        y_max_length_ = fix_len_compatibility(y_max_length)\n",
    "\n",
    "        y_mask = sequence_mask(y_lengths, y_max_length_).unsqueeze(1).to(x_mask.dtype)\n",
    "        attn_mask = x_mask.unsqueeze(-1) * y_mask.unsqueeze(2)\n",
    "        attn = generate_path(w_ceil.squeeze(1), attn_mask.squeeze(1)).unsqueeze(1)\n",
    "\n",
    "        mu_y = torch.matmul(attn.squeeze(1).transpose(1, 2), mu_x.transpose(1, 2))\n",
    "        mu_y = mu_y.transpose(1, 2)\n",
    "\n",
    "        eps = torch.randn_like(mu_y, device=mu_y.device) / temperature\n",
    "        z = mu_y + eps\n",
    "\n",
    "        encoder_outputs = mu_y[:, :, :y_max_length]\n",
    "\n",
    "        mu_x_edit = mu_x.clone()\n",
    "        mask_edit = torch.zeros_like(mu_x[:, :1, :])\n",
    "        for j, (start, end) in enumerate(emphases):\n",
    "            mask_edit[:, :, start:end] = 1\n",
    "            mu_x_edit[:, :, start:end] = shift_mel(\n",
    "                mu_x_edit[:, :, start:end], direction=direction\n",
    "            )\n",
    "\n",
    "        mu_y_edit = torch.matmul(\n",
    "            attn.squeeze(1).transpose(1, 2), mu_x_edit.transpose(1, 2)\n",
    "        )\n",
    "        mask_edit = torch.matmul(\n",
    "            attn.squeeze(1).transpose(1, 2), mask_edit.transpose(1, 2)\n",
    "        )\n",
    "\n",
    "        mu_y_edit = mu_y_edit.transpose(1, 2)\n",
    "        mask_edit = mask_edit.transpose(1, 2)  # [B, 1, T]\n",
    "        mask_edit[:, :, y_max_length:] = mask_edit[\n",
    "            :, :, y_max_length - 1\n",
    "        ]  # for soften_mask\n",
    "\n",
    "        z_edit = mu_y_edit + eps\n",
    "\n",
    "        dec_out, dec_edit = self.decoder.double_forward_pitch(\n",
    "            z,\n",
    "            z_edit,\n",
    "            mu_y,\n",
    "            mu_y_edit,\n",
    "            y_mask,\n",
    "            mask_edit,\n",
    "            n_timesteps,\n",
    "            stoc,\n",
    "            soften_mask,\n",
    "            n_soften,\n",
    "        )\n",
    "\n",
    "        # For baseline\n",
    "        emphases_expanded = []\n",
    "        attn = attn.squeeze()\n",
    "        for start, end in emphases:\n",
    "            i = attn[:start].sum().long().item() if start > 0 else 0\n",
    "            j = attn[:end].sum().long().item()\n",
    "            itv = [i, j]\n",
    "            emphases_expanded.append(itv)\n",
    "\n",
    "        dec_out = dec_out[:, :, :y_max_length]\n",
    "        dec_baseline = dec_out.clone()\n",
    "        for start, end in emphases_expanded:\n",
    "            dec_baseline[:, :, start:end] = shift_mel(\n",
    "                dec_baseline[:, :, start:end], direction=direction\n",
    "            )\n",
    "        dec_edit = dec_edit[:, :, :y_max_length]\n",
    "\n",
    "        return dec_out, dec_baseline, dec_edit\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def editts_edit_content(\n",
    "        self,\n",
    "        x1,\n",
    "        x2,\n",
    "        x1_lengths,\n",
    "        x2_lengths,\n",
    "        emphases1,\n",
    "        emphases2,\n",
    "        n_timesteps,\n",
    "        mel1=None,\n",
    "        mel2=None,\n",
    "        temperature=1.0,\n",
    "        stoc=False,\n",
    "        length_scale=1.0,\n",
    "        soften_mask=True,\n",
    "        n_soften_text=9,\n",
    "        n_soften=16,\n",
    "        amax=0.9,\n",
    "        amin=0.1,\n",
    "    ):\n",
    "        def _process_input(x, x_lengths):\n",
    "            x, x_lengths = self.relocate_input([x, x_lengths])\n",
    "\n",
    "            mu_x, logw, x_mask = self.encoder(x, x_lengths)\n",
    "            w = torch.exp(logw) * x_mask\n",
    "            w_ceil = torch.ceil(w) * length_scale\n",
    "            y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n",
    "            y_max_length = int(y_lengths.max())\n",
    "            y_max_length_ = fix_len_compatibility(y_max_length)\n",
    "\n",
    "            y_mask = (\n",
    "                sequence_mask(y_lengths, y_max_length_).unsqueeze(1).to(x_mask.dtype)\n",
    "            )\n",
    "            attn_mask = x_mask.unsqueeze(-1) * y_mask.unsqueeze(2)\n",
    "            attn = generate_path(w_ceil.squeeze(1), attn_mask.squeeze(1)).unsqueeze(1)\n",
    "\n",
    "            mu_y = torch.matmul(attn.squeeze(1).transpose(1, 2), mu_x.transpose(1, 2))\n",
    "            mu_y = mu_y.transpose(1, 2)  # [1, n_mels, T]\n",
    "            return mu_y, attn, y_mask, y_max_length, y_lengths\n",
    "\n",
    "        def _process_audio_input(x, x_lengths, mel):\n",
    "            x, x_lengths = self.relocate_input([x, x_lengths])\n",
    "\n",
    "            # Need to get encoded text, durations, and masks\n",
    "            mu_x, logw, x_mask = self.encoder(x, x_lengths)\n",
    "            w = torch.exp(logw) * x_mask\n",
    "            w_ceil = torch.ceil(w) * length_scale\n",
    "            y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()\n",
    "            y_max_length = int(y_lengths.max())\n",
    "            y_max_length_ = fix_len_compatibility(y_max_length)\n",
    "\n",
    "            y_mask = (\n",
    "                sequence_mask(y_lengths, y_max_length_).unsqueeze(1).to(x_mask.dtype)\n",
    "            )\n",
    "            attn_mask = x_mask.unsqueeze(-1) * y_mask.unsqueeze(2)\n",
    "            attn = generate_path(w_ceil.squeeze(1), attn_mask.squeeze(1)).unsqueeze(1)\n",
    "\n",
    "            mu_y = torch.matmul(attn.squeeze(1).transpose(1, 2), mu_x.transpose(1, 2))\n",
    "            mu_y = mu_y.transpose(1, 2)  # [1, n_mels, T]\n",
    "            return mu_y, attn, y_mask, y_max_length, y_lengths\n",
    "\n",
    "        def _soften_juntions(\n",
    "            y_edit, y1, y2, y_edit_lengths, y1_lengths, y2_lengths, i1, j1, i2, j2\n",
    "        ):\n",
    "            for n in range(1, n_soften_text + 1):\n",
    "                alpha = (amax - amin) * (n_soften_text - n) / (n_soften_text - 1) + amin\n",
    "                if i1 - n >= 0 and i2 - n >= 0:\n",
    "                    y_edit[:, :, i1 - n] = (1 - alpha) * y1[:, :, i1 - n] + alpha * y2[\n",
    "                        :, :, i2 - n\n",
    "                    ]\n",
    "                if (\n",
    "                    i1 + (j2 - i2) + n < y_edit_lengths\n",
    "                    and j1 + (n - 1) < y1_lengths\n",
    "                    and j2 + (n - 1) < y2_lengths\n",
    "                ):\n",
    "                    y_edit[:, :, i1 + (j2 - i2) + (n - 1)] = (1 - alpha) * y1[\n",
    "                        :, :, j1 + (n - 1)\n",
    "                    ] + alpha * y2[:, :, j2 + (n - 1)]\n",
    "            return y_edit\n",
    "\n",
    "        assert len(x1) == 1 and len(x2) == 1\n",
    "        assert emphases1 is not None and emphases2 is not None\n",
    "        assert len(emphases1) == 1 and len(emphases2) == 1\n",
    "\n",
    "        if mel1:\n",
    "            mu_y1, attn1, y1_mask, y1_max_length, y1_lengths = _process_audio_input(\n",
    "                x1, x1_lengths, mel1\n",
    "            )\n",
    "        else:\n",
    "            mu_y1, attn1, y1_mask, y1_max_length, y1_lengths = _process_input(\n",
    "                x1, x1_lengths\n",
    "            )  # mu_y1: [1, n_mels, T]\n",
    "\n",
    "        if mel2:\n",
    "            mu_y2, attn2, y2_mask, y2_max_length, y2_lengths = _process_audio_input(\n",
    "                x2, x2_lengths, mel2\n",
    "            )  # mu_y2: [1, n_mels, T]\n",
    "        else:\n",
    "            mu_y2, attn2, y2_mask, y2_max_length, y2_lengths = _process_input(\n",
    "                x2, x2_lengths\n",
    "            )  # mu_y2: [1, n_mels, T]\n",
    "\n",
    "        attn1 = attn1.squeeze()  # [N, T]\n",
    "        attn2 = attn2.squeeze()  # [N, T]\n",
    "\n",
    "        i1 = attn1[: emphases1[0][0]].sum().long().item() if emphases1[0][0] > 0 else 0\n",
    "        j1 = attn1[: emphases1[0][1]].sum().long().item()\n",
    "        i2 = attn2[: emphases2[0][0]].sum().long().item() if emphases2[0][0] > 0 else 0\n",
    "        j2 = attn2[: emphases2[0][1]].sum().long().item()\n",
    "\n",
    "        # Step 1. Direct concatenation\n",
    "        mu_y1_a, mu_y1_c = mu_y1[:, :, :i1], mu_y1[:, :, j1:y1_lengths]\n",
    "        mu_y2_b = mu_y2[:, :, i2:j2]\n",
    "        mu_y_edit = torch.cat((mu_y1_a, mu_y2_b, mu_y1_c), dim=2)\n",
    "        y_edit_lengths = int(mu_y_edit.shape[2])\n",
    "\n",
    "        # Step 2. Soften junctions\n",
    "        mu_y_edit = _soften_juntions(\n",
    "            mu_y_edit,\n",
    "            mu_y1,\n",
    "            mu_y2,\n",
    "            y_edit_lengths,\n",
    "            y1_lengths,\n",
    "            y2_lengths,\n",
    "            i1,\n",
    "            j1,\n",
    "            i2,\n",
    "            j2,\n",
    "        )\n",
    "\n",
    "        y_edit_length_ = fix_len_compatibility_text_edit(y_edit_lengths)\n",
    "        y_edit_lengths_tensor = torch.tensor([y_edit_lengths]).long().to(x1.device)\n",
    "        y_edit_mask_for_scorenet = (\n",
    "            sequence_mask(y_edit_lengths_tensor, y_edit_length_)\n",
    "            .unsqueeze(1)\n",
    "            .to(mu_y1.dtype)\n",
    "        )\n",
    "\n",
    "        eps1 = torch.randn_like(mu_y1, device=mu_y1.device) / temperature\n",
    "        eps2 = torch.randn_like(mu_y2, device=mu_y1.device) / temperature\n",
    "        eps_edit = torch.cat(\n",
    "            (eps1[:, :, :i1], eps2[:, :, i2:j2], eps1[:, :, j1:y1_lengths]), dim=2\n",
    "        )\n",
    "        z1 = mu_y1 + eps1\n",
    "        z2 = mu_y2 + eps2\n",
    "        z_edit = mu_y_edit + eps_edit\n",
    "\n",
    "        if z_edit.shape[2] < y_edit_length_:\n",
    "            pad = y_edit_length_ - z_edit.shape[2]\n",
    "            zeros = torch.zeros_like(z_edit[:, :, :pad])\n",
    "            z_edit = torch.cat((z_edit, zeros), dim=2)\n",
    "            mu_y_edit = torch.cat((mu_y_edit, zeros), dim=2)\n",
    "        elif z_edit.shape[2] > y_edit_length_:\n",
    "            res = z_edit.shape[2] - y_edit_length_\n",
    "            z_edit = z_edit[:, :, :-res]\n",
    "            mu_y_edit = mu_y_edit[:, :, :-res]\n",
    "\n",
    "        y_edit_mask_for_gradient = torch.zeros_like(mu_y_edit[:, :1, :])\n",
    "        y_edit_mask_for_gradient[:, :, i1 : i1 + (j2 - i2)] = 1\n",
    "\n",
    "        dec1 = self.decoder(z1, y1_mask, mu_y1, n_timesteps, stoc)\n",
    "        dec2, dec_edit = self.decoder.double_forward_text(\n",
    "            z2,\n",
    "            z_edit,\n",
    "            mu_y2,\n",
    "            mu_y_edit,\n",
    "            y2_mask,\n",
    "            y_edit_mask_for_scorenet,\n",
    "            y_edit_mask_for_gradient,\n",
    "            i1,\n",
    "            j1,\n",
    "            i2,\n",
    "            j2,\n",
    "            n_timesteps,\n",
    "            stoc,\n",
    "            soften_mask,\n",
    "            n_soften,\n",
    "        )\n",
    "\n",
    "        dec1 = dec1[:, :, :y1_max_length]\n",
    "        dec2 = dec2[:, :, :y2_max_length]\n",
    "        dec_edit = dec_edit[:, :, :y_edit_lengths]\n",
    "        dec_cat = torch.cat(\n",
    "            (dec1[:, :, :i1], dec2[:, :, i2:j2], dec1[:, :, j1:y1_lengths]), dim=2\n",
    "        )\n",
    "\n",
    "        return dec1, dec2, dec_edit, dec_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9542095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULTS = HParams(\n",
    "    cudnn_enabled=True,\n",
    "    log_dir=\"output\",\n",
    "    symbol_set=\"gradtts\",\n",
    "    intersperse_text=True,\n",
    "    n_spks=1,\n",
    "    spk_emb_dim=64,\n",
    "    sampling_rate=22050,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    n_enc_channels=192,\n",
    "    filter_channels=768,\n",
    "    filter_channels_dp=256,\n",
    "    n_enc_layers=6,\n",
    "    enc_kernel=3,\n",
    "    enc_dropout=0.1,\n",
    "    n_heads=2,\n",
    "    window_size=4,\n",
    "    dec_dim=64,\n",
    "    beta_min=0.05,\n",
    "    beta_max=20.0,\n",
    "    pe_scale=1000,\n",
    "    test_size=2,\n",
    "    n_epochs=10000,\n",
    "    batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    seed=37,\n",
    "    out_size=2 * 22050 // 256,\n",
    "    filter_length=1024,\n",
    "    rank=0,\n",
    "    distributed_run=False,\n",
    "    oversample_weights=None,\n",
    "    text_cleaners=[\"english_cleaners\"],\n",
    "    max_wav_value=32768.0,\n",
    "    n_feats=80,\n",
    "    mel_fmax=8000,\n",
    "    mel_fmin=0.0,\n",
    "    checkpoint=None,\n",
    "    log_interval=100,\n",
    "    save_every=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d6738",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'grad_250.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bf9438f37956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a test voice message.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'grad_250.pt'"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "checkpoint = \"grad_250.pt\"\n",
    "model = GradTTS(DEFAULTS)\n",
    "# print(model)\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "model = model.cuda()\n",
    "y_enc, y_dec, attn = model.infer(\"This is a test voice message.\", n_timesteps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a91044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight norm already removed\n",
      "weight norm already removed\n",
      "weight norm already removed\n"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "from uberduck_ml_dev.vocoders.hifigan import HiFiGanGenerator\n",
    "\n",
    "\n",
    "hifigan = HiFiGanGenerator(\n",
    "    config=\"/home/w_uberduck_ai/Speech-Backbones/Grad-TTS/checkpts/hifigan-config.json\",\n",
    "    checkpoint=\"/home/w_uberduck_ai/Speech-Backbones/Grad-TTS/checkpts/gen_02640000_studio\",\n",
    "    cudnn_enabled=True,\n",
    ")\n",
    "audio_1 = hifigan.infer(y_dec1)\n",
    "audio_2 = hifigan.infer(y_dec2)\n",
    "audio_edit = hifigan.infer(y_dec_edit)\n",
    "audio_cat = hifigan.infer(y_dec_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc9521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Audio(audio_1, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191ee75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-99cd0ca03354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m y_enc, y_dec, attn = model.infer(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"The Fitness Gram Pacer Test is a multistage aerobic capacity test that progressively gets more difficult as it continues.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mn_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhifigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c77e5f06e20e>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, n_timesteps, cleaner_names, temperature, stoc, spk, length_scale, intersperse_text, intersperse_token)\u001b[0m\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mintersperse_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersperse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersperse_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "y_enc, y_dec, attn = model.infer(\n",
    "    \"The Fitness Gram Pacer Test is a multistage aerobic capacity test that progressively gets more difficult as it continues.\",\n",
    "    n_timesteps=100,\n",
    ")\n",
    "audio = hifigan.infer(y_dec)\n",
    "# audio = audio / np.max(audio)\n",
    "# ipd.Audio(audio, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9fab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2cd39b3037b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m y_enc, y_dec, attn = model.infer(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"The fitness gram pace test is a multi stage aerobic capacity test that { P R AH0 G R EH1 S IH0 V L IY0 } gets more difficult as it continues.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mn_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhifigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c77e5f06e20e>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, n_timesteps, cleaner_names, temperature, stoc, spk, length_scale, intersperse_text, intersperse_token)\u001b[0m\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mintersperse_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersperse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersperse_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "y_enc, y_dec, attn = model.infer(\n",
    "    \"The fitness gram pace test is a multi stage aerobic capacity test that { P R AH0 G R EH1 S IH0 V L IY0 } gets more difficult as it continues.\",\n",
    "    n_timesteps=50,\n",
    ")\n",
    "audio = hifigan.infer(y_dec)\n",
    "audio = audio / np.max(audio)\n",
    "# ipd.Audio(audio, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ef4f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a54776690d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m y_enc, y_dec, attn = model.infer(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Do you say progressively or do you say { P R AH0 G R EH1 S IH0 V L IY0 }.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mn_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhifigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c77e5f06e20e>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, text, n_timesteps, cleaner_names, temperature, stoc, spk, length_scale, intersperse_text, intersperse_token)\u001b[0m\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mintersperse_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersperse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersperse_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "y_enc, y_dec, attn = model.infer(\n",
    "    \"Do you say progressively or do you say { P R AH0 G R EH1 S IH0 V L IY0 }.\",\n",
    "    n_timesteps=50,\n",
    ")\n",
    "audio = hifigan.infer(y_dec)\n",
    "audio = audio / np.max(audio)\n",
    "ipd.Audio(audio, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a500000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
