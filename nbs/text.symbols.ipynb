{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c650bc7",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484b461",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16036bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\"\"\" from https://github.com/keithito/tacotron \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Defines the set of symbols used in text input to the model.\n",
    "The default is a set of ASCII characters that works well for English or text that has been run through Unidecode. For other data, you can modify _characters. See TRAINING_DATA.md for details. \"\"\"\n",
    "\n",
    "from uberduck_ml_dev.text import cmudict\n",
    "\n",
    "_punctuation = \"!'\\\",.:;? \"\n",
    "_math = \"#%&*+-/[]()\"\n",
    "_special = \"_@©°½—₩€$\"\n",
    "_accented = \"áçéêëñöøćž\"\n",
    "_numbers = \"0123456789\"\n",
    "_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "# Prepend \"@\" to ARPAbet symbols to ensure uniqueness (some are the same as\n",
    "# uppercase letters):\n",
    "_arpabet = [\"@\" + s for s in cmudict.valid_symbols]\n",
    "\n",
    "# Export all symbols:\n",
    "symbols = (\n",
    "    list(_punctuation + _math + _special + _accented + _numbers + _letters) + _arpabet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re\n",
    "\n",
    "symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
    "id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
    "curly_re = re.compile(r\"(.*?)\\{(.+?)\\}(.*)\")\n",
    "words_re = re.compile(\n",
    "    r\"([a-zA-ZÀ-ž]+['][a-zA-ZÀ-ž]{1,2}|[a-zA-ZÀ-ž]+)|([{][^}]+[}]|[^a-zA-ZÀ-ž{}]+)\"\n",
    ")\n",
    "\n",
    "\n",
    "def symbols_to_sequence(symbols):\n",
    "    return [symbol_to_id[s] for s in symbols if should_keep_symbol(s)]\n",
    "\n",
    "\n",
    "def arpabet_to_sequence(text):\n",
    "    return symbols_to_sequence([\"@\" + s for s in text.split()])\n",
    "\n",
    "\n",
    "def should_keep_symbol(s):\n",
    "    return s in symbol_to_id and s != \"_\" and s != \"~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b3942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', ''), ('', '   '), ('quick', '')]\n",
      "[(\"I'm\", ''), ('', ' '), ('blue', ''), ('', ',')]\n",
      "[(\"L'mo\", ''), (\"nj'el\", ''), ('lo', '')]\n",
      "[('', '{ S IY }'), ('', ' '), ('', '{ EH M }')]\n"
     ]
    }
   ],
   "source": [
    "print(words_re.findall(\"The   quick\"))\n",
    "print(words_re.findall(\"I'm blue,\"))\n",
    "print(words_re.findall(\"L'monj'ello\"))\n",
    "print(words_re.findall(\"{ S IY } { EH M }\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1eca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert should_keep_symbol(\" \")\n",
    "assert not should_keep_symbol(\"\\n\")\n",
    "assert should_keep_symbol(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7099829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def say_hello2():\n",
    "    print(\"hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: arpabet_to_sequence does not properly handle whitespace, it should take single words only.\n",
    "assert (\n",
    "    len(arpabet_to_sequence(\"{ S IY } { EH M } { Y UW } { D IH K SH AH N EH R IY }\"))\n",
    "    == 15\n",
    ")\n",
    "assert arpabet_to_sequence(\"{ S IY }\") == [168, 148]\n",
    "# But symbols_to_sequence hanldes whitespace\n",
    "assert len(symbols_to_sequence(\"C M U Dictionary\")) == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f5667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
