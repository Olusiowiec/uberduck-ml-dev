{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52641b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export\n",
    "# def synthesize_speakerids(filelists):\n",
    "\n",
    "#     data_dict = {}\n",
    "#     for f in range(len(filelists)):\n",
    "#         data_dict[filelists[f]] = pd.read_csv(filelists[f], sep = \",\",index_col=0,error_bad_lines=False)\n",
    "#         #pd.read_csv(filelists[f], sep = \"|\",header=None, error_bad_lines=False)\n",
    "        \n",
    "#     source_files = list(data_dict.keys())\n",
    "#     nspeakers_cumulative = 0\n",
    "#     speaker_offset = {}\n",
    "#     for source_file in filelists:\n",
    "#         data = data_dict[source_file]\n",
    "#         nspeakers = len(np.unique(data.iloc[:,2]))\n",
    "#         data.iloc[:,2] = data.iloc[:,2] + nspeakers_cumulative\n",
    "#         data_dict[source_file] = data\n",
    "#         speaker_offset[source_file] = nspeakers_cumulative\n",
    "#         nspeakers_cumulative = nspeakers_cumulative + nspeakers\n",
    "\n",
    "#     return(data_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf114bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "def load_filepaths_and_text(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "    return filepaths_and_text\n",
    "\n",
    "def synthesize_speakerids2(filelists, fix_indices_index = None):\n",
    "\n",
    "    data_dict = {}\n",
    "    data_dict_out = {}\n",
    "    for f in range(len(filelists)):\n",
    "        #data_dict[filelists[f]] = pd.read_csv(filelists[f], sep = \",\",index_col=0,error_bad_lines=False)\n",
    "            data = load_filepaths_and_text(filelists[f])\n",
    "            data_dict[filelists[f]] = pd.DataFrame(data)    \n",
    "        #pd.read_csv(filelists[f], sep = \"|\",header=None, error_bad_lines=False)\n",
    "        \n",
    "    source_files = list(data_dict.keys())\n",
    "    \n",
    "    speaker_offset = {}\n",
    "    nfilelist = len(filelists)\n",
    "    reserved_speakers = np.unique(data_dict[filelists[fix_indices_index]].iloc[:,2])\n",
    "    \n",
    "    for s in range(nfilelist):\n",
    "        source_file = filelists[s]\n",
    "        data = data_dict[source_file]\n",
    "        if s != fix_indices_index:\n",
    "            speakers = np.unique(data.iloc[:,2])\n",
    "            overlap = np.where(np.isin(speakers, reserved_speakers))[0]\n",
    "            reserved_speakers_temp = np.union1d(speakers, reserved_speakers)\n",
    "            newindices = np.setdiff1d(list(range(len(reserved_speakers) + len(speakers))), reserved_speakers_temp)[:len(overlap)]\n",
    "            for o in range(len(overlap)):\n",
    "                data.iloc[np.where(data.iloc[:,2] == overlap[o])[0] ,2] = newindices[o]\n",
    "\n",
    "            data_dict_out[source_file] = data\n",
    "            speakers = np.unique(data.iloc[:,2])\n",
    "            reserved_speakers = np.union1d(speakers, reserved_speakers)\n",
    "            #print(speakers,reserved_speakers)\n",
    "        else:\n",
    "            data_dict_out[source_file] = data\n",
    "    return(data_dict_out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db47e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lj7_processed_file.npy', 'libritts_processed_file.npy', 'uberduck_processed_files.npy', 'vctk_processed_file.npy']\n"
     ]
    }
   ],
   "source": [
    "metalist_dir = '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/metadata_collections'\n",
    "metalist_files = os.listdir(metalist_dir)\n",
    "print(metalist_files)\n",
    "train_ratios = np.ones(4)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18397234",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelists=np.asarray([])\n",
    "#files = np.asarray([])\n",
    "for r in range(4):\n",
    "    files = np.load(metalist_dir +'/'+ metalist_files[r],allow_pickle=True)\n",
    "    filelist = np.asarray([])\n",
    "    \n",
    "    if files.ndim > 0:\n",
    "        nfiles = files.shape[0]\n",
    "        for s in range(nfiles):\n",
    "            filelist = np.append(filelist, files[s])\n",
    "    else: \n",
    "        filelist = files\n",
    "    filelists = np.append(filelists, filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/lj7all_processed.txt'\n",
      " '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/librittsall_processed.txt'\n",
      " '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/eminem_all_processed.txt'\n",
      " '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/ben-shapiro_all_processed.txt'\n",
      " '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/jay-z_all_processed.txt'\n",
      " '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/vctkall_processed.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:565: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "print(filelists)\n",
    "dd = synthesize_speakerids2(filelists,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = list(dd.values())\n",
    "#ad2 = [ad[i] for i in [0,2,3]]\n",
    "#ad2 = [ad[i] for i in [2,3,4]]\n",
    "#ad2 = [ad[i] for i in [0]]\n",
    "ad2 = [ad[i] for i in [2]]\n",
    "alldata = pd.concat(ad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57762",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = np.random.choice(alldata.shape[0], math.floor(alldata.shape[0]*.8), replace = False)\n",
    "val_ind = np.setdiff1d(list(range(alldata.shape[0])), train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76122c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.iloc[train_ind,:].to_csv('/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/filelists/todos_train.txt', header = False,sep = '|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb829e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.iloc[val_ind].to_csv('/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/filelists/todos_val.txt', header = False,sep = '|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c32cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audiopaths_and_text = '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/filelists/todos_train.txt'\n",
    "audiopaths_and_text = '/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/experiments/processed_metadata/eminem_all_processed.txt'\n",
    "audiopaths_and_text = load_filepaths_and_text(audiopaths_and_text)\n",
    "#asdf = [x[2] for x in audiopaths_and_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf9b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00335953,  0.00497484,  0.00431533, ..., -0.00397925,\n",
       "        -0.00451155,  0.        ], dtype=float32),\n",
       " 22050)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librosa.load(audiopaths_and_text[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd174f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00469971,  0.00460815,  0.00466919, ..., -0.00439453,\n",
       "        -0.00415039, -0.00308228]),\n",
       " 48000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.read(audiopaths_and_text[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080765a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/disks/uberduck-experiments-v0/data/LJSpeech-1.1/wavs/LJ010-0305.wav'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audiopaths_and_text[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = audiopaths_and_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba73ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, encoding='utf-8') as f:\n",
    "    filepaths_and_text = [line for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2585fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### source_files = [experiment_filelist_dir + 'eminem_all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/kanye-rap/all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/alex-trebek/all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/ben-shapiro/all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/michael-rosen/all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/steve-harvey/all.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/LJSpeech-1.1/metadata.csv',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/LibriTTS/metadata_mellotron.txt',\n",
    "#             '/mnt/disk/uberduck-experiments-v0/data/uberduck/vctk/metadata.txt']\n",
    "\n",
    "# synthesize_speakerids(source_files) #need to change\n",
    "# reindex()\n",
    "\n",
    "# train,val  = get_testval_split()\n",
    "\n",
    "# TTSModel('mellotron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800f326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
